{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a34f30c6",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Standard errors\n",
                "\n",
                "This is a notebook demonstrating how to obtain standard errors for your generated impact estimates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "43b770ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import os, sys\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# the below checks for whether we run dowhy, causaltune, and FLAML from source\n",
                "root_path = root_path = os.path.realpath('../..')\n",
                "try:\n",
                "    import causaltune\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
                "\n",
                "try:\n",
                "    import dowhy\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
                "\n",
                "try:\n",
                "    import flaml\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"FLAML\"))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "53241021",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# this makes the notebook expand to full width of the browser window\n",
                "from IPython.core.display import display, HTML\n",
                "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ed9b5f7",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "%%javascript\n",
                "\n",
                "// turn off scrollable windows for large output\n",
                "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
                "    return false;\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da208ce6",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "from causaltune import CausalTune\n",
                "from causaltune.datasets import synth_ihdp"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "ab536d1b",
            "metadata": {},
            "source": [
                "## Loading data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96719b4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load toy dataset and apply standard pre-processing\n",
                "cd = synth_ihdp()\n",
                "cd.preprocess_dataset()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "49e4721b",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# inspect the preprocessed dataset\n",
                "display(cd.data.head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "d4d1871f",
            "metadata": {},
            "source": [
                "## Model training and standard errors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd4b291e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# training configs\n",
                "\n",
                "# choose estimators of interest\n",
                "estimator_list = [\n",
                "\n",
                "            # \"Dummy\",\n",
                "            # \"SparseLinearDML\",\n",
                "            # \"ForestDRLearner\",\n",
                "            # \"TransformedOutcome\",\n",
                "            # \"CausalForestDML\",\n",
                "            \".LinearDML\",\n",
                "            # \"DomainAdaptationLearner\",\n",
                "            \"SLearner\",\n",
                "            \"XLearner\",\n",
                "            # \"TLearner\",\n",
                "            # \"Ortho\"\n",
                "    ]\n",
                "\n",
                "# set evaluation metric\n",
                "metric = \"energy_distance\"\n",
                "\n",
                "# it's best to specify either time_budget or components_time_budget, \n",
                "# and let the other one be inferred; time in seconds\n",
                "time_budget = None\n",
                "components_time_budget = 10\n",
                "\n",
                "# specify training set size\n",
                "train_size = 0.7\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "ct = CausalTune(\n",
                "    estimator_list=estimator_list,\n",
                "    metric=metric,\n",
                "    verbose=3,\n",
                "    components_verbose=2,\n",
                "    time_budget=time_budget,\n",
                "    components_time_budget=components_time_budget,\n",
                "    train_size=train_size\n",
                ")\n",
                "\n",
                "\n",
                "# run causaltune\n",
                "ct.fit(data=cd, outcome=cd.outcomes[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dd8b4d04",
            "metadata": {},
            "outputs": [],
            "source": [
                "# obtaining effect estimates\n",
                "cates = ct.effect(ct.test_df)\n",
                "display(cates)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8c819410",
            "metadata": {},
            "source": [
                "Below we show how to generate standard errors using `causaltune`. By default, this will use the `best_estimator` identified during training.\n",
                "\n",
                "If this estimator does not have analytical standard errors, it will be refitted `n_bootstrap_samples` times on the training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ee744d2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# generating standard errors by refitting train_df \n",
                "se = ct.effect_stderr(ct.test_df)\n",
                "display(se)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "causality",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
