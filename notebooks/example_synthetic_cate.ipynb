{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATE estimation with synthetic dataset\n",
    "Here, we explore the effectiveness of different scoring metrics in capturing the error between the estimated and true causal effects in small synthetic datasets.  \n",
    "\n",
    "## Background\n",
    "Often, different units are suceptible to a treatment to different degrees. Our goal is to use our toolbox to estimate these heterogenous treatment effects and assess how well the toolbox performs\n",
    "In other words, how well does a score reflect the mismatch between the estimated and true causal effect?  \n",
    "We divide our approach in different parts. First, we'll generate some synthetic data for which we know the relationship between variables, as well as the treatment effect. \n",
    "We'll consider two scenarios, with and without confounding variables. Next, we'll use AutoCausality for hyperparameter tuning and model selection of a zoo of causal estimators. We'll do this for different scoring methods.\n",
    "Lastly, we'll plot the returned scores against the misestimation error between predicted and true treatment effect. \n",
    "Below, we import the relevant modules and define a few helper functions (TODO outsource the latter to autocausality, once approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
    "try:\n",
    "    import graphviz\n",
    "except ModuleNotFoundError as e:\n",
    "    import pip\n",
    "    pip.main([\"install\",\"graphviz\"])\n",
    "    import graphviz\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from auto_causality import AutoCausality\n",
    "from auto_causality.data_utils import preprocess_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation 1: CATE without confounders\n",
    "We will begin with a simple synthetic dataset, in which the outcome is influenced by the treatment and a set of covariates, which are independent of the treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Title: causal&#45;graph Pages: 1 -->\n<svg width=\"220pt\" height=\"116pt\"\n viewBox=\"0.00 0.00 219.84 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n<title>causal&#45;graph</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 215.84,-112 215.84,4 -4,4\"/>\n<!-- X -->\n<g id=\"node1\" class=\"node\">\n<title>X</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"49.4\" cy=\"-90\" rx=\"49.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"49.4\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Covariates</text>\n</g>\n<!-- Y -->\n<g id=\"node3\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"106.4\" cy=\"-18\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"106.4\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outcome</text>\n</g>\n<!-- X&#45;&gt;Y -->\n<g id=\"edge1\" class=\"edge\">\n<title>X&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M62.9,-72.41C69.93,-63.78 78.66,-53.06 86.45,-43.5\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"89.38,-45.43 92.98,-35.47 83.96,-41.01 89.38,-45.43\"/>\n</g>\n<!-- T -->\n<g id=\"node2\" class=\"node\">\n<title>T</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"164.4\" cy=\"-90\" rx=\"47.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"164.4\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Treatment</text>\n</g>\n<!-- T&#45;&gt;Y -->\n<g id=\"edge2\" class=\"edge\">\n<title>T&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M150.65,-72.41C143.43,-63.69 134.44,-52.85 126.45,-43.21\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"129.12,-40.94 120.04,-35.47 123.73,-45.4 129.12,-40.94\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17f24039880>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = graphviz.Digraph(\"causal-graph\",comment=\"A simple causal graph\",filename=\"simple_graph.gv\")\n",
    "dot.node(\"X\",label=\"Covariates\")\n",
    "dot.node(\"T\",label=\"Treatment\")\n",
    "dot.node(\"Y\",label=\"Outcome\")\n",
    "dot.edge(\"X\",\"Y\")\n",
    "dot.edge(\"T\",\"Y\")\n",
    "dot.edge_attr.update(arrowsize=\"1\")\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X^{Nxd}$ be the matrix of $N$ observations and $d$ covariates, $T^{nx1}$ the vector of treatment assignments and $Y^{nx1}$ the vector of outcomes. \n",
    "We make the following assumptions:  \n",
    "- binary treatments\n",
    "- fully random propensity to treat \n",
    "- five continuous, normally distributed covariates\n",
    "- no interaction between treatment effects and covariates (unconfoundedness)\n",
    "- independence of the covariates, i.e. $\\Sigma = \\sigma^2I$\n",
    "- no additive noise in the outcomes, i.e. $\\epsilon=0$\n",
    "\n",
    "  \n",
    "Then, the data is generated according to the following equations:\n",
    "\\begin{align*}\n",
    "X_i \\sim \\mathcal{N}(0,\\Sigma) \\\\\\\\\n",
    "T_i \\sim Bernoulli(0.5) \\\\\\\\\n",
    "Y_i = \\tau(X_i) T_i + \\mu_0(X_i) + \\epsilon\n",
    "\\end{align*}\n",
    "where $i$ indexes individual units, $\\tau$ describes the following true treatment effect, which depends linearly on all covariates:\n",
    "\\begin{equation*}\n",
    "\\tau(X_i) = X_ib^T + e\n",
    "\\end{equation*}\n",
    "where $b$ is a 1xd vector of $b_i \\sim U(0.4,0.7)$ weights for each covariate and $e \\sim \\mathcal{N}(0,0.05)$ gaussian noise.  \n",
    "... and  $\\mu_0(x)$ describes the following transformation of the covariates (to keep things interesting):\n",
    "\\begin{equation*}\n",
    "\\mu_0(X_i) = X_{i,1} \\otimes X_{i,2} + X_{i,3} + X_{i,4} \\otimes X_{i,5} \n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psdmat(n_dims: int = 10) -> np.ndarray:\n",
    "    \"\"\"generates a symmetric, positive semidefinite matrix\n",
    "\n",
    "    Args:\n",
    "        n_dims (int, optional): number of dimensions. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: psd matrix\n",
    "    \"\"\"\n",
    "    A = np.random.rand(n_dims, n_dims)\n",
    "    A = A@A.T\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def mu_zero(X:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"hard-coded transformation of covariates, including interaction terms\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): matrix of n observations and d covariates\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: transformed matrix\n",
    "    \"\"\"\n",
    "    return X[:,0] * X[:,1] + X[:,2] + X[:,3] * X[:,4]\n",
    "\n",
    "def generate_cate_data(\n",
    "    n_samples: int = 100,\n",
    "    n_covariates: int = 5,\n",
    "    covariance: Union[str, np.ndarray] = \"isotropic\",\n",
    "    confounding: bool = False,\n",
    "    random_propensity: bool = True,\n",
    "    noisy_outcomes: bool = False,\n",
    "\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"generates synthetic dataset with random heterogenous treatment effects\n",
    "\n",
    "    Args:\n",
    "        n_samples (int, optional): number of independent samples. Defaults to 100.\n",
    "        n_covariates (int, optional): number of covariates. Defaults to 5.\n",
    "        covariance (Union[str, np.ndarray], optional): covariance matrix of covariates. can be \"isotropic\", \"anisotropic\" or user-supplied. Defaults to \"isotropic\".\n",
    "        confounding (bool, optional): whether or not values of covariates affect treatment effect. Defaults to False.        \n",
    "        noisy_outcomes (bool, optional): additive noise in the outcomes. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns for covariates, treatment assignment, outcome and true treatment effect\n",
    "    \"\"\"\n",
    "\n",
    "    if covariance == \"isotropic\":\n",
    "        sigma = np.random.randn(1)\n",
    "        covmat = np.eye(n_covariates)*sigma**2\n",
    "    elif covariance == \"anisotropic\":\n",
    "        covmat = generate_psdmat(n_covariates)\n",
    "\n",
    "    X = np.random.multivariate_normal(mean=[0]*n_covariates,cov=covmat,size=n_samples)\n",
    "\n",
    "    \n",
    "    if confounding:\n",
    "        T = 1/(1+np.exp(X[:,0]*X[:,1]+X[:,2]*3)) > np.random.rand(n_samples)\n",
    "    else:\n",
    "        T = np.random.binomial(n=1, p=0.5,size=n_samples)\n",
    "\n",
    "    # heterogeneity in effect size:\n",
    "    weights = np.random.uniform(low=0.4,high=0.7,size=n_covariates)\n",
    "    e = np.random.randn(n_samples) * 0.01\n",
    "    tau = X@weights.T + e\n",
    "\n",
    "\n",
    "    err = np.random.randn(n_samples) *0.05 if noisy_outcomes else 0\n",
    "\n",
    "    Y = tau*T + mu_zero(X) + err\n",
    "\n",
    "    df = pd.DataFrame(np.array([*X.T,T,Y,tau]).T,columns=[f\"X{i}\" for i in range(1,n_covariates+1)]+[\"treatment\",\"outcome\",\"true_effect\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing\n",
    "Now we apply AutoCausality's built-in preprocessing pipeline and construct train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_X: ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "features_W: ['random']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>true_effect</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497797</td>\n",
       "      <td>-0.860008</td>\n",
       "      <td>0.931187</td>\n",
       "      <td>0.357762</td>\n",
       "      <td>-1.592801</td>\n",
       "      <td>-0.590697</td>\n",
       "      <td>-0.805646</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.603148</td>\n",
       "      <td>2.148766</td>\n",
       "      <td>0.471225</td>\n",
       "      <td>-0.423814</td>\n",
       "      <td>-0.324886</td>\n",
       "      <td>-0.392196</td>\n",
       "      <td>0.886990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.115415</td>\n",
       "      <td>0.027012</td>\n",
       "      <td>0.170043</td>\n",
       "      <td>2.663901</td>\n",
       "      <td>0.163521</td>\n",
       "      <td>1.369919</td>\n",
       "      <td>2.222910</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.618903</td>\n",
       "      <td>0.037290</td>\n",
       "      <td>1.505594</td>\n",
       "      <td>0.356663</td>\n",
       "      <td>-1.082438</td>\n",
       "      <td>-1.172721</td>\n",
       "      <td>-0.063300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.521416</td>\n",
       "      <td>0.420891</td>\n",
       "      <td>0.388670</td>\n",
       "      <td>-0.026993</td>\n",
       "      <td>-0.552429</td>\n",
       "      <td>-0.696597</td>\n",
       "      <td>-0.140630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.092026</td>\n",
       "      <td>-0.486403</td>\n",
       "      <td>0.521498</td>\n",
       "      <td>1.305984</td>\n",
       "      <td>0.142133</td>\n",
       "      <td>0.525154</td>\n",
       "      <td>0.965057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.127552</td>\n",
       "      <td>0.316064</td>\n",
       "      <td>-0.278068</td>\n",
       "      <td>0.420151</td>\n",
       "      <td>-0.962904</td>\n",
       "      <td>1.516057</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>-0.355357</td>\n",
       "      <td>0.424834</td>\n",
       "      <td>-0.754118</td>\n",
       "      <td>0.974317</td>\n",
       "      <td>0.685025</td>\n",
       "      <td>0.251134</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.628158</td>\n",
       "      <td>0.468524</td>\n",
       "      <td>-0.999600</td>\n",
       "      <td>-1.865731</td>\n",
       "      <td>-0.851609</td>\n",
       "      <td>-0.669467</td>\n",
       "      <td>-1.864215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.066245</td>\n",
       "      <td>-0.453386</td>\n",
       "      <td>0.657938</td>\n",
       "      <td>-0.567920</td>\n",
       "      <td>2.391420</td>\n",
       "      <td>-0.083643</td>\n",
       "      <td>0.674201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment   outcome        X1        X2        X3        X4        X5  \\\n",
       "0        0.0  0.497797 -0.860008  0.931187  0.357762 -1.592801 -0.590697   \n",
       "1        1.0  1.603148  2.148766  0.471225 -0.423814 -0.324886 -0.392196   \n",
       "2        1.0  5.115415  0.027012  0.170043  2.663901  0.163521  1.369919   \n",
       "3        1.0  1.618903  0.037290  1.505594  0.356663 -1.082438 -1.172721   \n",
       "4        0.0  0.521416  0.420891  0.388670 -0.026993 -0.552429 -0.696597   \n",
       "5        1.0  2.092026 -0.486403  0.521498  1.305984  0.142133  0.525154   \n",
       "6        0.0 -1.127552  0.316064 -0.278068  0.420151 -0.962904  1.516057   \n",
       "7        1.0  0.013479 -0.355357  0.424834 -0.754118  0.974317  0.685025   \n",
       "8        1.0 -3.628158  0.468524 -0.999600 -1.865731 -0.851609 -0.669467   \n",
       "9        0.0 -1.066245 -0.453386  0.657938 -0.567920  2.391420 -0.083643   \n",
       "\n",
       "   true_effect  random  \n",
       "0    -0.805646     0.0  \n",
       "1     0.886990     1.0  \n",
       "2     2.222910     0.0  \n",
       "3    -0.063300     1.0  \n",
       "4    -0.140630     1.0  \n",
       "5     0.965057     1.0  \n",
       "6     0.538922     1.0  \n",
       "7     0.251134     1.0  \n",
       "8    -1.864215     0.0  \n",
       "9     0.674201     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_cate_data(n_samples=1000,confounding=False)\n",
    "outcome = \"outcome\"\n",
    "data_df, features_X, features_W = preprocess_dataset(data, treatment=\"treatment\", targets=[\"outcome\"])\n",
    "# drop true effect:\n",
    "features_X = [f for f in features_X if f != \"true_effect\"]\n",
    "print(f\"features_X: {features_X}\")\n",
    "print(f\"features_W: {features_W}\")\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Model fitting\n",
    "Now we're ready to find the best fitting model, given a user-specified metric. As we'd like to compare different metrics, we'll be doing this in a for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AutoCausality(\n",
    "    metric=\"norm_erupt\",\n",
    "    verbose=3,\n",
    "    components_verbose=2,\n",
    "    components_time_budget=30,\n",
    ") \n",
    "\n",
    "ac.fit(\n",
    "    train_df,\n",
    "    treatment=\"treatment\",\n",
    "    outcome=\"outcome\",\n",
    "    common_causes=features_W,\n",
    "    effect_modifiers=features_X,\n",
    "   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Evaluation\n",
    "How well did the different metrics quantify the mismatch between estimated and true treatment effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: backdoor.econml.metalearners.SLearner\n",
      "best config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}\n",
      "best score: -0.011536820689823125\n"
     ]
    }
   ],
   "source": [
    "# return best estimator\n",
    "print(f\"Best estimator: {ac.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"best config: {ac.best_config}\")\n",
    "# best score:\n",
    "print(f\"best score: {ac.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score all estimators on the test set, which we've kept aside up till now\n",
    "# NOTE: I'm adding the CATE estimates here, too\n",
    "# NOTE: I'm ignoring NewDummy, as it's throwing some errors\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "for est_name, scr in ac.scores.items():\n",
    "    if \"NewDummy\" in est_name:\n",
    "        pass\n",
    "    else:\n",
    "        causal_estimate = scr['estimator']\n",
    "    \n",
    "        scr['scores']['test'] = ac.scorer.make_scores(causal_estimate, test_df, problem=ac.problem, metrics_to_report=ac.metrics_to_report)\n",
    "        # add cate:\n",
    "        scr[\"scores\"][\"test\"][\"values\"][\"CATE_estimate\"] = causal_estimate.estimator.effect(test_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treated</th>\n",
       "      <th>outcome</th>\n",
       "      <th>p</th>\n",
       "      <th>policy</th>\n",
       "      <th>norm_policy</th>\n",
       "      <th>weights</th>\n",
       "      <th>CATE_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.440696</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.25138</td>\n",
       "      <td>-1.481938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.025875</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.25138</td>\n",
       "      <td>-0.458143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.581499</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.33742</td>\n",
       "      <td>0.890703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.584122</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.33742</td>\n",
       "      <td>0.864529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.411661</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.810092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.838410</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.25138</td>\n",
       "      <td>-0.428102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.054105</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.678419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.303919</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.33742</td>\n",
       "      <td>0.502824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.567933</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.33742</td>\n",
       "      <td>0.708026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.782934</td>\n",
       "      <td>0.490625</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.33742</td>\n",
       "      <td>2.087335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treated   outcome         p  policy  norm_policy  weights  CATE_estimate\n",
       "0      0.0 -1.440696  0.490625   False        False  2.25138      -1.481938\n",
       "1      0.0 -1.025875  0.490625   False        False  2.25138      -0.458143\n",
       "2      1.0  4.581499  0.490625    True         True  2.33742       0.890703\n",
       "3      1.0  4.584122  0.490625    True         True  2.33742       0.864529\n",
       "4      1.0 -4.411661  0.490625   False        False  0.00000      -0.810092\n",
       "5      0.0 -1.838410  0.490625   False        False  2.25138      -0.428102\n",
       "6      0.0  2.054105  0.490625    True         True  0.00000       0.678419\n",
       "7      1.0  2.303919  0.490625    True         True  2.33742       0.502824\n",
       "8      1.0 -0.567933  0.490625    True         True  2.33742       0.708026\n",
       "9      1.0  5.782934  0.490625    True         True  2.33742       2.087335"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.scores[ac.best_estimator][\"scores\"][\"test\"][\"values\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'norm_erupt')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true against estimated:\n",
    "plt.scatter(test_df[\"true_effect\"],ac.scores[ac.best_estimator][\"scores\"][\"test\"][\"values\"][\"CATE_estimate\"])\n",
    "plt.xlabel(\"true CATE\")\n",
    "plt.ylabel(\"estimated CATE\")\n",
    "plt.title(ac.metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('autocausality')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d738b306ac6f08f90dfb29051c15b9a8f4fea312b55b05a4c05e42fcf3ab44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
