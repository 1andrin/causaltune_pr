{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV estimation with observational data\n",
    "Here, we explore the effectiveness of different scoring metrics in capturing the error between the estimated and true causal effects in small synthetic datasets.    \n",
    "The data is observational (treatment confounded by covariates) and includes an instrumental variable that affects the treatment.  \n",
    "\n",
    "## Background\n",
    "Instrumental Variables (IVs) influence the treatment, but not directly the outcome. An example would be links for marketing campaigns. The IV determines who will receive the links, while the treatment determines who of those would actually click on the link   \n",
    "We divide our approach in different parts. First, we'll generate some synthetic data for which we know the relationship between variables, as well as the treatment effect.   \n",
    "We'll use AutoCausality for hyperparameter tuning and model selection of a zoo of causal estimators. We'll do this for different scoring methods.\n",
    "Lastly, we'll plot the returned scores against the misestimation error between predicted and true treatment effect. \n",
    "Below, we import the relevant modules and define a few helper functions (TODO outsource the latter to autocausality, once approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
    "try:\n",
    "    import graphviz\n",
    "except ModuleNotFoundError as e:\n",
    "    import pip\n",
    "    pip.main([\"install\",\"graphviz\"])\n",
    "    import graphviz\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from auto_causality import AutoCausality\n",
    "from auto_causality.data_utils import preprocess_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observational Data: Instrumental Variables\n",
    "We will simulate data in which the outcome is influenced by the treatment and a set of covariates, which also affect the treatment. The treatment is influenced by an instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 6.0.1 (20220911.1526)\n -->\n<!-- Title: causal&#45;graph Pages: 1 -->\n<svg width=\"239pt\" height=\"204pt\"\n viewBox=\"0.00 0.00 239.40 204.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 200)\">\n<title>causal&#45;graph</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-200 235.4,-200 235.4,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_0</title>\n<polygon fill=\"none\" stroke=\"white\" points=\"8,-136 8,-188 122,-188 122,-136 8,-136\"/>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_1</title>\n<polygon fill=\"none\" stroke=\"white\" points=\"85,-64 85,-116 195,-116 195,-64 85,-64\"/>\n</g>\n<!-- X -->\n<g id=\"node1\" class=\"node\">\n<title>X</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"65\" cy=\"-162\" rx=\"49.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"65\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Covariates</text>\n</g>\n<!-- Y -->\n<g id=\"node2\" class=\"node\">\n<title>Y</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"102\" cy=\"-18\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"102\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outcome</text>\n</g>\n<!-- X&#45;&gt;Y -->\n<g id=\"edge1\" class=\"edge\">\n<title>X&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M66.4,-143.85C68.33,-124.21 72.58,-91.23 81,-64 82.97,-57.62 85.67,-50.99 88.48,-44.83\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"91.71,-46.19 92.89,-35.66 85.4,-43.15 91.71,-46.19\"/>\n</g>\n<!-- T -->\n<g id=\"node3\" class=\"node\">\n<title>T</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"140\" cy=\"-90\" rx=\"47.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"140\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Treatment</text>\n</g>\n<!-- X&#45;&gt;T -->\n<g id=\"edge3\" class=\"edge\">\n<title>X&#45;&gt;T</title>\n<path fill=\"none\" stroke=\"black\" d=\"M82.4,-144.76C92.21,-135.6 104.65,-124 115.44,-113.92\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.04,-116.29 122.96,-106.91 113.26,-111.17 118.04,-116.29\"/>\n</g>\n<!-- T&#45;&gt;Y -->\n<g id=\"edge2\" class=\"edge\">\n<title>T&#45;&gt;Y</title>\n<path fill=\"none\" stroke=\"black\" d=\"M130.8,-72.05C126.37,-63.89 120.95,-53.91 116.02,-44.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.96,-42.91 111.11,-35.79 112.81,-46.25 118.96,-42.91\"/>\n</g>\n<!-- I -->\n<g id=\"node4\" class=\"node\">\n<title>I</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"182\" cy=\"-162\" rx=\"49.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"182\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Instrument</text>\n</g>\n<!-- I&#45;&gt;T -->\n<g id=\"edge4\" class=\"edge\">\n<title>I&#45;&gt;T</title>\n<path fill=\"none\" stroke=\"black\" d=\"M171.83,-144.05C166.88,-135.8 160.82,-125.7 155.32,-116.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"158.22,-114.56 150.07,-107.79 152.22,-118.16 158.22,-114.56\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1525b7f9190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot = graphviz.Digraph(\"causal-graph\",comment=\"A simple causal graph with confounders\",filename=\"instrumental_variable_graph.gv\")\n",
    "dot.attr(rank=\"same\")\n",
    "with dot.subgraph(name=\"cluster_0\") as c:\n",
    "    c.attr(color=\"white\")\n",
    "    c.node(\"X\",label=\"Covariates\")\n",
    "dot.node(\"Y\",label=\"Outcome\")\n",
    "dot.edge(\"X\",\"Y\")\n",
    "with dot.subgraph(name=\"cluster_1\") as d:\n",
    "    d.attr(color=\"white\")\n",
    "    d.node(\"T\",label=\"Treatment\")\n",
    "dot.edge(\"T\",\"Y\")\n",
    "dot.edge(\"X\",\"T\")\n",
    "dot.node(\"I\",label=\"Instrument\")\n",
    "dot.edge(\"I\",\"T\")\n",
    "dot.edge_attr.update(arrowsize=\"1\")\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X^{Nxd}$ be the matrix of $N$ observations and $d$ covariates, $Z^{nx1}$ the vector of instruments, $T^{nx1}$ the vector of treatment assignments and $Y^{nx1}$ the vector of outcomes.   \n",
    "Let $C^{nx1}$ be the vector of compliers when recommended (when Z=1) and $C0^{nx1}$ the vector of non-compliers when not recommended (when Z==0)\n",
    "\n",
    "We make the following assumptions:  \n",
    "- binary instruments\n",
    "- binary treatments that depend on compliance with instrument\n",
    "- treatment allocation depends on the confounding covariates\n",
    "- five continuous, normally distributed covariates\n",
    "- constant treatment effect (ATE)\n",
    "- independence of the covariates, i.e. $\\Sigma = \\sigma^2I$\n",
    "- no additive noise in the outcomes, i.e. $\\epsilon=0$\n",
    "\n",
    "  \n",
    "Then, the data is generated according to the following equations:\n",
    "\\begin{align*}\n",
    "& X_i \\sim \\mathcal{N}(0,\\Sigma) \\\\\\\\\n",
    "& Z_i \\sim Bernoulli(0.5) \\\\\\\\\n",
    "& C_i \\sim Bernoulli \\left( 0.8 * \\frac{1}{1+exp(X_{i,1} \\otimes X_{i,2} + 3*X_{i,3})} \\right)  \\\\\\\\\n",
    "& C0_i \\sim Bernoulli(0.006) \\\\\\\\\n",
    "& T = C * Z + C0 * (1-Z) \\\\\\\\\n",
    "& Y_i = \\tau T_i + \\mu_0(X_i) + \\epsilon\n",
    "\\end{align*}\n",
    "where $i$ indexes individual units, $\\tau$ describes the following true treatment effect, which is constant (and set to 5 here):\n",
    "\\begin{equation*}\n",
    "\\tau = 5\n",
    "\\end{equation*}\n",
    "where $b$ is a 1xd vector of $b_i \\sim U(0.4,0.7)$ weights for each covariate and $e \\sim \\mathcal{N}(0,0.05)$ gaussian noise.  \n",
    "... and  $\\mu_0(x)$ describes the following transformation of the covariates (to keep things interesting):\n",
    "\\begin{equation*}\n",
    "\\mu_0(X_i) = X_{i,1} \\otimes X_{i,2} + X_{i,3} + X_{i,4} \\otimes X_{i,5} \n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psdmat(n_dims: int = 10) -> np.ndarray:\n",
    "    \"\"\"generates a symmetric, positive semidefinite matrix\n",
    "\n",
    "    Args:\n",
    "        n_dims (int, optional): number of dimensions. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: psd matrix\n",
    "    \"\"\"\n",
    "    A = np.random.rand(n_dims, n_dims)\n",
    "    A = A@A.T\n",
    "    \n",
    "    return A\n",
    "\n",
    "\n",
    "def mu_zero(X:np.ndarray) -> np.ndarray:\n",
    "    \"\"\"hard-coded transformation of covariates, including interaction terms\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): matrix of n observations and d covariates\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: transformed matrix\n",
    "    \"\"\"\n",
    "    return X[:,0] * X[:,1] + X[:,2] + X[:,3] * X[:,4]\n",
    "\n",
    "def generate_iv_data(\n",
    "    n_samples: int = 100,\n",
    "    n_covariates: int = 5,\n",
    "    covariance: Union[str, np.ndarray] = \"isotropic\",\n",
    "    confounding: bool = True,    \n",
    "    noisy_outcomes: bool = False,\n",
    "    effect_size: int = 5,\n",
    "\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"generates synthetic dataset with constant treatment effect (ATE) and instrumental variable\n",
    "\n",
    "    Args:\n",
    "        n_samples (int, optional): number of independent samples. Defaults to 100.\n",
    "        n_covariates (int, optional): number of covariates. Defaults to 5.\n",
    "        covariance (Union[str, np.ndarray], optional): covariance matrix of covariates. can be \"isotropic\", \"anisotropic\" or user-supplied. Defaults to \"isotropic\".\n",
    "        confounding (bool, optional): whether or not values of covariates affect treatment effect. Defaults to True.        \n",
    "        noisy_outcomes (bool, optional): additive noise in the outcomes. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: columns for covariates, treatment assignment, outcome and true treatment effect\n",
    "    \"\"\"\n",
    "\n",
    "    if covariance == \"isotropic\":\n",
    "        sigma = np.random.randn(1)\n",
    "        covmat = np.eye(n_covariates)*sigma**2\n",
    "    elif covariance == \"anisotropic\":\n",
    "        covmat = generate_psdmat(n_covariates)\n",
    "\n",
    "    X = np.random.multivariate_normal(mean=[0]*n_covariates,cov=covmat,size=n_samples)\n",
    "\n",
    "    Z = np.random.binomial(n=1,p=0.5, size=n_samples)\n",
    "    if confounding:\n",
    "        C = 1/(1+np.exp(X[:,0]*X[:,1]+X[:,2]*3)) > np.random.rand(n_samples)\n",
    "    else:\n",
    "        C = np.random.binomial(n=1, p=0.5,size=n_samples)\n",
    "\n",
    "    C0 = np.random.binomial(n=1, p=0.006, size=n_samples)\n",
    "\n",
    "    T = C*Z + C0*(1-Z)\n",
    "    # fixed effect size:    \n",
    "    tau = effect_size\n",
    "\n",
    "    err = np.random.randn(n_samples) *0.05 if noisy_outcomes else 0\n",
    "\n",
    "    Y = tau*T + mu_zero(X) + err\n",
    "\n",
    "    df = pd.DataFrame(np.array([*X.T,T,Y,Z,[tau]*n_samples]).T,columns=[f\"X{i}\" for i in range(1,n_covariates+1)]+[\"treatment\",\"outcome\",\"instrument\",\"true_effect\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Preprocessing\n",
    "Now we apply AutoCausality's built-in preprocessing pipeline and construct train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_X: ['X1', 'X2', 'X3', 'X4', 'X5']\n",
      "features_W: ['random']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>outcome</th>\n",
       "      <th>instrument</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>true_effect</th>\n",
       "      <th>random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.097335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071303</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>-0.101861</td>\n",
       "      <td>-0.068705</td>\n",
       "      <td>-0.014350</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.190518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>-0.180814</td>\n",
       "      <td>-0.174585</td>\n",
       "      <td>-0.119535</td>\n",
       "      <td>0.119284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.137171</td>\n",
       "      <td>0.016038</td>\n",
       "      <td>0.061607</td>\n",
       "      <td>0.086723</td>\n",
       "      <td>-0.072138</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.045862</td>\n",
       "      <td>-0.032304</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>-0.007094</td>\n",
       "      <td>-0.021779</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170421</td>\n",
       "      <td>-0.088367</td>\n",
       "      <td>0.041294</td>\n",
       "      <td>0.113269</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.068472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.216474</td>\n",
       "      <td>-0.040070</td>\n",
       "      <td>0.069139</td>\n",
       "      <td>-0.036047</td>\n",
       "      <td>0.259126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.036252</td>\n",
       "      <td>0.063922</td>\n",
       "      <td>-0.174873</td>\n",
       "      <td>-0.041275</td>\n",
       "      <td>-0.048097</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.024792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.054844</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.014928</td>\n",
       "      <td>-0.151229</td>\n",
       "      <td>-0.067149</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.886415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018581</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>-0.111298</td>\n",
       "      <td>-0.038987</td>\n",
       "      <td>0.060669</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.937912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060899</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>-0.062351</td>\n",
       "      <td>-0.030584</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment   outcome  instrument        X1        X2        X3        X4  \\\n",
       "0        0.0 -0.097335         0.0  0.071303  0.049645 -0.101861 -0.068705   \n",
       "1        0.0 -0.190518         0.0  0.009258 -0.180814 -0.174585 -0.119535   \n",
       "2        0.0  0.057551         1.0  0.137171  0.016038  0.061607  0.086723   \n",
       "3        0.0  0.052980         1.0  0.045862 -0.032304  0.054307 -0.007094   \n",
       "4        0.0  0.026186         0.0  0.170421 -0.088367  0.041294  0.113269   \n",
       "5        1.0  5.068472         1.0 -0.216474 -0.040070  0.069139 -0.036047   \n",
       "6        0.0 -0.175205         0.0 -0.036252  0.063922 -0.174873 -0.041275   \n",
       "7        1.0  5.024792         1.0 -0.054844  0.005307  0.014928 -0.151229   \n",
       "8        1.0  4.886415         1.0  0.018581  0.004211 -0.111298 -0.038987   \n",
       "9        1.0  4.937912         1.0  0.060899  0.043737 -0.062351 -0.030584   \n",
       "\n",
       "         X5  true_effect  random  \n",
       "0 -0.014350          5.0     0.0  \n",
       "1  0.119284          5.0     1.0  \n",
       "2 -0.072138          5.0     1.0  \n",
       "3 -0.021779          5.0     0.0  \n",
       "4 -0.000426          5.0     1.0  \n",
       "5  0.259126          5.0     1.0  \n",
       "6 -0.048097          5.0     0.0  \n",
       "7 -0.067149          5.0     1.0  \n",
       "8  0.060669          5.0     0.0  \n",
       "9  0.078500          5.0     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_iv_data(n_samples=1000,confounding=True)\n",
    "outcome = \"outcome\"\n",
    "data_df, features_X, features_W = preprocess_dataset(data, treatment=\"treatment\", targets=[\"outcome\"], instruments=[\"instrument\"])\n",
    "# drop true effect:\n",
    "features_X = [f for f in features_X if f != \"true_effect\"]\n",
    "print(f\"features_X: {features_X}\")\n",
    "print(f\"features_W: {features_W}\")\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(data_df, test_size=0.2)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Model fitting\n",
    "Now we're ready to find the best fitting model, given a user-specified metric. As we'd like to compare different metrics, we'll be doing this in a for-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"energy_distance\"]\n",
    "\n",
    "# train_df, test_df = train_test_split(data_df, test_size=0.2)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "\n",
    "    ac = AutoCausality(\n",
    "        metric=metric, verbose=1, components_verbose=1, components_time_budget=60,\n",
    "    )\n",
    "\n",
    "    ac.fit(\n",
    "        train_df,\n",
    "        treatment=\"treatment\",\n",
    "        outcome=\"outcome\",\n",
    "        instruments=[\"instrument\"],\n",
    "        common_causes=features_W,\n",
    "        effect_modifiers=features_X,\n",
    "    )\n",
    "    scores = {}\n",
    "    # compute relevant scores (skip newdummy)\n",
    "    for est_name, scr in ac.scores.items():\n",
    "        if \"NewDummy\" not in est_name:\n",
    "\n",
    "            causal_estimate = scr[\"estimator\"]\n",
    "\n",
    "            scr[\"scores\"][\"test\"] = ac.scorer.make_scores(\n",
    "                causal_estimate,\n",
    "                test_df,\n",
    "                problem=ac.problem,\n",
    "                metrics_to_report=ac.metrics_to_report,\n",
    "            )\n",
    "            \n",
    "            # add ground truth for convenience\n",
    "            scr[\"scores\"][\"test\"][\"ATE_groundtruth\"] = test_df[\"true_effect\"]\n",
    "            scr[\"scores\"][\"test\"][\"ATE_est\"] = scr[\"estimator\"].estimator.effect(test_df).mean()\n",
    "            scores[est_name] = scr[\"scores\"][\"test\"]\n",
    "\n",
    "    results = {\n",
    "        \"best_estimator\": ac.best_estimator,\n",
    "        \"best_config\": ac.best_config,\n",
    "        \"best_score\": ac.best_score,\n",
    "        \"optimised_metric\": metric,\n",
    "        \"scores_per_estimator\": scores,\n",
    "    }\n",
    "    with open(\"synthetic_observational_instrument_\" + metric + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Evaluation\n",
    "How well did the different metrics quantify the mismatch between estimated and true treatment effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "colors = ([matplotlib.colors.CSS4_COLORS['black']] +\n",
    "    list(matplotlib.colors.TABLEAU_COLORS) + [\n",
    "    matplotlib.colors.CSS4_COLORS['lime'],\n",
    "    matplotlib.colors.CSS4_COLORS['yellow'],\n",
    "    matplotlib.colors.CSS4_COLORS['pink']\n",
    "])\n",
    "\n",
    "for metric in [\"energy_distance\"]:\n",
    "    with open(\"synthetic_observational_instrument_\"+metric+\".pkl\",\"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for (est_name, scr), col in zip(ac.scores.items(),colors):\n",
    "        if \"NewDummy\" in est_name:\n",
    "            pass\n",
    "        else:\n",
    "            true_ate = scr[\"scores\"][\"test\"][\"ATE_groundtruth\"][0]\n",
    "            estimated_ate = scr[\"scores\"][\"test\"][\"ATE_est\"]\n",
    "            mse = np.mean((true_ate-estimated_ate)**2)\n",
    "            plt.scatter(mse,scr[\"scores\"][\"test\"][metric],color=col)\n",
    "    plt.xlabel(\"MSE(ate_hat, ate)\")\n",
    "    plt.ylabel(ac.metric)\n",
    "    plt.legend([k.split(\".\")[-1] for k in ac.scores.keys() if \"NewDummy\" not in k],loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('autocausality')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d738b306ac6f08f90dfb29051c15b9a8f4fea312b55b05a4c05e42fcf3ab44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
