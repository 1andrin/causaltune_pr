{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308c1a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this makes the notebook expand to full width of the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2d83a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "// turn off scrollable windows for too large output\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "// turn off scrollable windows for too large output\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egor.kraev\\Transferwise\\auto-causality\\data\\example\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cloudpickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "\n",
    "# set this path to differ by project\n",
    "data_dir = os.path.realpath(os.path.join(root_path, \"auto-causality/data/example\"))\n",
    "\n",
    "parent = os.path.realpath(os.path.join(data_dir, \"..\"))\n",
    "if not os.path.isdir(parent):\n",
    "    os.mkdir(parent)\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ceab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are using dowhy and this repo by just pulling the source\n",
    "sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
    "sys.path.append(os.path.join(root_path, \"auto-causality\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8de5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\anaconda3\\envs\\autocausality\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "from auto_causality.utils import featurize,AutoMLWrapper\n",
    "from auto_causality.params import SimpleParamService\n",
    "from auto_causality.scoring import make_scores, ate, group_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9331f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment       int64\n",
       "y_factual     float64\n",
       "y_cfactual    float64\n",
       "mu0           float64\n",
       "mu1           float64\n",
       "x1            float64\n",
       "x2            float64\n",
       "x3            float64\n",
       "x4            float64\n",
       "x5            float64\n",
       "x6            float64\n",
       "x7              int64\n",
       "x8              int64\n",
       "x9              int64\n",
       "x10             int64\n",
       "x11             int64\n",
       "x12             int64\n",
       "x13             int64\n",
       "x14             int64\n",
       "x15             int64\n",
       "x16             int64\n",
       "x17             int64\n",
       "x18             int64\n",
       "x19             int64\n",
       "x20             int64\n",
       "x21             int64\n",
       "x22             int64\n",
       "x23             int64\n",
       "x24             int64\n",
       "x25             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "      <td>3.268256</td>\n",
       "      <td>6.854457</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  y_factual  y_cfactual       mu0       mu1        x1        x2  \\\n",
       "0          1   5.599916    4.318780  3.268256  6.854457 -0.528603 -0.343455   \n",
       "1          0   6.875856    7.856495  6.636059  7.562718 -1.736945 -1.802002   \n",
       "2          0   2.996273    6.633952  1.570536  6.121617 -0.807451 -0.202946   \n",
       "3          0   1.366206    5.697239  1.244738  5.889125  0.390083  0.596582   \n",
       "4          0   1.963538    6.202582  1.685048  6.191994 -1.045229 -0.602710   \n",
       "\n",
       "         x3        x4        x5  ...  x16  x17  x18  x19  x20  x21  x22  x23  \\\n",
       "0  1.128554  0.161703 -0.316603  ...    1    1    1    1    0    0    0    0   \n",
       "1  0.383828  2.244320 -0.629189  ...    1    1    1    1    0    0    0    0   \n",
       "2 -0.360898 -0.879606  0.808706  ...    1    0    1    1    0    0    0    0   \n",
       "3 -1.850350 -0.879606 -0.004017  ...    1    0    1    1    0    0    0    0   \n",
       "4  0.011465  0.161703  0.683672  ...    1    1    1    1    0    0    0    0   \n",
       "\n",
       "   x24  x25  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data\n",
    "data= pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\", header = None)\n",
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ,]\n",
    "for i in range(1,26):\n",
    "    col.append(\"x\"+str(i))\n",
    "data.columns = col\n",
    "\n",
    "display(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1667d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns we don't care about\n",
    "ignore_patterns = ['y_cfactual','mu']\n",
    "ignore_cols = [c for c in data.columns if any([s in c for s in ignore_patterns])]\n",
    "data = data.drop(columns=ignore_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0113ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the control parameters here\n",
    "train_size = 0.5\n",
    "test_size = None\n",
    "time_budget = 60\n",
    "num_cores = os.cpu_count() -4\n",
    "conf_intervals=False\n",
    "\n",
    "# Only change the n_bootstrap_samples (to at least 20) if you want\n",
    "# confidence intervals specifically for metalearner models\n",
    "# warning: that will be VERY slow!\n",
    "n_bootstrap_samples = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f020527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "treatment = \"treatment\"\n",
    "targets = [\"y_factual\"] # it's good to allow multiple ones\n",
    "features = [c for c in data.columns if c not in [treatment] + targets]\n",
    "\n",
    "data[treatment] = data[treatment].astype(int)\n",
    "# this is a trick to bypass some DoWhy/EconML bugs\n",
    "data[\"random\"] = np.random.randint(0, 2, size=len(data))\n",
    "\n",
    "used_df = featurize(\n",
    "        data,\n",
    "        features=features,\n",
    "        exclude_cols=[treatment] + targets,\n",
    "        drop_first=False,\n",
    "    )\n",
    "used_features = [\n",
    "        c for c in used_df.columns if c not in ignore_cols + [treatment] + targets\n",
    "    ]\n",
    "\n",
    "\n",
    "# Let's treat all features as effect modifiers\n",
    "features_X = [f for f in used_features if f != \"random\"]\n",
    "features_W = [f for f in used_features if f not in features_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb6bb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isfile(os.path.join(data_dir, f\"test_{time_budget}.csv\")) and\n",
    "        os.path.isfile(os.path.join(data_dir, f\"train_{time_budget}.csv\"))):\n",
    "    train_df, test_df = train_test_split(used_df, train_size=train_size)\n",
    "    if test_size is not None:\n",
    "        test_df = test_df.sample(test_size)\n",
    "    test_df.to_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "    train_df.to_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n",
    "else:\n",
    "    test_df = pd.read_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n",
    "        \n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parametrization\n",
    "propensity_model = DummyClassifier(strategy=\"prior\")\n",
    "outcome_model = AutoMLWrapper(\n",
    "    fit_params={\n",
    "        \"time_budget\": time_budget,\n",
    "        \"verbose\": 1,\n",
    "        \"task\": \"regression\",\n",
    "        \"n_jobs\": num_cores,\n",
    "        \"pred_time_limit\": 10 / 1e6,\n",
    "    }\n",
    ")\n",
    "\n",
    "cfg = SimpleParamService(\n",
    "    propensity_model,\n",
    "    outcome_model,\n",
    "    n_bootstrap_samples=n_bootstrap_samples,\n",
    "    min_leaf_size=2*len(used_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b034c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_factual\n",
      "fitting backdoor.econml.metalearners.TLearner {'init_params': {'models': <auto_causality.utils.AutoMLWrapper object at 0x000001A6D6A3C430>}, 'fit_params': {}}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.7067899869844037 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n",
      "manual mean impact: 3.7067899869844037 3.605932873479594 std: 0.0539277907612137\n",
      "Scores for backdoor.econml.metalearners.TLearner_y_factual 6.339885315898782 6.55697691313854\n",
      "dumping...\n",
      "yahoo!\n",
      "fitting backdoor.econml.metalearners.XLearner {'init_params': {'propensity_model': DummyClassifier(), 'models': <auto_causality.utils.AutoMLWrapper object at 0x000001A6D800D1C0>}, 'fit_params': {}}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.8069074490401125 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n",
      "manual mean impact: 3.8069074490401125 3.7696412305003046 std: 0.0275617199227258\n",
      "Scores for backdoor.econml.metalearners.XLearner_y_factual 6.318419841333325 6.566009170312499\n",
      "dumping...\n",
      "yahoo!\n",
      "fitting backdoor.econml.metalearners.DomainAdaptationLearner {'init_params': {'propensity_model': DummyClassifier(), 'models': <auto_causality.utils.AutoMLWrapper object at 0x000001A6DF600A90>, 'final_models': <auto_causality.utils.AutoMLWrapper object at 0x000001A6DF600DF0>}, 'fit_params': {}}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.773495572861334 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n",
      "manual mean impact: 3.773495572861334 3.716015421053305 std: 0.05069143289787579\n",
      "Scores for backdoor.econml.metalearners.DomainAdaptationLearner_y_factual 6.346495846461864 6.536791450419653\n",
      "dumping...\n",
      "yahoo!\n",
      "fitting backdoor.econml.dr.ForestDRLearner {'init_params': {'model_propensity': DummyClassifier(), 'model_regression': <auto_causality.utils.AutoMLWrapper object at 0x000001A6DF61F3A0>, 'max_depth': 10, 'n_estimators': 500}, 'fit_params': {}}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n",
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.85696648288917 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n",
      "manual mean impact: 3.85696648288917 3.8391422064626415 std: 0.02593803799679443\n",
      "Scores for backdoor.econml.dr.ForestDRLearner_y_factual 6.318419841333325 6.566009170312499\n",
      "dumping...\n",
      "yahoo!\n",
      "fitting backdoor.econml.dr.LinearDRLearner {'init_params': {'model_propensity': DummyClassifier(), 'model_regression': <auto_causality.utils.AutoMLWrapper object at 0x000001A6E092B400>}, 'fit_params': {}}\n",
      "calling AutoML fit method with  {'time_budget': 60, 'verbose': 1, 'task': 'regression', 'n_jobs': 8, 'pred_time_limit': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# and now let's fit some models!\n",
    "\n",
    "for outcome in targets:  \n",
    "    print(outcome)\n",
    "    model = CausalModel(\n",
    "        data=train_df,\n",
    "        treatment=treatment,\n",
    "        outcome=outcome,\n",
    "        common_causes=features_W,\n",
    "        effect_modifiers=features_X,\n",
    "    )\n",
    "    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "    \n",
    "    estimates = {}\n",
    "    eis ={}\n",
    "    for estimator in cfg.estimators():\n",
    "        if not any(\n",
    "            [\n",
    "                e in estimator\n",
    "                for e in [\n",
    "                    \"causality\",\n",
    "                    \"metalearners\",\n",
    "                    \"CausalForestDML\",\n",
    "                    \".LinearDML\",\n",
    "                    \"SparseLinearDML\",\n",
    "                    \"ForestDRLearner\",\n",
    "                    \"LinearDRLearner\",\n",
    "                    \"Ortho\"\n",
    "                ]\n",
    "            ]\n",
    "        ):  \n",
    "            continue\n",
    "            \n",
    "        scores_fname = os.path.join(data_dir, f\"scores_{estimator}_{outcome}_{time_budget}.zip\")\n",
    "        model_fname = os.path.join(data_dir, f\"model_{estimator}_{outcome}_{time_budget}.zip\")\n",
    "        if os.path.isfile(scores_fname) and os.path.isfile(model_fname):\n",
    "            continue\n",
    "\n",
    "        method_params = cfg.method_params(estimator)\n",
    "        print(\"fitting\", estimator, method_params)\n",
    "\n",
    "        estimates[estimator] = model.estimate_effect(\n",
    "            identified_estimand,\n",
    "            method_name=estimator,\n",
    "            control_value=0,\n",
    "            treatment_value=1,\n",
    "            target_units=\"ate\",  # condition used for CATE\n",
    "            confidence_intervals=conf_intervals,\n",
    "            method_params=method_params,\n",
    "        )\n",
    "\n",
    "        estimates[estimator].interpret()\n",
    "\n",
    "        if conf_intervals:\n",
    "            X_train = train_df[estimates[estimator].estimator._effect_modifier_names]\n",
    "            est_obj = estimates[estimator].estimator.estimator\n",
    "            eis[estimator] = est_obj.effect_inference(X_train)\n",
    "            print(eis[estimator].population_summary())\n",
    "        else:\n",
    "            eis[estimator] = None\n",
    "\n",
    "        try:\n",
    "            te_train = estimates[estimator].cate_estimates\n",
    "            X_test = test_df[estimates[estimator].estimator._effect_modifier_names] \n",
    "            te_test = estimates[estimator].estimator.estimator.effect(X_test).flatten()\n",
    "            print(\n",
    "                \"manual mean impact:\",\n",
    "                te_train.mean(),\n",
    "                te_test.mean(),\n",
    "                \"std:\",\n",
    "                te_train.std()/np.sqrt(len(te_train)),\n",
    "            )\n",
    "        except:\n",
    "            te_train = estimates[estimator].estimator.effect(train_df)\n",
    "            te_test = estimates[estimator].estimator.effect(test_df)\n",
    "\n",
    "        scores = {\n",
    "            \"estimator\": estimator,\n",
    "            \"outcome\": outcome,\n",
    "            \"train\": make_scores(estimates[estimator], train_df, te_train),\n",
    "            \"test\": make_scores(estimates[estimator], test_df, te_test),\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            f\"Scores for {estimator}_{outcome}\",\n",
    "            scores[\"train\"][\"erupt\"],\n",
    "            scores[\"test\"][\"erupt\"],\n",
    "        )\n",
    "\n",
    "        print(\"dumping...\")\n",
    "\n",
    "        with gzip.open(scores_fname, \"wb\") as f:\n",
    "            cloudpickle.dump(scores, f)\n",
    "            \n",
    "        with gzip.open(model_fname, \"wb\") as f:\n",
    "            cloudpickle.dump(estimates[estimator], f)\n",
    "\n",
    "        print(\"yahoo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a baseline calculation\n",
    "train_df = pd.read_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "\n",
    "scores = defaultdict(lambda:defaultdict(dict))\n",
    "for outcome in targets:\n",
    "    scores[outcome][\"baseline\"]={\"estimator\": \"baseline\",\n",
    "                               \"outcome\": outcome,\n",
    "                              \"train\":{\"erupt\": train_df[outcome].mean(),\n",
    "                                       \"ate\": ate(train_df[treatment],train_df[outcome])[0]},\n",
    "                              \"test\":{\"erupt\": test_df[outcome].mean(),\n",
    "                                      \"ate\": ate(test_df[treatment],test_df[outcome])[0]}}\n",
    "                              \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb71a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "for outcome in targets:\n",
    "    print(outcome)\n",
    "    for estimator in cfg.estimators():\n",
    "        try:\n",
    "            fname = os.path.join(data_dir, f\"scores_{estimator}_*_{time_budget}.zip\")\n",
    "            files = glob.glob(fname)\n",
    "            if not len(files):\n",
    "                continue\n",
    "            with gzip.open(files[0], \"rb\") as f:\n",
    "                scores[outcome][estimator] = dill.load(f)\n",
    "                print(estimator, \"score:\", scores[outcome][estimator])\n",
    "        except Exception as e:\n",
    "            display(e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "colors = ([matplotlib.colors.CSS4_COLORS['black']] +\n",
    "    list(matplotlib.colors.TABLEAU_COLORS) + [\n",
    "    matplotlib.colors.CSS4_COLORS['lime'],\n",
    "    matplotlib.colors.CSS4_COLORS['yellow'],\n",
    "    matplotlib.colors.CSS4_COLORS['pink']\n",
    "])\n",
    "\n",
    "for outcome, v in scores.items():\n",
    "    plt.figure(figsize = (7,5))\n",
    "    plt.title(outcome)\n",
    "    for (est, scr),col in zip(v.items(),colors):\n",
    "        sc = [scr['train']['erupt'], scr['test']['erupt']]\n",
    "        crv = [scr['train']['ate'], scr['test']['ate']]\n",
    "        plt.plot(sc, crv, color=col, marker=\"o\")\n",
    "        plt.scatter(sc[1:],crv[1:], c=col, s=120 )\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"ERUPT score\")\n",
    "        plt.ylabel(\"ATE\")\n",
    "        plt.legend(v.keys(),bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "        \n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for outcome, v in scores.items():\n",
    "    for est, scr in v.items():\n",
    "        if est == 'baseline':\n",
    "            continue\n",
    "        intrp = scr['test']['intrp']\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        try: \n",
    "            feature_names = intrp.feature_names\n",
    "        except:\n",
    "            feature_names = features_X + [ w for w in features_W if w not in features_X]\n",
    "        intrp.plot(feature_names=intrp.feature_names, fontsize=10)\n",
    "#         intrp.plot( fontsize=10)\n",
    "        plt.title(f\"{estimator}_{outcome}\")\n",
    "        plt.show()\n",
    "        # remove the 'break' if you want to see all simple policies\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "def load_model(data_dir: str, estimator:str, outcome: str, time_budget:str):\n",
    "    new_fn = os.path.join(data_dir, f\"model_{estimator}_{outcome}_{time_budget}.zip\")\n",
    "    print('loading', new_fn)\n",
    "    with gzip.open(new_fn, \"rb\") as f:\n",
    "        model = cloudpickle.load(f)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add SHAP plots!\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# and now let's visualize feature importances!\n",
    "from auto_causality.shap import shap_values\n",
    "\n",
    "# Shapley values calculation can be slow so let's subsample\n",
    "this_df = test_df.sample(100)\n",
    "\n",
    "wanted = [\"CausalForestDML\"]#,\"ForestDRLearner\",\"DirectUpliftDoWhyWrapper\"]#,\"CausalForestDML\",]\n",
    "\n",
    "for outcome, v in scores.items():\n",
    "    for estimator, scr in v.items():\n",
    "        if not any([e in estimator for e in wanted]):\n",
    "            continue\n",
    "        print(outcome, estimator)\n",
    "        est = load_model(data_dir, estimator, outcome, time_budget)\n",
    "        shaps = shap_values(est, this_df)\n",
    "\n",
    "        plt.title(outcome + '_' + estimator.split('.')[-1])\n",
    "        shap.summary_plot(shaps, this_df[est.estimator._effect_modifier_names])\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a987d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out-of sample difference of outcomes between treated and untreated for the points where a model predicts positive vs negative impact\n",
    "\n",
    "for my_est in [e for e in scores[targets[0]].keys() if e != 'baseline']:\n",
    "    stats = []\n",
    "    for outcome in targets:\n",
    "        if 'test' not in scores[outcome][my_est]:\n",
    "            continue\n",
    "        v = scores[outcome][my_est]['test']['values']\n",
    "        stats.append(group_ate(v['treated'], v[outcome], v['policy']))\n",
    "\n",
    "    sts = pd.DataFrame(stats)\n",
    "    sts\n",
    "\n",
    "\n",
    "    colors = (matplotlib.colors.CSS4_COLORS['black'],\n",
    "        matplotlib.colors.CSS4_COLORS['red'],\n",
    "        matplotlib.colors.CSS4_COLORS['blue'])\n",
    "    grp = ['all', 'pos','neg']\n",
    "\n",
    "    for i,(g,c) in enumerate(zip(grp, colors)):\n",
    "        plt.errorbar(np.array(range(len(sts))) +0.1*i, sts[f\"{g}_mean\"],  yerr = sts[f\"{g}_std\"], color=c)\n",
    "    plt.legend(grp)\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(len(sts)), targets)\n",
    "    plt.title(my_est.split('.')[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a157d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
