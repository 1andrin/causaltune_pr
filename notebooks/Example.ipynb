{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egor.kraev\\Transferwise\\auto-causality\\data\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import dill\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "data_dir = os.path.realpath(os.path.join(root_path, \"auto-causality/data\"))\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ceab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are using dowhy and this repo by just pulling the source\n",
    "sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
    "sys.path.append(os.path.join(root_path, \"auto-causality\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8de5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "from auto_causality.utils import featurize, AutoMLWrapper\n",
    "from auto_causality.params import SimpleParamService\n",
    "from auto_causality.scoring import make_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9331f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "treatment       int64\n",
       "y_factual     float64\n",
       "y_cfactual    float64\n",
       "mu0           float64\n",
       "mu1           float64\n",
       "x1            float64\n",
       "x2            float64\n",
       "x3            float64\n",
       "x4            float64\n",
       "x5            float64\n",
       "x6            float64\n",
       "x7              int64\n",
       "x8              int64\n",
       "x9              int64\n",
       "x10             int64\n",
       "x11             int64\n",
       "x12             int64\n",
       "x13             int64\n",
       "x14             int64\n",
       "x15             int64\n",
       "x16             int64\n",
       "x17             int64\n",
       "x18             int64\n",
       "x19             int64\n",
       "x20             int64\n",
       "x21             int64\n",
       "x22             int64\n",
       "x23             int64\n",
       "x24             int64\n",
       "x25             int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_factual</th>\n",
       "      <th>y_cfactual</th>\n",
       "      <th>mu0</th>\n",
       "      <th>mu1</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>...</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.599916</td>\n",
       "      <td>4.318780</td>\n",
       "      <td>3.268256</td>\n",
       "      <td>6.854457</td>\n",
       "      <td>-0.528603</td>\n",
       "      <td>-0.343455</td>\n",
       "      <td>1.128554</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-0.316603</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6.875856</td>\n",
       "      <td>7.856495</td>\n",
       "      <td>6.636059</td>\n",
       "      <td>7.562718</td>\n",
       "      <td>-1.736945</td>\n",
       "      <td>-1.802002</td>\n",
       "      <td>0.383828</td>\n",
       "      <td>2.244320</td>\n",
       "      <td>-0.629189</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.996273</td>\n",
       "      <td>6.633952</td>\n",
       "      <td>1.570536</td>\n",
       "      <td>6.121617</td>\n",
       "      <td>-0.807451</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.808706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.366206</td>\n",
       "      <td>5.697239</td>\n",
       "      <td>1.244738</td>\n",
       "      <td>5.889125</td>\n",
       "      <td>0.390083</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-1.850350</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.963538</td>\n",
       "      <td>6.202582</td>\n",
       "      <td>1.685048</td>\n",
       "      <td>6.191994</td>\n",
       "      <td>-1.045229</td>\n",
       "      <td>-0.602710</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>0.683672</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  y_factual  y_cfactual       mu0       mu1        x1        x2  \\\n",
       "0          1   5.599916    4.318780  3.268256  6.854457 -0.528603 -0.343455   \n",
       "1          0   6.875856    7.856495  6.636059  7.562718 -1.736945 -1.802002   \n",
       "2          0   2.996273    6.633952  1.570536  6.121617 -0.807451 -0.202946   \n",
       "3          0   1.366206    5.697239  1.244738  5.889125  0.390083  0.596582   \n",
       "4          0   1.963538    6.202582  1.685048  6.191994 -1.045229 -0.602710   \n",
       "\n",
       "         x3        x4        x5  ...  x16  x17  x18  x19  x20  x21  x22  x23  \\\n",
       "0  1.128554  0.161703 -0.316603  ...    1    1    1    1    0    0    0    0   \n",
       "1  0.383828  2.244320 -0.629189  ...    1    1    1    1    0    0    0    0   \n",
       "2 -0.360898 -0.879606  0.808706  ...    1    0    1    1    0    0    0    0   \n",
       "3 -1.850350 -0.879606 -0.004017  ...    1    0    1    1    0    0    0    0   \n",
       "4  0.011465  0.161703  0.683672  ...    1    1    1    1    0    0    0    0   \n",
       "\n",
       "   x24  x25  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    0    0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw data\n",
    "data= pd.read_csv(\"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\", header = None)\n",
    "col =  [\"treatment\", \"y_factual\", \"y_cfactual\", \"mu0\", \"mu1\" ,]\n",
    "for i in range(1,26):\n",
    "    col.append(\"x\"+str(i))\n",
    "data.columns = col\n",
    "\n",
    "display(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1667d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns we don't care about\n",
    "ignore_patterns = ['y_cfactual','mu']\n",
    "ignore_cols = [c for c in data.columns if any([s in c for s in ignore_patterns])]\n",
    "data = data.drop(columns=ignore_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0113ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the control parameters here\n",
    "train_size = 0.5\n",
    "test_size = None\n",
    "time_budget = 60\n",
    "num_cores = os.cpu_count() - 1\n",
    "conf_intervals = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f020527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "treatment = \"treatment\"\n",
    "targets = [\"y_factual\"] # it's good to allow multiple ones\n",
    "features = [c for c in data.columns if c not in [treatment] + targets]\n",
    "\n",
    "data[treatment] = data[treatment].astype(int)\n",
    "# this is a trick to bypass some DoWhy/EconML bugs\n",
    "data[\"random\"] = np.random.randint(0, 2, size=len(data))\n",
    "\n",
    "used_df = featurize(\n",
    "        data,\n",
    "        features=features,\n",
    "        exclude_cols=[treatment] + targets,\n",
    "        drop_first=False,\n",
    "    )\n",
    "used_features = [\n",
    "        c for c in used_df.columns if c not in ignore_cols + [treatment] + targets\n",
    "    ]\n",
    "\n",
    "\n",
    "# Let's treat all features as effect modifiers\n",
    "features_X = [f for f in used_features if f != \"random\"]\n",
    "features_W = [f for f in used_features if f not in features_X]\n",
    "\n",
    "train_df, test_df = train_test_split(used_df, train_size=train_size)\n",
    "if test_size is not None:\n",
    "    test_df = test_df.sample(test_size)\n",
    "\n",
    "test_df.to_csv(os.path.join(data_dir, f\"crm_test_{time_budget}.csv\"))\n",
    "train_df.to_csv(os.path.join(data_dir, f\"crm_train_{time_budget}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parametrization\n",
    "propensity_model = DummyClassifier(strategy=\"prior\")\n",
    "outcome_model = AutoMLWrapper(\n",
    "    fit_params={\n",
    "        \"time_budget\": time_budget,\n",
    "        \"verbose\": 1,\n",
    "        \"task\": \"regression\",\n",
    "        \"n_jobs\": num_cores,\n",
    "        \"pred_time_limit\": 10 / 1e6,\n",
    "    }\n",
    ")\n",
    "\n",
    "cfg = SimpleParamService(\n",
    "    propensity_model,\n",
    "    outcome_model,\n",
    "    conf_intervals=conf_intervals,\n",
    "    n_bootstrap_samples=20,\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_leaf_size=2*len(used_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b034c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_factual\n",
      "fitting backdoor.econml.orf.DROrthoForest {'init_params': {'propensity_model': DummyClassifier(), 'model_Y': Ridge(alpha=0.01), 'n_jobs': None, 'max_depth': 10, 'n_trees': 500, 'min_leaf_size': 52, 'backend': 'threading'}, 'fit_params': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.848690359468098 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual mean impact: 3.848690359468098 3.9524937605756847 std: 1.1927819517356248\n",
      "Scores for backdoor.econml.orf.DROrthoForest_y_factual 6.427314264569056 6.445663412910029\n",
      "dumping...\n",
      "yahoo!\n",
      "fitting backdoor.econml.orf.DMLOrthoForest {'init_params': {'model_T': DummyClassifier(), 'model_Y': Ridge(alpha=0.01), 'discrete_treatment': True, 'n_jobs': None, 'max_depth': 10, 'n_trees': 500, 'min_leaf_size': 52, 'backend': 'threading'}, 'fit_params': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 373 out of 373 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 3.395061735460179 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 374 out of 374 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual mean impact: 3.395061735460179 3.533415345365768 std: 1.1107348908840942\n",
      "Scores for backdoor.econml.orf.DMLOrthoForest_y_factual 6.411460340797122 6.465227217203946\n",
      "dumping...\n",
      "yahoo!\n"
     ]
    }
   ],
   "source": [
    "# and now let's fit some models!\n",
    "\n",
    "for outcome in targets:  \n",
    "    print(outcome)\n",
    "    model = CausalModel(\n",
    "        data=train_df,\n",
    "        treatment=treatment,\n",
    "        outcome=outcome,\n",
    "        common_causes=features_W,\n",
    "        effect_modifiers=features_X,\n",
    "    )\n",
    "    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "    \n",
    "    estimates = {}\n",
    "    eis ={}\n",
    "    for estimator in cfg.estimators():\n",
    "        if not any(\n",
    "            [\n",
    "                e in estimator\n",
    "                for e in [\n",
    "                    \"causality\",\n",
    "                    \"metalearners\",\n",
    "                    \"CausalForestDML\",\n",
    "                    \"LinearDML\",\n",
    "                    \"SparseLinearDML\"\n",
    "                    \"ForestDRLearner\",\n",
    "                    \"LinearDRLearner\",\n",
    "                    \"Ortho\"\n",
    "                ]\n",
    "            ]\n",
    "        ):  \n",
    "            continue\n",
    "\n",
    "        method_params = cfg.method_params(estimator)\n",
    "        print(\"fitting\", estimator, method_params)\n",
    "\n",
    "        estimates[estimator] = model.estimate_effect(\n",
    "            identified_estimand,\n",
    "            method_name=estimator,\n",
    "            control_value=0,\n",
    "            treatment_value=1,\n",
    "            target_units=\"ate\",  # condition used for CATE\n",
    "            confidence_intervals=conf_intervals,\n",
    "            method_params=method_params,\n",
    "        )\n",
    "\n",
    "        estimates[estimator].interpret()\n",
    "\n",
    "        if conf_intervals:\n",
    "            X_train = train_df[estimates[estimator].estimator._effect_modifier_names]\n",
    "            est_obj = estimates[estimator].estimator.estimator\n",
    "            eis[estimator] = est_obj.effect_inference(X_train)\n",
    "            print(eis[estimator].population_summary())\n",
    "        else:\n",
    "            eis[estimator] = None\n",
    "\n",
    "        try:\n",
    "            te_train = estimates[estimator].cate_estimates\n",
    "            X_test = test_df[estimates[estimator].estimator._effect_modifier_names] \n",
    "            te_test = estimates[estimator].estimator.estimator.effect(X_test).flatten()\n",
    "            print(\n",
    "                \"manual mean impact:\",\n",
    "                te_train.mean(),\n",
    "                te_test.mean(),\n",
    "                \"std:\",\n",
    "                te_train.std(),\n",
    "            )\n",
    "        except:\n",
    "            te_train = estimates[estimator].estimator.effect(train_df)\n",
    "            te_test = estimates[estimator].estimator.effect(test_df)\n",
    "\n",
    "        scores = {\n",
    "            \"estimator\": estimator,\n",
    "            \"outcome\": outcome,\n",
    "            \"train\": make_scores(model, train_df, te_train),\n",
    "            \"test\": make_scores(model, test_df, te_test),\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            f\"Scores for {estimator}_{outcome}\",\n",
    "            scores[\"train\"][\"erupt\"],\n",
    "            scores[\"test\"][\"erupt\"],\n",
    "        )\n",
    "\n",
    "        print(\"dumping...\")\n",
    "        fname = os.path.join(\n",
    "            data_dir, f\"scores_{estimator}_{outcome[-3:]}_{time_budget}.zip\"\n",
    "        )\n",
    "        with gzip.open(fname, \"wb\") as f:\n",
    "            dill.dump(scores, f)\n",
    "        fname = os.path.join(\n",
    "            data_dir, f\"model_{estimator}_{outcome[-3:]}_{time_budget}.zip\"\n",
    "        )\n",
    "        with gzip.open(fname, \"wb\") as f:\n",
    "            dill.dump(estimates[estimator], f)\n",
    "\n",
    "        print(\"yahoo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add decision tree and SHAP plots!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
