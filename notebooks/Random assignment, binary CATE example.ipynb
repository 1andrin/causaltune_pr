{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a34f30c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random assignment, binary CATE example\n",
    "\n",
    "This is a fully worked-out notebook showing how you would apply auto-causality to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6eaac69",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the below checks for whether we run dowhy, auto-causality, and FLAML from source\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "try:\n",
    "    import dowhy\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
    "\n",
    "try:\n",
    "    import flaml\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"FLAML\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53241021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this makes the notebook expand to full width of the browser window\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed9b5f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n// turn off scrollable windows for large output\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "// turn off scrollable windows for large output\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da208ce6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from auto_causality import AutoCausality\n",
    "from auto_causality.datasets import synth_ihdp\n",
    "from auto_causality.scoring import Scorer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b637c532",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model fitting & scoring\n",
    "Here we fit a (selection of) model(s) to the data and score them with the normalized ERUPT metric (chosen to specifically look for differences in impctt across customers) on held-out data.\n",
    "\n",
    "We import an example dataset and pre-process it. The pre-processing fills in the NaNs and one-hot-encodes all categorical and int variables.\n",
    "\n",
    "If you don't want an int variable to be one-hot-encoded, please cast it to float before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96719b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = synth_ihdp()\n",
    "cd.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e4721b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   treatment  y_factual  random        x1        x2        x3        x4  \\\n",
      "0          1   5.599916     1.0 -0.528603 -0.343455  1.128554  0.161703   \n",
      "1          0   6.875856     1.0 -1.736945 -1.802002  0.383828  2.244319   \n",
      "2          0   2.996273     1.0 -0.807451 -0.202946 -0.360898 -0.879606   \n",
      "3          0   1.366206     1.0  0.390083  0.596582 -1.850350 -0.879606   \n",
      "4          0   1.963538     0.0 -1.045228 -0.602710  0.011465  0.161703   \n",
      "\n",
      "         x5        x6   x7  ...  x16  x17  x18  x19  x20  x21  x22  x23  x24  \\\n",
      "0 -0.316603  1.295216  1.0  ...  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1 -0.629189  1.295216  0.0  ...  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2  0.808706 -0.526556  0.0  ...  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3 -0.004017 -0.857787  0.0  ...  1.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4  0.683672 -0.360940  1.0  ...  1.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   x25  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cd.data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "541e8ec6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fitting the model is as simple as calling AutoCausality.fit(), with the only required parameter apart from the data being the amount of time you want to give the optimizer, either for the whole run (`time_budget`) or per FLAML component model (`components_time_budget`), or both.\n",
    "\n",
    "If you want to use specific estimators, comment in the `estimator_list` below to include any estimators whose full name contains any of the elements of `estimator_list`.\n",
    "\n",
    "The other allowed values are `all` and `auto`, the default is `auto`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-12 15:46:39] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-12 15:46:39] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.SparseLinearDML', 'fit_cate_intercept': True, 'n_alphas': 100, 'n_alphas_cov': 10, 'tol': 0.0001, 'max_iter': 10000, 'mc_agg': 'mean'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-12 15:46:39] {198} INFO - result: {'energy_distance': 0.3409869959994314, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': 4.029953761597362, 'ate_std': 0.038202260766478265, 'erupt': 6.428079560416515, 'norm_erupt': 2.3474874846745637, 'qini': -9.28235433124249, 'auc': 0.49154811806308435, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   7.045186  0.20268    True        False  0.000000\n",
      "1          0   3.182114  0.20268    True         True  0.000000\n",
      "2          1   7.647942  0.20268    True        False  4.933884\n",
      "3          0   4.498734  0.20268    True        False  0.000000\n",
      "4          1   6.554958  0.20268    True         True  4.933884\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "592        1   8.025306  0.20268    True        False  4.933884\n",
      "593        0   2.532334  0.20268    True        False  0.000000\n",
      "594        0   2.874851  0.20268    True         True  0.000000\n",
      "595        0   1.744767  0.20268    True         True  0.000000\n",
      "596        0   2.358916  0.20268    True        False  0.000000\n",
      "\n",
      "[597 rows x 6 columns], 'energy_distance': 0.13344897669896394}, 'validation': {'ate': 3.9866098723356846, 'ate_std': 0.03895930318456941, 'erupt': 6.461580506462417, 'norm_erupt': 1.8276594443272638, 'qini': -4.9831288760016275, 'auc': 0.493343579533839, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   2.557908  0.20268    True        False  0.000000\n",
      "1          1   6.175583  0.20268    True        False  8.333333\n",
      "2          0   2.184495  0.20268    True        False  0.000000\n",
      "3          0   2.405894  0.20268    True        False  0.000000\n",
      "4          0   2.811190  0.20268    True         True  0.000000\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "145        0   2.441898  0.20268    True         True  0.000000\n",
      "146        0   1.604390  0.20268    True        False  0.000000\n",
      "147        0   2.269523  0.20268    True        False  0.000000\n",
      "148        0   6.594044  0.20268    True        False  0.000000\n",
      "149        0   0.782929  0.20268    True        False  0.000000\n",
      "\n",
      "[150 rows x 6 columns], 'energy_distance': 0.3409869959994314}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.14640188217163086}\n",
      "[flaml.tune.tune: 05-12 15:46:39] {636} INFO - trial 2 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}\n",
      "[flaml.tune.tune: 05-12 15:46:39] {198} INFO - result: {'energy_distance': 0.34159196882255216, 'estimator_name': 'backdoor.auto_causality.models.Dummy', 'scores': {'train': {'ate': 4.032635944235338, 'ate_std': 0.039638059442952275, 'erupt': 6.428079560416515, 'norm_erupt': 2.5163306967499466, 'qini': 29.280109137802246, 'auc': 0.503994864190425, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   7.045186  0.20268    True         True  0.000000\n",
      "1          0   3.182114  0.20268    True        False  0.000000\n",
      "2          1   7.647942  0.20268    True         True  4.933884\n",
      "3          0   4.498734  0.20268    True         True  0.000000\n",
      "4          1   6.554958  0.20268    True        False  4.933884\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "592        1   8.025306  0.20268    True         True  4.933884\n",
      "593        0   2.532334  0.20268    True         True  0.000000\n",
      "594        0   2.874851  0.20268    True        False  0.000000\n",
      "595        0   1.744767  0.20268    True         True  0.000000\n",
      "596        0   2.358916  0.20268    True         True  0.000000\n",
      "\n",
      "[597 rows x 6 columns], 'energy_distance': 0.13384655327796846}, 'validation': {'ate': 4.000151201189445, 'ate_std': 0.04347363638255067, 'erupt': 6.461580506462417, 'norm_erupt': 2.0977201889997494, 'qini': 9.165771256826039, 'auc': 0.5134428625931459, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   2.557908  0.20268    True         True  0.000000\n",
      "1          1   6.175583  0.20268    True         True  8.333333\n",
      "2          0   2.184495  0.20268    True        False  0.000000\n",
      "3          0   2.405894  0.20268    True         True  0.000000\n",
      "4          0   2.811190  0.20268    True        False  0.000000\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "145        0   2.441898  0.20268    True        False  0.000000\n",
      "146        0   1.604390  0.20268    True         True  0.000000\n",
      "147        0   2.269523  0.20268    True         True  0.000000\n",
      "148        0   6.594044  0.20268    True         True  0.000000\n",
      "149        0   0.782929  0.20268    True        False  0.000000\n",
      "\n",
      "[150 rows x 6 columns], 'energy_distance': 0.34159196882255216}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.09034609794616699}\n",
      "[flaml.tune.tune: 05-12 15:46:39] {636} INFO - trial 3 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}\n",
      "[flaml.tune.tune: 05-12 15:46:49] {198} INFO - result: {'energy_distance': 0.3639341973566408, 'estimator_name': 'backdoor.econml.metalearners.SLearner', 'scores': {'train': {'ate': 3.831521291616295, 'ate_std': 1.0213021442843842, 'erupt': 6.417968284051881, 'norm_erupt': 2.77866228894887, 'qini': 30.437010551668585, 'auc': 0.5674532865266131, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   7.045186  0.20268   False        False  1.245831\n",
      "1          0   3.182114  0.20268    True        False  0.000000\n",
      "2          1   7.647942  0.20268    True        False  4.900954\n",
      "3          0   4.498734  0.20268    True        False  0.000000\n",
      "4          1   6.554958  0.20268    True        False  4.900954\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "592        1   8.025306  0.20268    True        False  4.900954\n",
      "593        0   2.532334  0.20268    True         True  0.000000\n",
      "594        0   2.874851  0.20268    True        False  0.000000\n",
      "595        0   1.744767  0.20268    True         True  0.000000\n",
      "596        0   2.358916  0.20268    True        False  0.000000\n",
      "\n",
      "[597 rows x 6 columns], 'energy_distance': 0.11994552333050734}, 'validation': {'ate': 3.795242800266456, 'ate_std': 1.0273530493682137, 'erupt': 6.4782925927882635, 'norm_erupt': 2.0114987670287445, 'qini': 0.3996345583384256, 'auc': 0.556657140987688, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   2.557908  0.20268    True        False  0.000000\n",
      "1          1   6.175583  0.20268    True         True  7.887760\n",
      "2          0   2.184495  0.20268    True         True  0.000000\n",
      "3          0   2.405894  0.20268    True         True  0.000000\n",
      "4          0   2.811190  0.20268    True        False  0.000000\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "145        0   2.441898  0.20268    True         True  0.000000\n",
      "146        0   1.604390  0.20268    True         True  0.000000\n",
      "147        0   2.269523  0.20268    True         True  0.000000\n",
      "148        0   6.594044  0.20268   False        False  2.005082\n",
      "149        0   0.782929  0.20268    True         True  0.000000\n",
      "\n",
      "[150 rows x 6 columns], 'energy_distance': 0.3639341973566408}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}, 'experiment_tag': 'exp', 'time_total_s': 10.144988298416138}\n",
      "[flaml.tune.tune: 05-12 15:46:49] {636} INFO - trial 4 config: {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}}\n",
      "[flaml.automl: 05-12 15:47:09] {2913} WARNING - Time taken to find the best model is 96% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.tune.tune: 05-12 15:47:10] {198} INFO - result: {'energy_distance': 0.33506196921984976, 'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'scores': {'train': {'ate': 3.993520293450701, 'ate_std': 0.4733851329730215, 'erupt': 6.428079560416515, 'norm_erupt': 2.8446408765983344, 'qini': 58.03654131326761, 'auc': 0.5717947382239145, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   7.045186  0.20268    True        False  0.000000\n",
      "1          0   3.182114  0.20268    True        False  0.000000\n",
      "2          1   7.647942  0.20268    True         True  4.933884\n",
      "3          0   4.498734  0.20268    True        False  0.000000\n",
      "4          1   6.554958  0.20268    True        False  4.933884\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "592        1   8.025306  0.20268    True        False  4.933884\n",
      "593        0   2.532334  0.20268    True         True  0.000000\n",
      "594        0   2.874851  0.20268    True        False  0.000000\n",
      "595        0   1.744767  0.20268    True         True  0.000000\n",
      "596        0   2.358916  0.20268    True         True  0.000000\n",
      "\n",
      "[597 rows x 6 columns], 'energy_distance': 0.12753424912681943}, 'validation': {'ate': 3.961689350467165, 'ate_std': 0.5204072807814314, 'erupt': 6.461580506462417, 'norm_erupt': 2.279748990110822, 'qini': 2.488264359210127, 'auc': 0.5393690288352175, 'values':      treated  y_factual        p  policy  norm_policy   weights\n",
      "0          0   2.557908  0.20268    True         True  0.000000\n",
      "1          1   6.175583  0.20268    True         True  8.333333\n",
      "2          0   2.184495  0.20268    True         True  0.000000\n",
      "3          0   2.405894  0.20268    True         True  0.000000\n",
      "4          0   2.811190  0.20268    True         True  0.000000\n",
      "..       ...        ...      ...     ...          ...       ...\n",
      "145        0   2.441898  0.20268    True         True  0.000000\n",
      "146        0   1.604390  0.20268    True        False  0.000000\n",
      "147        0   2.269523  0.20268    True         True  0.000000\n",
      "148        0   6.594044  0.20268    True        False  0.000000\n",
      "149        0   0.782929  0.20268    True         True  0.000000\n",
      "\n",
      "[150 rows x 6 columns], 'energy_distance': 0.33506196921984976}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}, 'experiment_tag': 'exp', 'time_total_s': 20.28067898750305}\n",
      "[flaml.tune.tune: 05-12 15:47:10] {636} INFO - trial 5 config: {'estimator': {'estimator_name': 'backdoor.econml.dml.SparseLinearDML', 'fit_cate_intercept': 1, 'n_alphas': 100, 'n_alphas_cov': 10, 'tol': 9.999999999999999e-05, 'max_iter': 10000, 'mc_agg': 'mean'}}\n"
     ]
    }
   ],
   "source": [
    "ct = AutoCausality(\n",
    "#     time_budget=600,# it's best to specify either time_budget or components_time_budget, and let the other one be inferred\n",
    "     estimator_list=[\n",
    "             \"Dummy\",\n",
    "             \"SparseLinearDML\",\n",
    "             \"ForestDRLearner\",\n",
    "#             \"TransformedOutcome\",\n",
    "#             \"CausalForestDML\",\n",
    "#             \".LinearDML\",\n",
    "#             \"DomainAdaptationLearner\",\n",
    "             \"SLearner\",\n",
    "#             \"XLearner\",\n",
    "#             \"TLearner\",\n",
    "#             \"Ortho\",\n",
    "         ],\n",
    "    metric=\"energy_distance\",\n",
    "    verbose=3,\n",
    "    components_verbose=2,\n",
    "    components_time_budget=10,\n",
    ")\n",
    "\n",
    "\n",
    "# run autocausality\n",
    "ct.fit(data=cd, outcome=cd.outcomes[0]))\n",
    "# return best estimator\n",
    "print(f\"Best estimator: {ct.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"best config: {ct.best_config}\")\n",
    "# best score:\n",
    "print(f\"best score: {ct.best_score}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After running a fit, you can resume it without losing past results, for example if you want to search over extra estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we can now resume the fit to continue with the init_cfgs which we haven't tried yet\n",
    "# ct.fit(train_df, treatment, outcome, features_W, features_X,resume=True)\n",
    "# # return best estimator\n",
    "# print(f\"Best estimator: {ct.best_estimator}\")\n",
    "# # config of best estimator:\n",
    "# print(f\"best config: {ct.best_config}\")\n",
    "# # best score:\n",
    "# print(f\"best score: {ct.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ct.results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# score all estimators on the test set, which we've kept aside up till now\n",
    "for est_name, scr in ct.scores.items():\n",
    "    causal_estimate = scr['estimator']\n",
    "    scr['scores']['test'] = ct.scorer.make_scores(causal_estimate, test_df, problem=ct.problem, metrics_to_report=ct.metrics_to_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "colors = ([matplotlib.colors.CSS4_COLORS['black']] +\n",
    "    list(matplotlib.colors.TABLEAU_COLORS) + [\n",
    "    matplotlib.colors.CSS4_COLORS['lime'],\n",
    "    matplotlib.colors.CSS4_COLORS['yellow'],\n",
    "    matplotlib.colors.CSS4_COLORS['pink']\n",
    "])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title(outcome)\n",
    "\n",
    "m1 = \"ate\"\n",
    "m2 = \"norm_erupt\"\n",
    "\n",
    "for (est, scr), col in zip(ct.scores.items(),colors):\n",
    "    try:\n",
    "        sc = [scr[\"scores\"]['train'][m1], scr[\"scores\"]['validation'][m1], scr[\"scores\"]['test'][m1]]\n",
    "        crv = [scr[\"scores\"]['train'][m2], scr[\"scores\"]['validation'][m2], scr[\"scores\"]['test'][m2]]\n",
    "        plt.plot(sc, crv, color=col, marker=\"o\", label=est)\n",
    "        plt.scatter(sc[1:2],crv[1:2], c=col, s=70, label=\"_nolegend_\" )\n",
    "        plt.scatter(sc[2:],crv[2:], c=col, s=120, label=\"_nolegend_\" )\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "plt.xlabel(m1)\n",
    "plt.ylabel(m2)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.04,1), borderaxespad=0)\n",
    "\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scr = ct.scores[ct.best_estimator]\n",
    "intrp = scr[\"scores\"]['validation']['intrp']\n",
    "plt.figure(figsize=(15, 7))\n",
    "intrp.plot(feature_names=intrp.feature_names, fontsize=10)\n",
    "plt.title(f\"{ct.best_estimator}_{outcome}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# and now let's visualize feature importances!\n",
    "from auto_causality.shap import shap_values\n",
    "\n",
    "# Shapley values calculation can be slow so let's subsample\n",
    "this_df = test_df.sample(100)\n",
    "\n",
    "if \"Dummy\" not in ct.best_estimator:\n",
    "    scr = ct.scores[ct.best_estimator]\n",
    "    print(outcome, ct.best_estimator)\n",
    "    est = ct.model\n",
    "    shaps = shap_values(est, this_df)\n",
    "\n",
    "    plt.title(outcome + '_' + ct.best_estimator.split('.')[-1])\n",
    "    shap.summary_plot(shaps, this_df[est.estimator._effect_modifier_names])\n",
    "    plt.show()\n",
    "else: \n",
    "    print(f\"The best performing model is {ct.best_estimator} which doesn't depend on features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot out-of sample difference of outcomes between treated and untreated for the points where a model predicts positive vs negative impact\n",
    "my_est = ct.best_estimator\n",
    "stats = []\n",
    "\n",
    "v = ct.scores[my_est]['scores']['test']['values']\n",
    "\n",
    "sts = ct.scorer.group_ate(test_df.reset_index(), v['norm_policy'])\n",
    "\n",
    "display(sts)\n",
    "\n",
    "\n",
    "colors = (matplotlib.colors.CSS4_COLORS['black'],\n",
    "    matplotlib.colors.CSS4_COLORS['red'],\n",
    "    matplotlib.colors.CSS4_COLORS['blue'])\n",
    "\n",
    "grp = sts[\"policy\"].unique()\n",
    "\n",
    "for i,(p,c) in enumerate(zip(grp, colors)):\n",
    "    st = sts[sts[\"policy\"] == p]\n",
    "    plt.errorbar(np.array(range(len(st))) +0.1*i, st[\"mean\"].values[0],  yerr = st[\"std\"].values[0], color=c)\n",
    "plt.legend(grp)\n",
    "plt.grid(True)\n",
    "plt.title(my_est.split('.')[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot out-of sample difference of outcomes between treated and untreated for the points where a model predicts positive vs negative impact\n",
    "my_est = ct.best_estimator\n",
    "stats = []\n",
    "\n",
    "v = ct.scores[my_est]['scores']['test']['values']\n",
    "\n",
    "sts = ct.scorer.group_ate(test_df, v['norm_policy'])\n",
    "\n",
    "display(sts)\n",
    "\n",
    "\n",
    "colors = (matplotlib.colors.CSS4_COLORS['black'],\n",
    "    matplotlib.colors.CSS4_COLORS['red'],\n",
    "    matplotlib.colors.CSS4_COLORS['blue'])\n",
    "\n",
    "grp = sts[\"policy\"].unique()\n",
    "\n",
    "for i,(p,c) in enumerate(zip(grp, colors)):\n",
    "    st = sts[sts[\"policy\"] == p]\n",
    "    plt.errorbar(np.array(range(len(st))) +0.1*i, st[\"mean\"].values[0],  yerr = st[\"std\"].values[0], color=c)\n",
    "plt.legend(grp)\n",
    "plt.grid(True)\n",
    "plt.title(my_est.split('.')[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec342a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
