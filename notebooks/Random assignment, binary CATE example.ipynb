{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a34f30c6",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Random assignment, binary CATE example\n",
                "\n",
                "This is a fully worked-out notebook showing how you would apply causaltune to a dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6eaac69",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import os, sys\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# the below checks for whether we run dowhy, causaltune, and FLAML from source\n",
                "root_path = root_path = os.path.realpath('../..')\n",
                "try:\n",
                "    import causaltune\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
                "\n",
                "try:\n",
                "    import dowhy\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
                "\n",
                "try:\n",
                "    import flaml\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"FLAML\"))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "53241021",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# this makes the notebook expand to full width of the browser window\n",
                "from IPython.core.display import display, HTML\n",
                "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ed9b5f7",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "data": {
                        "application/javascript": "\n// turn off scrollable windows for large output\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}\n",
                        "text/plain": [
                            "<IPython.core.display.Javascript object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "%%javascript\n",
                "\n",
                "// turn off scrollable windows for large output\n",
                "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
                "    return false;\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da208ce6",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "from causaltune import CausalTune\n",
                "from causaltune.datasets import synth_ihdp"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "b637c532",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "### Model fitting & scoring\n",
                "Here we fit a (selection of) model(s) to the data and score them with the energy distance metric on held-out data.\n",
                "\n",
                "We import an example dataset and pre-process it. The pre-processing fills in the NaNs and one-hot-encodes all categorical and int variables.\n",
                "\n",
                "If you don't want an int variable to be one-hot-encoded, please cast it to float before preprocessing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96719b4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load toy dataset and apply standard pre-processing\n",
                "cd = synth_ihdp()\n",
                "cd.preprocess_dataset()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a12303d6",
            "metadata": {},
            "source": [
                "Inspecting the dataset below, we can see that the causal inference problem is defined by a binary `treatment`, a continuous outcome `y_factual`, and a range of covariates `x_{i}`. The `random` column is added to bypass a DoWhy bug."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "49e4721b",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# inspect the preprocessed dataset\n",
                "display(cd.data.head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "541e8ec6",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "Fitting the model is as simple as calling CausalTune.fit(), with the only required parameter apart from the data being the amount of time you want to give the optimizer, either for the whole run (`time_budget`) or per FLAML component model (`components_time_budget`), or both.\n",
                "\n",
                "If you want to use specific estimators, comment in the `estimator_list` below to include any estimators whose full name contains any of the elements of `estimator_list`.\n",
                "\n",
                "The other allowed values are `all` and `auto`, the default is `auto`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd4b291e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# training configs\n",
                "\n",
                "# choose estimators of interest\n",
                "estimator_list = [\n",
                "            \"Dummy\",\n",
                "            # \"SparseLinearDML\",\n",
                "            # \"ForestDRLearner\",\n",
                "            # \"TransformedOutcome\",\n",
                "            # \"CausalForestDML\",\n",
                "            # \".LinearDML\",\n",
                "            # \"DomainAdaptationLearner\",\n",
                "            \"SLearner\",\n",
                "            \"XLearner\",\n",
                "            # \"TLearner\",\n",
                "            # \"Ortho\"\n",
                "    ]\n",
                "\n",
                "# set evaluation metric\n",
                "metric = \"energy_distance\"\n",
                "\n",
                "# it's best to specify either time_budget or components_time_budget, \n",
                "# and let the other one be inferred; time in seconds\n",
                "time_budget = None\n",
                "components_time_budget = 10\n",
                "\n",
                "# specify training set size\n",
                "train_size = 0.7\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "ct = CausalTune(\n",
                "    estimator_list=estimator_list,\n",
                "    metric=metric,\n",
                "    verbose=3,\n",
                "    components_verbose=2,\n",
                "    time_budget=time_budget,\n",
                "    components_time_budget=components_time_budget,\n",
                "    train_size=train_size\n",
                ")\n",
                "\n",
                "\n",
                "# run causaltune\n",
                "ct.fit(data=cd, outcome=cd.outcomes[0])\n",
                "\n",
                "print('---------------------')\n",
                "# return best estimator\n",
                "print(f\"Best estimator: {ct.best_estimator}\")\n",
                "# config of best estimator:\n",
                "print(f\"best config: {ct.best_config}\")\n",
                "# best score:\n",
                "print(f\"best score: {ct.best_score}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "After running a fit, you also have the option resume it without losing past results, for example if you want to search over extra estimators. To do so, simply pass `resume=True` to the `fit` method as shown below: \n",
                "\n",
                "`ct.fit(data=cd,outcome=cd.outcomes[0],resume=True)`"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "b5f10b9b",
            "metadata": {},
            "source": [
                "We will now score all estimators on the held-out test set and save the results per estimator in `ct.scores`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "test_df = ct.test_df\n",
                "\n",
                "for est_name, scr in ct.scores.items():\n",
                "    causal_estimate = scr['estimator']\n",
                "    scr['scores']['test'] = ct.scorer.make_scores(causal_estimate, test_df, metrics_to_report=ct.metrics_to_report)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "416910e8",
            "metadata": {},
            "source": [
                "Below we demonstrate some basic plotting functionality that comes with `causaltune`. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93bc5191",
            "metadata": {},
            "outputs": [],
            "source": [
                "from causaltune.visualizer import Visualizer\n",
                "\n",
                "viz = Visualizer(\n",
                "    test_df=test_df,\n",
                "    treatment_col_name=cd.treatment,\n",
                "    outcome_col_name=cd.outcomes[0]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "353818ad",
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "# plotting metrics by estimator\n",
                "\n",
                "figtitle = f'{viz.outcome_col_name}'\n",
                "figsize = (7,5)\n",
                "metrics = ('energy_distance', 'ate')\n",
                "\n",
                "viz.plot_metrics_by_estimator(\n",
                "    scores_dict=ct.scores,\n",
                "    metrics=metrics,\n",
                "    figtitle=figtitle,\n",
                "    figsize=figsize\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c0287e14",
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "# plotting shapley feature importances\n",
                "# sampling from test_df as calculation can take a while\n",
                "# optional: supply pre-computed shapley values by passing them as shaps=your_array\n",
                "\n",
                "use_df = test_df.sample(100)\n",
                "est = ct.model\n",
                "\n",
                "viz.plot_shap(\n",
                "    estimate=est,\n",
                "    df=use_df,\n",
                "    figtitle='Shapley feature importances'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "98d7921e",
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "# plotting out-of sample difference of outcomes between treated and untreated \n",
                "# for the points where model predicts positive vs negative impact\n",
                "\n",
                "viz.plot_group_ate(\n",
                "    scorer=ct.scorer,\n",
                "    scores_dict=ct.scores,\n",
                "    estimator=ct.best_estimator\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "causality",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
