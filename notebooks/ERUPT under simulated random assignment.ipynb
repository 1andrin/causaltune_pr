{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a34f30c6",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## ERUPT under simulated random assignment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c37a7a94",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import os, sys\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore') # suppress sklearn deprecation warnings for now..\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# the below checks for whether we run dowhy, causaltune, and FLAML from source\n",
                "root_path = root_path = os.path.realpath('../..')\n",
                "try:\n",
                "    import causaltune\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
                "\n",
                "try:\n",
                "    import dowhy\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
                "\n",
                "try:\n",
                "    import flaml\n",
                "except ModuleNotFoundError:\n",
                "    sys.path.append(os.path.join(root_path, \"FLAML\"))\n",
                "\n",
                "from causaltune import CausalTune\n",
                "from causaltune.datasets import generate_non_random_dataset\n",
                "from causaltune.erupt import DummyPropensity, ERUPT\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "53241021",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# this makes the notebook expand to full width of the browser window\n",
                "from IPython.core.display import display, HTML\n",
                "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ed9b5f7",
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "%%javascript\n",
                "\n",
                "// turn off scrollable windows for large output\n",
                "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
                "    return false;\n",
                "}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "af5333b0",
            "metadata": {},
            "source": [
                "## Loading data and model training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0211b9a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load toy dataset with non-random assignment and apply standard pre-processing\n",
                "cd = generate_non_random_dataset()\n",
                "cd.preprocess_dataset()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cec1abf",
            "metadata": {},
            "outputs": [],
            "source": [
                "display(cd.data.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b5d0795",
            "metadata": {},
            "outputs": [],
            "source": [
                "# training configs\n",
                "\n",
                "# set evaluation metric\n",
                "metric = \"energy_distance\"\n",
                "\n",
                "# it's best to specify either time_budget or components_time_budget, \n",
                "# and let the other one be inferred; time in seconds\n",
                "time_budget = None\n",
                "components_time_budget = 10\n",
                "\n",
                "# specify training set size\n",
                "train_size = 0.7"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a51c87f4",
            "metadata": {},
            "outputs": [],
            "source": [
                "ct = CausalTune(\n",
                "    estimator_list='cheap_inference',\n",
                "    metric=metric,\n",
                "    verbose=0,\n",
                "    components_verbose=0,\n",
                "    time_budget=time_budget,\n",
                "    components_time_budget=components_time_budget,\n",
                "    train_size=train_size\n",
                ")\n",
                "\n",
                "\n",
                "# run causaltune\n",
                "ct.fit(data=cd, outcome=cd.outcomes[0])\n",
                "\n",
                "print('---------------------')\n",
                "# return best estimator\n",
                "print(f\"Best estimator: {ct.best_estimator}\")\n",
                "# config of best estimator:\n",
                "print(f\"Best config: {ct.best_config}\")\n",
                "# best score:\n",
                "print(f\"Best score: {ct.best_score}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "19bcfc2e",
            "metadata": {},
            "source": [
                "## Random ERUPT"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "2bea4e38",
            "metadata": {},
            "source": [
                "Below we demonstrate how to use Estimated Response Under Proposed Treatment (ERUPT) to estimate the average treatment effect had the treatment been assigned randomly. Recall that the dataset used in this example is constructed in a way that the treatment propensity is a function of a unit's covariates."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db1b69a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "use_df = ct.test_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8afee5a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# computing mean ERUPT over 10 bootstrapped samples\n",
                "\n",
                "scores_list = []\n",
                "\n",
                "for i in range(10):\n",
                "\n",
                "    bootstrap_df = use_df.sample(frac=1, replace=True)\n",
                "    propensities = bootstrap_df['propensity']\n",
                "    actual_treatment = bootstrap_df['T']\n",
                "    outcome = bootstrap_df['Y']\n",
                "\n",
                "    # define the random assignment policy\n",
                "    random_policy = np.random.randint(0,2, size=len(bootstrap_df))\n",
                "\n",
                "    # define a propensity model that will simply return the propensities when calling predict_proba\n",
                "    propensity_model = DummyPropensity(p=propensities, treatment=actual_treatment)\n",
                "\n",
                "    # obtain ERUPT under random policy\n",
                "    e = ERUPT(treatment_name='T', propensity_model=propensity_model)\n",
                "    scores_list.append(e.score(df=use_df,outcome=outcome,policy=random_policy))\n",
                "\n",
                "erupt_mean = np.mean(scores_list)\n",
                "erupt_sd = np.std(scores_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "438112f2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# compute naive ate as difference in means\n",
                "naive_ate, naive_sd, _ = ct.scorer.naive_ate(ct.test_df['T'], ct.test_df['Y'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0f6d079",
            "metadata": {},
            "outputs": [],
            "source": [
                "# comparison of naive ate to mean random erupt over 10 bootstrap runs\n",
                "erupt_df = pd.DataFrame([[naive_ate,naive_sd],[erupt_mean,erupt_sd]], columns=['estimated_effect', 'sd'], index=['naive_ate','random_erupt'])\n",
                "display(erupt_df)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "a54530bf",
            "metadata": {},
            "source": [
                "For more details on the ERUPT implementation, consult [Hitsch and Misra (2018)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957). Note also that we assume that treatment takes integer values from 0 to n."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "causality",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
