{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import dcor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from dowhy import CausalModel\n",
    "from dowhy.causal_estimator import CausalEstimate\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "from auto_causality import AutoCausality # noqa F401\n",
    "from auto_causality.data_utils import preprocess_dataset # noqa F401\n",
    "from auto_causality.scoring import Scorer # noqa F401\n",
    "from auto_causality.datasets import iv_dgp_econml # noqa F401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Needed since ac.model.estimator doesn't include additional params -\n",
    "# treatment, outcome etc. - needed from CausalEstimate instance\n",
    "def energy_scorer_patch(\n",
    "    estimate: CausalEstimate,\n",
    "    df: pd.DataFrame,\n",
    "    treatment: str,\n",
    "    outcome: str,\n",
    "    instrument: str,\n",
    "    effect_modifiers: [],\n",
    "):\n",
    "\n",
    "    df[\"dy\"] = estimate.estimator.effect(df[effect_modifiers])\n",
    "    df.loc[df[treatment] == 0, \"dy\"] = 0\n",
    "    df[\"yhat\"] = df[outcome] - df[\"dy\"]\n",
    "\n",
    "    X1 = df[df[instrument] == 1]\n",
    "    X0 = df[df[instrument] == 0]\n",
    "    select_cols = effect_modifiers + [\"yhat\"]\n",
    "\n",
    "    energy_distance_score = dcor.energy_distance(X1[select_cols], X0[select_cols])\n",
    "\n",
    "    return energy_distance_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      treatment          y    Z        x1        x2        x3        x4  \\\n4707        1.0  10.885826  1.0 -0.957813 -0.633441  0.117917 -0.433192   \n3039        1.0  18.750271  1.0 -0.539135  1.191224 -0.196336 -1.248182   \n4052        1.0  19.557085  1.0  1.174392  0.096396  1.555359 -1.718700   \n2001        0.0   9.353517  0.0  0.743674  0.982287  0.845747  1.123714   \n662         0.0   8.886736  0.0 -0.591889  0.102331 -1.327556  1.787519   \n\n            x5        x6        x7        x8        x9       x10  random  \n4707 -0.361684 -0.135773 -0.052122  0.380327  1.329565 -0.321435     1.0  \n3039 -0.984221  0.556852  1.936504 -0.913703  0.890823  0.481807     0.0  \n4052  1.015463  0.395455  1.236376  0.041600  0.687383 -0.027819     0.0  \n2001  1.357107  0.908090 -1.981520 -1.037397  0.846038 -0.385248     1.0  \n662  -0.449173 -0.020433 -0.833148  0.881001 -1.593588  0.384400     0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>treatment</th>\n      <th>y</th>\n      <th>Z</th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>x3</th>\n      <th>x4</th>\n      <th>x5</th>\n      <th>x6</th>\n      <th>x7</th>\n      <th>x8</th>\n      <th>x9</th>\n      <th>x10</th>\n      <th>random</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4707</th>\n      <td>1.0</td>\n      <td>10.885826</td>\n      <td>1.0</td>\n      <td>-0.957813</td>\n      <td>-0.633441</td>\n      <td>0.117917</td>\n      <td>-0.433192</td>\n      <td>-0.361684</td>\n      <td>-0.135773</td>\n      <td>-0.052122</td>\n      <td>0.380327</td>\n      <td>1.329565</td>\n      <td>-0.321435</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3039</th>\n      <td>1.0</td>\n      <td>18.750271</td>\n      <td>1.0</td>\n      <td>-0.539135</td>\n      <td>1.191224</td>\n      <td>-0.196336</td>\n      <td>-1.248182</td>\n      <td>-0.984221</td>\n      <td>0.556852</td>\n      <td>1.936504</td>\n      <td>-0.913703</td>\n      <td>0.890823</td>\n      <td>0.481807</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4052</th>\n      <td>1.0</td>\n      <td>19.557085</td>\n      <td>1.0</td>\n      <td>1.174392</td>\n      <td>0.096396</td>\n      <td>1.555359</td>\n      <td>-1.718700</td>\n      <td>1.015463</td>\n      <td>0.395455</td>\n      <td>1.236376</td>\n      <td>0.041600</td>\n      <td>0.687383</td>\n      <td>-0.027819</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2001</th>\n      <td>0.0</td>\n      <td>9.353517</td>\n      <td>0.0</td>\n      <td>0.743674</td>\n      <td>0.982287</td>\n      <td>0.845747</td>\n      <td>1.123714</td>\n      <td>1.357107</td>\n      <td>0.908090</td>\n      <td>-1.981520</td>\n      <td>-1.037397</td>\n      <td>0.846038</td>\n      <td>-0.385248</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>0.0</td>\n      <td>8.886736</td>\n      <td>0.0</td>\n      <td>-0.591889</td>\n      <td>0.102331</td>\n      <td>-1.327556</td>\n      <td>1.787519</td>\n      <td>-0.449173</td>\n      <td>-0.020433</td>\n      <td>-0.833148</td>\n      <td>0.881001</td>\n      <td>-1.593588</td>\n      <td>0.384400</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = iv_dgp_econml()\n",
    "\n",
    "treatment = data.treatment\n",
    "targets = data.outcomes\n",
    "instruments = data.instruments\n",
    "data_df, features_X, features_W = preprocess_dataset(\n",
    "    data.data, treatment, targets, instruments\n",
    ")\n",
    "\n",
    "outcome = targets[0]\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.2)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Component model time budget is 60. Recommended value is at least 300 for smallish datasets, 1800 for datasets with> 100K rows\n",
      "\u001B[32m[I 2022-07-12 17:53:15,158]\u001B[0m A new study created in memory with name: optuna\u001B[0m\n",
      "[flaml.tune.tune: 07-12 17:53:15] {456} INFO - trial 1 config: {'estimator': {'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial configs: [{'estimator': {'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}}, {'estimator': {'estimator_name': 'iv.econml.iv.dml.DMLIV', 'mc_agg': 'mean'}}]\n",
      "{'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "[flaml.automl: 07-12 17:55:24] {2322} WARNING - Time taken to find the best model is 78% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "[flaml.automl: 07-12 17:56:25] {2322} WARNING - Time taken to find the best model is 82% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.tune.tune: 07-12 17:57:25] {110} INFO - result: {'energy_distance': 0.023866990213011974, 'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'scores': {'train': {'energy_distance': 0.014418654175849532}, 'validation': {'energy_distance': 0.023866990213011974}}, 'config': {'estimator': {'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}, 'experiment_tag': 'exp', 'time_total_s': 250.59895300865173}\n"
     ]
    }
   ],
   "source": [
    "ac = AutoCausality(\n",
    "    time_budget=240,\n",
    "    verbose=3,\n",
    "    components_verbose=2,\n",
    "    components_time_budget=60,\n",
    "    propensity_model=\"auto\",\n",
    ")\n",
    "\n",
    "ac.fit(train_df, treatment, outcome, features_W, features_X, instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: iv.econml.iv.dml.OrthoIV\n",
      "best config: {'estimator': {'estimator_name': 'iv.econml.iv.dml.OrthoIV', 'mc_agg': 'mean'}}\n",
      "best score: 0.023866990213011974\n"
     ]
    }
   ],
   "source": [
    "# return best estimator\n",
    "print(f\"Best estimator: {ac.best_estimator}\")\n",
    "# config of best estimator:\n",
    "print(f\"best config: {ac.best_config}\")\n",
    "# best score:\n",
    "print(f\"best score: {ac.best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n"
     ]
    }
   ],
   "source": [
    "# Comparing best model searched to base IV model configuration\n",
    "model = CausalModel(\n",
    "    data=train_df,\n",
    "    treatment=treatment,\n",
    "    outcome=outcome[0],\n",
    "    effect_modifiers=features_X,\n",
    "    common_causes=[\"random\"],\n",
    "    instruments=instruments,\n",
    ")\n",
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "estimate = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=\"iv.econml.iv.dml.DMLIV\",\n",
    "    method_params={\n",
    "        \"init_params\": {},\n",
    "        \"fit_params\": {},\n",
    "    },\n",
    "    test_significance=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Baseline Estimator) Treatment Effect:  10.189894905013425\n",
      "(AutoCausality Estimator) Treatment Effect:  9.82992883200494\n",
      "Energy distance scores\n",
      "(Baseline Estimator) Energy distance score:  0.09726814255196636\n",
      "(AutoCausality Estimator) Energy distance score:  0.05911449386666323\n"
     ]
    }
   ],
   "source": [
    "Xtest = test_df[features_X]\n",
    "print()\n",
    "print(\n",
    "    \"(Baseline Estimator) Treatment Effect: \",\n",
    "    estimate.estimator.effect(Xtest).mean(),\n",
    ")\n",
    "print(\n",
    "    \"(AutoCausality Estimator) Treatment Effect: \",\n",
    "    ac.model.estimator.estimator.effect(Xtest).mean(),\n",
    ")\n",
    "\n",
    "print(\"Energy distance scores\")\n",
    "base_estimator_edist = Scorer.energy_distance_score(estimate, test_df)\n",
    "ac_estimator_edist = energy_scorer_patch(\n",
    "    ac.model.estimator, test_df, treatment, outcome, instruments[0], features_X\n",
    ")\n",
    "print(\"(Baseline Estimator) Energy distance score: \", base_estimator_edist)\n",
    "print(\"(AutoCausality Estimator) Energy distance score: \", ac_estimator_edist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}