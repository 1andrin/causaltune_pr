{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34f30c6",
   "metadata": {},
   "source": [
    "### Minimal example of how to use FLAML for auto-causality\n",
    "We use FLAML twice, first to find the best component model for each estimator, and then to find the best econML estimator. Here we show how to perform the first step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d7480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "C:\\Users\\Timo\\Desktop\\osgd_wise\\code\\auto-causality\\data\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import dill\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "data_dir = os.path.realpath(os.path.join(root_path, \"auto-causality/data\"))\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ceab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if you are using dowhy and this repo by just pulling the source\n",
    "sys.path.append(os.path.join(root_path, \"dowhy\"))\n",
    "sys.path.append(os.path.join(root_path, \"auto-causality\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8de5d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Timo\\anaconda3\\envs\\autocausality\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "from dowhy import CausalModel\n",
    "\n",
    "from auto_causality.utils import featurize, AutoMLWrapper\n",
    "from auto_causality.params import SimpleParamService\n",
    "from auto_causality.scoring import make_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc1f5c",
   "metadata": {},
   "source": [
    "### Control Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c777cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all the control parameters here\n",
    "train_size = 0.5\n",
    "test_size = None\n",
    "time_budget = 300\n",
    "num_cores = os.cpu_count() - 1\n",
    "conf_intervals = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12dc41e",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9331f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load raw data\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AMLab-Amsterdam/CEVAE/master/datasets/IHDP/csv/ihdp_npci_1.csv\",\n",
    "    header=None,\n",
    ")\n",
    "col = [\n",
    "    \"treatment\",\n",
    "    \"y_factual\",\n",
    "    \"y_cfactual\",\n",
    "    \"mu0\",\n",
    "    \"mu1\",\n",
    "]\n",
    "for i in range(1, 26):\n",
    "    col.append(\"x\" + str(i))\n",
    "data.columns = col\n",
    "# drop the columns we don't care about\n",
    "ignore_patterns = [\"y_cfactual\", \"mu\"]\n",
    "ignore_cols = [c for c in data.columns if any([s in c for s in ignore_patterns])]\n",
    "data = data.drop(columns=ignore_cols)\n",
    "\n",
    "\n",
    "# prepare the data\n",
    "\n",
    "treatment = \"treatment\"\n",
    "targets = [\"y_factual\"]  # it's good to allow multiple ones\n",
    "features = [c for c in data.columns if c not in [treatment] + targets]\n",
    "\n",
    "data[treatment] = data[treatment].astype(int)\n",
    "# this is a trick to bypass some DoWhy/EconML bugs\n",
    "data[\"random\"] = np.random.randint(0, 2, size=len(data))\n",
    "\n",
    "used_df = featurize(\n",
    "    data, features=features, exclude_cols=[treatment] + targets, drop_first=False,\n",
    ")\n",
    "used_features = [\n",
    "    c for c in used_df.columns if c not in ignore_cols + [treatment] + targets\n",
    "]\n",
    "\n",
    "\n",
    "# Let's treat all features as effect modifiers\n",
    "features_X = [f for f in used_features if f != \"random\"]\n",
    "features_W = [f for f in used_features if f not in features_X]\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(used_df, train_size=train_size)\n",
    "if test_size is not None:\n",
    "    test_df = test_df.sample(test_size)\n",
    "\n",
    "test_df.to_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "train_df.to_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d9d57",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a6e138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model parameters here\n",
    "# component models:\n",
    "propensity_model = DummyClassifier(strategy=\"prior\")\n",
    "outcome_model = AutoMLWrapper(\n",
    "    fit_params={\n",
    "        \"time_budget\": time_budget,\n",
    "        \"verbose\": 1,\n",
    "        \"task\": \"regression\",\n",
    "        \"n_jobs\": num_cores,\n",
    "        \"pred_time_limit\": 10 / 1e6,\n",
    "    }\n",
    ")\n",
    "\n",
    "# instantiate model config:\n",
    "cfg = SimpleParamService(\n",
    "    propensity_model,\n",
    "    outcome_model,\n",
    "    conf_intervals=conf_intervals,\n",
    "    n_bootstrap_samples=20,\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_leaf_size=2 * len(used_features),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d234a",
   "metadata": {},
   "source": [
    "### Model fitting & scoring\n",
    "Here we fit a (selection of) model(s) to the data and score them with the ERUPT metric on held-out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9023200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported models: \n",
      " - backdoor.propensity_score_weighting\n",
      " - backdoor.econml.metalearners.SLearner\n",
      " - backdoor.econml.metalearners.TLearner\n",
      " - backdoor.econml.metalearners.XLearner\n",
      " - backdoor.econml.metalearners.DomainAdaptationLearner\n",
      " - backdoor.econml.dr.ForestDRLearner\n",
      " - backdoor.econml.dr.LinearDRLearner\n",
      " - backdoor.econml.dr.SparseLinearDRLearner\n",
      " - backdoor.econml.dml.LinearDML\n",
      " - backdoor.econml.dml.SparseLinearDML\n",
      " - backdoor.econml.dml.CausalForestDML\n",
      " - backdoor.auto_causality.dowhy_wrapper.direct_uplift.DirectUpliftDoWhyWrapper\n",
      " - backdoor.econml.orf.DROrthoForest\n",
      " - backdoor.econml.orf.DMLOrthoForest\n"
     ]
    }
   ],
   "source": [
    "# get list of supported models\n",
    "\n",
    "bulletpoint = \"\\n - \"\n",
    "print(f\"supported models: {bulletpoint}{(bulletpoint).join(cfg.estimators())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e8ef7",
   "metadata": {},
   "source": [
    "1. Choose econML model and retrieve its default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fef374e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. choose econML model and retrieve parameters\n",
    "estimator = \"backdoor.econml.dml.LinearDML\"\n",
    "estimator_params = cfg.method_params(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bd611",
   "metadata": {},
   "source": [
    "2. Instantiate the causal model with DoWhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf022154",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = targets[0]\n",
    "model = CausalModel(\n",
    "    data=train_df,\n",
    "    treatment=treatment,\n",
    "    outcome=targets[0],\n",
    "    common_causes=features_W,\n",
    "    effect_modifiers=features_X,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1803d83",
   "metadata": {},
   "source": [
    "3. Identify the effect with DoWhy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4334120",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c468c35",
   "metadata": {},
   "source": [
    "4. Estimate the effect (this uses FLAML for the component models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = model.estimate_effect(\n",
    "    identified_estimand,\n",
    "    method_name=estimator,\n",
    "    control_value=0,\n",
    "    treatment_value=1,\n",
    "    target_units=\"ate\",  # condition used for CATE\n",
    "    confidence_intervals=conf_intervals,\n",
    "    method_params=estimator_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b24d6e",
   "metadata": {},
   "source": [
    "5. Interpret the effect (i.e. how large is the treatment effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fab36eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing the treatment variable(s) [treatment] from [0] to [1] causes an increase of 4.122409568331659 in the expected value of the outcome [y_factual], over the data distribution/population represented by the dataset.\n"
     ]
    }
   ],
   "source": [
    "estimates.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290949c2",
   "metadata": {},
   "source": [
    "6. Score the estimator (with ERUPT metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e32251d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual mean impact: 4.122409568331659 4.515768093730235 std: 1.7655081756724051\n",
      "Scores for backdoor.econml.dml.LinearDML_y_factual 6.4705822558812605 6.3390611739300935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n",
      "Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    te_train = estimates.cate_estimates\n",
    "    X_test = test_df[estimates.estimator._effect_modifier_names]\n",
    "    te_test = estimates.estimator.estimator.effect(X_test).flatten()\n",
    "    print(\n",
    "        \"manual mean impact:\",\n",
    "        te_train.mean(),\n",
    "        te_test.mean(),\n",
    "        \"std:\",\n",
    "        te_train.std(),\n",
    "    )\n",
    "except:\n",
    "    te_train = estimates.estimator.effect(train_df)\n",
    "    te_test = estimates.estimator.effect(test_df)\n",
    "\n",
    "scores = {\n",
    "    \"estimator\": estimator,\n",
    "    \"outcome\": outcome,\n",
    "    \"train\": make_scores(model, train_df, te_train),\n",
    "    \"test\": make_scores(model, test_df, te_test),\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Scores for {estimator}_{outcome}\",\n",
    "    scores[\"train\"][\"erupt\"],\n",
    "    scores[\"test\"][\"erupt\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74b38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add a baseline calculation\n",
    "# train_df = pd.read_csv(os.path.join(data_dir, f\"train_{time_budget}.csv\"))\n",
    "# test_df = pd.read_csv(os.path.join(data_dir, f\"test_{time_budget}.csv\"))\n",
    "# # purge previous ones\n",
    "# for outcome in targets:\n",
    "#     def ate(df: pd.DataFrame):\n",
    "#         return df[outcome][df[treatment]==1].mean() - df[outcome][df[treatment]==0].mean()\n",
    "\n",
    "#     scores[outcome][\"baseline\"]={\"estimator\": \"baseline\",\n",
    "#                                \"outcome\": outcome,\n",
    "#                               \"train\":{\"erupt\": train_df[outcome].mean(),\"ate\": ate(train_df)},\n",
    "#                               \"test\":{\"erupt\": test_df[outcome].mean(),\"ate\": ate(test_df)}}\n",
    "                              \n",
    "                              \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
