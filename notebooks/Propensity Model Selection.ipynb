{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from scipy.stats import betabinom\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "root_path = root_path = os.path.realpath('../..')\n",
    "try:\n",
    "    import auto_causality\n",
    "except ModuleNotFoundError:\n",
    "    sys.path.append(os.path.join(root_path, \"auto-causality\"))\n",
    "\n",
    "from auto_causality import AutoCausality\n",
    "from auto_causality.data_utils import CausalityDataset\n",
    "\n",
    "from flaml import AutoML\n",
    "import wise_pizza as wp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CausalTune for AB Testing \n",
    "\n",
    "CausalTune can be used for AB Testing in two ways:\n",
    "1. Variance Reduction\n",
    "2. Segmentation analysis\n",
    "\n",
    "#### 1. Variance Reduction\n",
    "A standard variance reduction technique is to control for natural variation in the experiment's outcome metric. The simplest way to do so is by running a simple regression with a selection of controls. A potentially more powerful and automated approach is to run CausalTune. \n",
    "\n",
    "#### 2. Segmentation Analysis\n",
    "\n",
    "We use the heterogeneous treatment effect estimates from CausalTune to feed them into the segmentation analytics tool Wise-Pizza."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generating Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DGP in this example can be described as follows:\n",
    "\n",
    "\\begin{align}\n",
    "    & T \\sim Bernoulli(.5)\\\\\n",
    "    %T &= h(\\beta \\cdot W) + \\eta \\\\ \n",
    "    Y &= T* \\rho + m(\\gamma \\cdot X) + \\epsilon \\\\\n",
    "    &\\rho = 0.01 \\\\\n",
    "    %& W \\sim BetaBinom(8, 600, 400) \\\\ % later give individual probabilities\n",
    "    %\\beta & = (.1, .2, .3, .4, .5, 0 , 0, ...)\\\\\n",
    "    & X \\sim hypergeometric(5, 5, 8)\\\\\n",
    "    & \\gamma \\sim Uniform([.5, 1.5]) \\\\\n",
    "    & m(x) = .5*x\n",
    "\n",
    "\\end{align}\n",
    "In particular, we assume \n",
    "- perfect randomisation of the treatment as we are replicating an AB test environment and\n",
    "- a constant treatment effect (for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_synth_data_with_categories(\n",
    "    n_samples=10000,\n",
    "    n_x=10,\n",
    ") -> CausalityDataset:\n",
    "    n_w = 3\n",
    "    T = np.random.binomial(1, 0.5, size=(n_samples,))\n",
    "    X = np.random.hypergeometric(5, 5, 8, size=(n_samples, n_x))\n",
    "    W = betabinom.rvs(8, 600, 400, size=(n_samples, n_w))\n",
    "    epsilon = 3*np.random.uniform(low=-1, high=1, size=(n_samples,))\n",
    "    gamma = np.random.uniform(low=0.5, high=1.5, size=(n_x,))\n",
    "    rho = lambda x: 0.01\n",
    "    feature_transform = lambda x: 0.5 * x\n",
    "\n",
    "    Y = T.T * rho(X[:, : int(n_x / 2)])   + feature_transform(np.matmul(gamma.T, X.T)) + epsilon\n",
    "\n",
    "    features = [f\"X{i+1}\" for i in range(n_x)]\n",
    "    features_w = [f\"W{i+1}\" for i in range(n_w)]\n",
    "    df = pd.DataFrame(np.array([*X.T, T, Y, *W.T]).T, columns=features + [\"variant\", \"Y\"] + features_w) \n",
    "    cd = CausalityDataset(\n",
    "        data=df,\n",
    "        treatment=\"variant\",\n",
    "        outcomes=[\"Y\"],\n",
    "    )\n",
    "    return cd\n",
    "cd = generate_synth_data_with_categories(n_samples=10000)\n",
    "cd.preprocess_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Y', ylabel='Density'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(data=cd.data, x=cd.outcomes[0], hue=cd.treatment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ATE estimation: Running CausalTune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CausalTune configuration\n",
    "num_samples = 10\n",
    "components_time_budget = 5\n",
    "train_size = 0.7\n",
    "\n",
    "target = cd.outcomes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 13:43:54] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 13:43:54] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 13:43:54] {198} INFO - result: {'energy_distance': 0.007011752515238889, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.04208969109980015, 'ate_std': 0.00042308312136897416, 'erupt': 17.227812483605984, 'norm_erupt': 17.22864301778871, 'qini': 4.729713386913961, 'auc': -0.5000773150754506, 'values':       treated          Y         p  policy  norm_policy  weights\n",
      "0           0  16.443682  0.504143   False         True  2.01671\n",
      "1           1  19.220052  0.504143   False        False  0.00000\n",
      "2           1  16.795653  0.504143   False        False  0.00000\n",
      "3           1  17.168290  0.504143   False        False  0.00000\n",
      "4           0  17.372071  0.504143   False        False  2.01671\n",
      "...       ...        ...       ...     ...          ...      ...\n",
      "6995        0  15.901622  0.504143   False         True  2.01671\n",
      "6996        0  19.665493  0.504143   False         True  2.01671\n",
      "6997        1  13.684731  0.504143   False        False  0.00000\n",
      "6998        0  14.509022  0.504143   False         True  2.01671\n",
      "6999        0  14.743065  0.504143   False        False  2.01671\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0025271770340955513}, 'validation': {'ate': 0.05474449708983579, 'ate_std': 0.0005428919796889405, 'erupt': 17.237800423577063, 'norm_erupt': 17.148952279692605, 'qini': -44.4564172992302, 'auc': 0.0380712648407744, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True        False  0.000000\n",
      "1           1  16.947004  0.504143    True        False  2.102313\n",
      "2           1  19.124658  0.504143    True         True  2.102313\n",
      "3           0  15.266764  0.504143    True        False  0.000000\n",
      "4           0  15.059235  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143    True        False  0.000000\n",
      "2996        1  16.902579  0.504143    True        False  2.102313\n",
      "2997        1  18.835211  0.504143    True         True  2.102313\n",
      "2998        0  14.982820  0.504143    True        False  0.000000\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007011752515238889}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.3170440196990967}\n",
      "[flaml.tune.tune: 05-16 13:43:54] {636} INFO - trial 2 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}\n",
      "[flaml.tune.tune: 05-16 13:43:54] {198} INFO - result: {'energy_distance': 0.0070117740194186595, 'estimator_name': 'backdoor.auto_causality.models.Dummy', 'scores': {'train': {'ate': -0.042100350049787655, 'ate_std': 0.0004176397916615878, 'erupt': 17.227812483605984, 'norm_erupt': 17.26679184576023, 'qini': 78.11734450917905, 'auc': 0.04746766216087184, 'values':       treated          Y         p  policy  norm_policy  weights\n",
      "0           0  16.443682  0.504143   False         True  2.01671\n",
      "1           1  19.220052  0.504143   False        False  0.00000\n",
      "2           1  16.795653  0.504143   False        False  0.00000\n",
      "3           1  17.168290  0.504143   False        False  0.00000\n",
      "4           0  17.372071  0.504143   False        False  2.01671\n",
      "...       ...        ...       ...     ...          ...      ...\n",
      "6995        0  15.901622  0.504143   False         True  2.01671\n",
      "6996        0  19.665493  0.504143   False         True  2.01671\n",
      "6997        1  13.684731  0.504143   False         True  0.00000\n",
      "6998        0  14.509022  0.504143   False         True  2.01671\n",
      "6999        0  14.743065  0.504143   False        False  2.01671\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0025271481274655727}, 'validation': {'ate': 0.05474284867351844, 'ate_std': 0.0005503793723579433, 'erupt': 17.237800423577063, 'norm_erupt': 17.183126203018848, 'qini': 40.953923682038415, 'auc': 0.7666775140614206, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True         True  0.000000\n",
      "1           1  16.947004  0.504143    True        False  2.102313\n",
      "2           1  19.124658  0.504143    True        False  2.102313\n",
      "3           0  15.266764  0.504143    True        False  0.000000\n",
      "4           0  15.059235  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143    True        False  0.000000\n",
      "2996        1  16.902579  0.504143    True         True  2.102313\n",
      "2997        1  18.835211  0.504143    True        False  2.102313\n",
      "2998        0  14.982820  0.504143    True         True  0.000000\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.0070117740194186595}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.30059194564819336}\n",
      "[flaml.tune.tune: 05-16 13:43:54] {636} INFO - trial 3 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}\n",
      "[flaml.automl: 05-16 13:43:54] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:43:54] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:43:54] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:43:54] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:43:54] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3296} INFO - Estimated sufficient time budget=226s. Estimated necessary time budget=2s.\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9909,\tbest estimator lgbm's best error=0.9909\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9909,\tbest estimator lgbm's best error=0.9909\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9740,\tbest estimator lgbm's best error=0.9740\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9666,\tbest estimator lgbm's best error=0.9666\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9666,\tbest estimator lgbm's best error=0.9666\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9613,\tbest estimator lgbm's best error=0.9613\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9613,\tbest estimator lgbm's best error=0.9613\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9587,\tbest estimator lgbm's best error=0.9587\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9587,\tbest estimator lgbm's best error=0.9587\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9445,\tbest estimator lgbm's best error=0.9445\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:54] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9445,\tbest estimator lgbm's best error=0.9445\n",
      "[flaml.automl: 05-16 13:43:54] {3166} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9445,\tbest estimator lgbm's best error=0.9445\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9445,\tbest estimator lgbm's best error=0.9445\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9445,\tbest estimator lgbm's best error=0.9445\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9436,\tbest estimator lgbm's best error=0.9436\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.8975,\tbest estimator lgbm's best error=0.8975\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator xgboost's best error=62.4459,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator xgboost's best error=62.4459,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator xgboost's best error=42.7612,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9459,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9459,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9459,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9269,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9249,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8956,\tbest estimator lgbm's best error=0.8956\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8877,\tbest estimator extra_tree's best error=0.8877\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8877,\tbest estimator extra_tree's best error=0.8877\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8667,\tbest estimator extra_tree's best error=0.8667\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8579,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8579,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8579,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9131,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8579,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8875,\tbest estimator extra_tree's best error=0.8579\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8518,\tbest estimator extra_tree's best error=0.8518\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8517,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8517,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8875,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8517,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8624,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8567,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8517,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8567,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8567,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8567,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8534,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8517,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8534,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8534,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9269,\tbest estimator extra_tree's best error=0.8517\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8373,\tbest estimator rf's best error=0.8373\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 60, current learner rf\n",
      "[flaml.automl: 05-16 13:43:55] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8373,\tbest estimator rf's best error=0.8373\n",
      "[flaml.automl: 05-16 13:43:55] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8339,\tbest estimator rf's best error=0.8339\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8339,\tbest estimator rf's best error=0.8339\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8339,\tbest estimator rf's best error=0.8339\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 64, current learner rf\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8339,\tbest estimator rf's best error=0.8339\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 66, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.8s,\testimator catboost's best error=0.9839,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 67, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 1.9s,\testimator catboost's best error=0.9839,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 68, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:56] {3343} INFO -  at 2.0s,\testimator catboost's best error=0.9733,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:43:56] {3166} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8316,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 70, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.5s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.5s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.5s,\testimator catboost's best error=0.9733,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.5s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 74, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.6s,\testimator catboost's best error=0.9668,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:57] {3343} INFO -  at 2.6s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:57] {3166} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 05-16 13:43:58] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8316,\tbest estimator rf's best error=0.8316\n",
      "[flaml.automl: 05-16 13:43:58] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:43:58] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8294,\tbest estimator rf's best error=0.8294\n",
      "[flaml.automl: 05-16 13:43:58] {3166} INFO - iteration 78, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:58] {3343} INFO -  at 3.9s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8294\n",
      "[flaml.automl: 05-16 13:43:58] {3166} INFO - iteration 79, current learner catboost\n",
      "[flaml.automl: 05-16 13:43:58] {3343} INFO -  at 4.0s,\testimator catboost's best error=0.9668,\tbest estimator rf's best error=0.8294\n",
      "[flaml.automl: 05-16 13:43:58] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 13:43:58] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8294,\tbest estimator rf's best error=0.8294\n",
      "[flaml.automl: 05-16 13:43:58] {3166} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:59] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8294\n",
      "[flaml.automl: 05-16 13:43:59] {3166} INFO - iteration 82, current learner rf\n",
      "[flaml.automl: 05-16 13:43:59] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:43:59] {3166} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:59] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:43:59] {3166} INFO - iteration 84, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:59] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:43:59] {3166} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 05-16 13:43:59] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:43:59] {3166} INFO - iteration 86, current learner rf\n",
      "[flaml.automl: 05-16 13:44:00] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:00] {3166} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:00] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:00] {3166} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 05-16 13:44:00] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:00] {3166} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=38.2893,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=38.2893,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=4.8215,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9168,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9168,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9168,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 96, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.0s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.1s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:01] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:01] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 7.1s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:02] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:02] {3166} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.6s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.0s,\testimator catboost's best error=0.9668,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.0s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:03] {3343} INFO -  at 9.1s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:03] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.1s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator catboost's best error=0.9668,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator xgboost's best error=0.9269,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator lgbm's best error=0.8956,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 9.3s,\testimator xgb_limitdepth's best error=0.9026,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:04] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:44:04] {3343} INFO -  at 10.0s,\testimator rf's best error=0.8289,\tbest estimator rf's best error=0.8289\n",
      "[flaml.automl: 05-16 13:44:05] {3602} INFO - retrain rf for 0.5s\n",
      "[flaml.automl: 05-16 13:44:05] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.3619584436755192, max_leaf_nodes=185,\n",
      "                      n_estimators=575, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:44:05] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:05] {2902} INFO - Time taken to find the best model: 4.662547826766968\n",
      "[flaml.tune.tune: 05-16 13:44:06] {198} INFO - result: {'energy_distance': 0.007764008681001577, 'estimator_name': 'backdoor.econml.metalearners.SLearner', 'scores': {'train': {'ate': -0.006565802010469489, 'ate_std': 0.07800842194070606, 'erupt': 17.93405447635838, 'norm_erupt': 17.854674109297296, 'qini': 1811.0318986712375, 'auc': 11.706011663819293, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143   False         True  0.000000\n",
      "2           1  16.795653  0.504143    True         True  1.951981\n",
      "3           1  17.168290  0.504143    True         True  1.951981\n",
      "4           0  17.372071  0.504143   False        False  1.984599\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143   False         True  1.984599\n",
      "6996        0  19.665493  0.504143   False        False  1.984599\n",
      "6997        1  13.684731  0.504143   False        False  0.000000\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143    True         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002806952873587676}, 'validation': {'ate': -0.00460211419662373, 'ate_std': 0.06682978571466049, 'erupt': 17.24346653068913, 'norm_erupt': 17.207696762445636, 'qini': 9.494302691059561, 'auc': 0.6762739009526914, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True        False  0.000000\n",
      "1           1  16.947004  0.504143   False        False  0.000000\n",
      "2           1  19.124658  0.504143   False        False  0.000000\n",
      "3           0  15.266764  0.504143   False        False  2.011866\n",
      "4           0  15.059235  0.504143    True        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  2.011866\n",
      "2996        1  16.902579  0.504143   False        False  0.000000\n",
      "2997        1  18.835211  0.504143    True        False  1.978801\n",
      "2998        0  14.982820  0.504143   False        False  2.011866\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007764008681001577}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}, 'experiment_tag': 'exp', 'time_total_s': 11.32034683227539}\n",
      "[flaml.tune.tune: 05-16 13:44:06] {636} INFO - trial 4 config: {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}\n",
      "[flaml.automl: 05-16 13:44:06] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:06] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:06] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:06] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:06] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3296} INFO - Estimated sufficient time budget=36s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9862,\tbest estimator lgbm's best error=0.9862\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9862,\tbest estimator lgbm's best error=0.9862\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9663,\tbest estimator lgbm's best error=0.9663\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator xgboost's best error=60.0645,\tbest estimator lgbm's best error=0.9663\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator extra_tree's best error=0.9172,\tbest estimator extra_tree's best error=0.9172\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.0s,\testimator rf's best error=0.8967,\tbest estimator rf's best error=0.8967\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9336,\tbest estimator rf's best error=0.8967\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8704,\tbest estimator rf's best error=0.8704\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9336,\tbest estimator rf's best error=0.8704\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9227,\tbest estimator rf's best error=0.8704\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8704,\tbest estimator rf's best error=0.8704\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator xgboost's best error=60.0645,\tbest estimator rf's best error=0.8704\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8456,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.8857,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.1s,\testimator xgboost's best error=41.0057,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.8857,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8456,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.8580,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9227,\tbest estimator rf's best error=0.8456\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.8335,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8335,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8335,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8335,\tbest estimator extra_tree's best error=0.8335\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8240,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8240,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 30, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8456,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9209,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8240,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8331,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8240,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 39, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9780,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9780,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 41, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9658,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8240,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.9209,\tbest estimator extra_tree's best error=0.8240\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8236,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8236,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9283,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8283,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9191,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8283,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8283,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:06] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8236,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:06] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8242,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8242,\tbest estimator extra_tree's best error=0.8236\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8178,\tbest estimator rf's best error=0.8178\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.0s,\testimator lgbm's best error=0.9209,\tbest estimator rf's best error=0.8178\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8178,\tbest estimator rf's best error=0.8178\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8155,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=36.7533,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=36.7533,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=4.5617,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9290,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9290,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9290,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8155,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8155\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:07] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:07] {3166} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:44:08] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:08] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 80, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 2.8s,\testimator catboost's best error=0.9658,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 83, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 90, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.9209,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 100, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:09] {3343} INFO -  at 3.7s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:09] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 3.9s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 3.9s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.9209,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 106, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 109, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.9209,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:44:10] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:10] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator lgbm's best error=0.9209,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.5s,\testimator lgbm's best error=0.9169,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 130, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 133, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:11] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:11] {3166} INFO - iteration 136, current learner rf\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.0s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.0s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 146, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.2s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 153, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.3s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8900,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8826,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 161, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:12] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:12] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8121,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.1s,\testimator extra_tree's best error=0.8236,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8121\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.4s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 168, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:13] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:13] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 174, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 175, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.0s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.1s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 182, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 185, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.3s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 186, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.4s,\testimator extra_tree's best error=0.8212,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.7s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 190, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.8s,\testimator catboost's best error=0.9582,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:14] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:14] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8119,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 193, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.1s,\testimator extra_tree's best error=0.8151,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 194, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.2s,\testimator extra_tree's best error=0.8151,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 196, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.5s,\testimator extra_tree's best error=0.8151,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.5s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.6s,\testimator extra_tree's best error=0.8151,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.7s,\testimator extra_tree's best error=0.8151,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.8973,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.8794,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 203, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:15] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9191,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:15] {3166} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 10.1s,\testimator extra_tree's best error=0.8139,\tbest estimator rf's best error=0.8119\n",
      "[flaml.automl: 05-16 13:44:16] {3602} INFO - retrain rf for 0.2s\n",
      "[flaml.automl: 05-16 13:44:16] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.44071236898197913, max_leaf_nodes=102,\n",
      "                      n_estimators=272, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:44:16] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:16] {2902} INFO - Time taken to find the best model: 7.4220662117004395\n",
      "[flaml.automl: 05-16 13:44:16] {2913} WARNING - Time taken to find the best model is 74% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl: 05-16 13:44:16] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:16] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:16] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:16] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:16] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:16] {3296} INFO - Estimated sufficient time budget=45s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9899,\tbest estimator lgbm's best error=0.9899\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9899,\tbest estimator lgbm's best error=0.9899\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9752,\tbest estimator lgbm's best error=0.9752\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.0s,\testimator xgboost's best error=63.1790,\tbest estimator lgbm's best error=0.9752\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.0s,\testimator extra_tree's best error=0.9378,\tbest estimator extra_tree's best error=0.9378\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9529,\tbest estimator extra_tree's best error=0.9378\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9546,\tbest estimator extra_tree's best error=0.9378\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9062,\tbest estimator rf's best error=0.9062\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 8, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9062,\tbest estimator rf's best error=0.9062\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8975,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator xgboost's best error=63.1790,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator xgboost's best error=43.1124,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9173,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9612,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9612,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9612,\tbest estimator rf's best error=0.8975\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9173,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9598,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 21, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 23, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator catboost's best error=0.9846,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 24, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator catboost's best error=0.9846,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 25, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator catboost's best error=0.9764,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9008,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8999,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 29, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9764,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 30, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:16] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:16] {3166} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 34, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 36, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8999,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 38, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 41, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 42, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.7s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.7s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8999,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 48, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.9s,\testimator xgb_limitdepth's best error=38.5734,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 49, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 0.9s,\testimator xgb_limitdepth's best error=38.5734,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=4.6846,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9554,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9554,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9554,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 55, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.0s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.2s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.2s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.2s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 71, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 73, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator xgboost's best error=0.9598,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator lgbm's best error=0.9546,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.3s,\testimator lgbm's best error=0.9494,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.9598,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 05-16 13:44:17] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:17] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8984,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8878,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8878,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8878,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8878,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8878,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.8s,\testimator lgbm's best error=0.9470,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.0s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.1s,\testimator lgbm's best error=0.9470,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8773,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8773\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.3s,\testimator lgbm's best error=0.9470,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.5s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8773,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.5s,\testimator lgbm's best error=0.9398,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.5s,\testimator lgbm's best error=0.9398,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:18] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:18] {3343} INFO -  at 2.5s,\testimator lgbm's best error=0.9398,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8751,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 130, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.7s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9398,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9598,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.9s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 2.9s,\testimator lgbm's best error=0.9273,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.0s,\testimator lgbm's best error=0.9273,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 143, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.0s,\testimator rf's best error=0.8751,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.1s,\testimator lgbm's best error=0.9273,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9252,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9252,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9252,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8751,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 152, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.9598,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 153, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 154, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8697,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9252,\tbest estimator extra_tree's best error=0.8697\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 156, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 158, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:44:19] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:19] {3166} INFO - iteration 161, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 163, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.7s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 167, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.7s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 168, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.7s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 172, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.9s,\testimator xgboost's best error=0.9598,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 175, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 3.9s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9369,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9598,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 180, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.1s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.1s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.2s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 184, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 186, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.3s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.4s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 189, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.4s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.4s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:44:20] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:20] {3166} INFO - iteration 193, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 194, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.9539,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 196, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 197, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8694,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 200, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 201, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8694\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 204, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.9s,\testimator xgboost's best error=0.9539,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.9s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.9s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 207, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 4.9s,\testimator xgboost's best error=0.9539,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 209, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 210, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 211, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.0s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.1s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 213, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.1s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 214, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 215, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 216, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.2s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.2s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 218, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 219, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 220, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 221, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.3s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 224, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.4s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.4s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 226, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 227, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 228, current learner rf\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 229, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:21] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:21] {3166} INFO - iteration 230, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 231, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 232, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.6s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 233, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 234, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 235, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 236, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.7s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 237, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 238, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 239, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 240, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.8s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 241, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.8s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.8s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 243, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.8s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 244, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 245, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.9s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 246, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 247, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 248, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.0s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 249, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 251, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.1s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 252, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.1s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 253, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.1s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 254, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.1s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 255, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 258, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 260, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.2s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 262, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 263, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.4s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 264, current learner rf\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 265, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.4s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 267, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:22] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:22] {3166} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 269, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 270, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 271, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 272, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.6s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 273, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 274, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 275, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 276, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 277, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 278, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 279, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 281, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.8s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 282, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 283, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 284, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 285, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 286, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 287, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 288, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.0s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 289, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 290, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.1s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 292, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.2s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 294, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.3s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 296, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 297, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.3s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 298, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 299, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 300, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 301, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 302, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 303, current learner rf\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:23] {3343} INFO -  at 7.5s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:23] {3166} INFO - iteration 305, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 306, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 307, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 308, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 309, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.6s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 310, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 311, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 312, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 313, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 314, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 315, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 316, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.8s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 317, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 318, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8678,\tbest estimator rf's best error=0.8678\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 319, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 320, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 321, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 322, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.0s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 323, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 324, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 325, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.1s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 326, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 327, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.1s,\testimator xgboost's best error=0.9480,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 328, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 329, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 330, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 331, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 332, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 333, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.9476,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 334, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 335, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.9476,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 336, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 337, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.5s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 338, current learner rf\n",
      "[flaml.automl: 05-16 13:44:24] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:24] {3166} INFO - iteration 339, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 340, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 342, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 343, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 344, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 345, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.8s,\testimator rf's best error=0.8652,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 346, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 348, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 349, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.9s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8652\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 350, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 351, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 352, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 353, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 354, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.0s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 355, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 356, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 357, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 358, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 359, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 360, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 361, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 362, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 363, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 364, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.3s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 366, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.4s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 367, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.4s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 368, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.4s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 369, current learner rf\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 370, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:25] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:25] {3166} INFO - iteration 371, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 372, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9309,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 373, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.6s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 374, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.6s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 375, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.7s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 376, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.7s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 378, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 379, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 380, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.8s,\testimator lgbm's best error=0.9252,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 381, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 382, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.9s,\testimator extra_tree's best error=0.8697,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 383, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.9s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 384, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 9.9s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 385, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 10.0s,\testimator rf's best error=0.8647,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 386, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 10.0s,\testimator catboost's best error=0.9715,\tbest estimator rf's best error=0.8647\n",
      "[flaml.automl: 05-16 13:44:26] {3602} INFO - retrain rf for 0.0s\n",
      "[flaml.automl: 05-16 13:44:26] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.6984322874514837, max_leaf_nodes=81,\n",
      "                      n_estimators=18, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:44:26] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:26] {2902} INFO - Time taken to find the best model: 8.896728992462158\n",
      "[flaml.automl: 05-16 13:44:26] {2913} WARNING - Time taken to find the best model is 89% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl: 05-16 13:44:26] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:26] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:26] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:26] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:26] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3296} INFO - Estimated sufficient time budget=44s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9997,\tbest estimator lgbm's best error=0.9997\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9997,\tbest estimator lgbm's best error=0.9997\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9995,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.1s,\testimator xgboost's best error=1.0739,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=1.0013,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.2s,\testimator rf's best error=1.0039,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9995,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.2s,\testimator rf's best error=1.0039,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 8, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.2s,\testimator rf's best error=1.0020,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9995,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.3s,\testimator rf's best error=1.0020,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.3s,\testimator xgboost's best error=1.0739,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.3s,\testimator xgboost's best error=1.0503,\tbest estimator lgbm's best error=0.9995\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9994,\tbest estimator extra_tree's best error=0.9994\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9994,\tbest estimator extra_tree's best error=0.9994\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9994,\tbest estimator extra_tree's best error=0.9994\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9995,\tbest estimator extra_tree's best error=0.9994\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9990,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:26] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9995,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:26] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.9990,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.9990,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.9990,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9991,\tbest estimator extra_tree's best error=0.9990\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 24, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 30, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.8s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 37, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.8s,\testimator catboost's best error=0.9991,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 38, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9991,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9988,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 55, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.2s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.3s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 60, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:27] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:27] {3166} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.5s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=1.0522,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=1.0522,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=1.0510,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.7s,\testimator catboost's best error=0.9988,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 77, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 78, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=1.0122,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=1.0108,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=1.0108,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 94, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 95, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=1.0028,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=1.0028,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.3s,\testimator lgbm's best error=0.9995,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 107, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.4s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:28] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:28] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.5s,\testimator lgbm's best error=0.9995,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.6s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.7s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9995,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.8s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=1.0014,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 131, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 2.9s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 132, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 133, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.0s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.0s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 136, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 137, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 138, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.1s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 140, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 142, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.2s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 143, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 144, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.3s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 145, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 146, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:44:29] {3343} INFO -  at 3.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:29] {3166} INFO - iteration 153, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.5s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 154, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.5s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.5s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.5s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 157, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 158, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 161, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 163, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 165, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.8s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.8s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 167, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.8s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 168, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.9s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 169, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.9s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 174, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 175, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 177, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.1s,\testimator extra_tree's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 178, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.1s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 180, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 181, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 182, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.2s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 186, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 188, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.4s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:30] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:30] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.5s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 191, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.5s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 193, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 194, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 195, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.6s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 196, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9967,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 197, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.7s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 200, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 201, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.8s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.9s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 205, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.9s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 206, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 4.9s,\testimator extra_tree's best error=0.9981,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 207, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.0s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 209, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 210, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 211, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 212, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 213, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.2s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 214, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.2s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 215, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.2s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 216, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 217, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 218, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 219, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 220, current learner rf\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 221, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.4s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:31] {3343} INFO -  at 5.4s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:31] {3166} INFO - iteration 223, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 224, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.5s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 226, current learner rf\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 227, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 228, current learner rf\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.6s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 229, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 230, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 231, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 232, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.8s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 233, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.8s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 234, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.8s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 235, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.9s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 236, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 5.9s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 237, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 238, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 239, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.0s,\testimator catboost's best error=0.9987,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 240, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 241, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.1s,\testimator lgbm's best error=0.9990,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 243, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 244, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.2s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 245, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 246, current learner rf\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.3s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 247, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 248, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.4s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 249, current learner rf\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.4s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:32] {3343} INFO -  at 6.4s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:32] {3166} INFO - iteration 251, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.5s,\testimator lgbm's best error=0.9962,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 253, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.5s,\testimator lgbm's best error=0.9962,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 254, current learner rf\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.5s,\testimator rf's best error=0.9934,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 255, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.6s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.9962,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 257, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.6s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 258, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.9962,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 259, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 260, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator lgbm's best error=0.9962,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator extra_tree's best error=0.9935,\tbest estimator rf's best error=0.9934\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 262, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 263, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 264, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 265, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 266, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 267, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 268, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 269, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 270, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 272, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 274, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 275, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 277, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 279, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 280, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 281, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 282, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 283, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 284, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 285, current learner rf\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.1s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 286, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.2s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 287, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.2s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 288, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 289, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 290, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.3s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 292, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.3s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.4s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 294, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.4s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 295, current learner rf\n",
      "[flaml.automl: 05-16 13:44:33] {3343} INFO -  at 7.5s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:33] {3166} INFO - iteration 296, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.5s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 297, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.5s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 298, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.5s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 299, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 300, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 302, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 304, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.7s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 305, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 306, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 307, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 308, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 309, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 310, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 311, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 312, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 313, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 7.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 314, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.0s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 315, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 316, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.0s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 317, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.0s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 318, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 319, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 320, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 321, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 322, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.1s,\testimator xgboost's best error=0.9967,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 323, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 324, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 325, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 326, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 327, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.2s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 328, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 329, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 330, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.3s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 331, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 332, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.4s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 333, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.4s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 334, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.4s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 335, current learner rf\n",
      "[flaml.automl: 05-16 13:44:34] {3343} INFO -  at 8.5s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:34] {3166} INFO - iteration 336, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.5s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 337, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.5s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 338, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.5s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 339, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.5s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 340, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 342, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 343, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 344, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 345, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.7s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 346, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 347, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 348, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 349, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.9s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 350, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 351, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 8.9s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 352, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.0s,\testimator catboost's best error=0.9987,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 353, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.0s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 354, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.1s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 356, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.1s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 357, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.1s,\testimator xgboost's best error=0.9967,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 358, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.1s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 359, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 360, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.2s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 361, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.2s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 362, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.3s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 363, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.3s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 364, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.3s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 365, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.3s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 366, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.4s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 367, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.4s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 368, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.4s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 369, current learner rf\n",
      "[flaml.automl: 05-16 13:44:35] {3343} INFO -  at 9.4s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:35] {3166} INFO - iteration 370, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.5s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 371, current learner rf\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.5s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 372, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 373, current learner rf\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 374, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 375, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 376, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 378, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 379, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.7s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 380, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 381, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.7s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 382, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.8s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 383, current learner rf\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.8s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 384, current learner rf\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.8s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 385, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 386, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.9s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 387, current learner rf\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.9s,\testimator rf's best error=0.9934,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 388, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 9.9s,\testimator extra_tree's best error=0.9935,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 389, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 390, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 391, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 392, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9922,\tbest estimator lgbm's best error=0.9922\n",
      "[flaml.automl: 05-16 13:44:36] {3602} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl: 05-16 13:44:36] {3609} INFO - retrained model: LGBMRegressor(colsample_bytree=0.9603305047713148,\n",
      "              learning_rate=0.47279020352633505, max_bin=127,\n",
      "              min_child_samples=9, n_estimators=2, num_leaves=47,\n",
      "              reg_alpha=0.0009765625, reg_lambda=20.176924674987667,\n",
      "              verbose=-1)\n",
      "[flaml.automl: 05-16 13:44:36] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:36] {2902} INFO - Time taken to find the best model: 6.726263999938965\n",
      "[flaml.tune.tune: 05-16 13:44:36] {198} INFO - result: {'energy_distance': 0.007811658483262818, 'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner', 'scores': {'train': {'ate': -0.008352966097185024, 'ate_std': 0.14849790617109038, 'erupt': 17.443504347147385, 'norm_erupt': 17.466836644400935, 'qini': 663.7707409324361, 'auc': 3.7403667604487354, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143   False        False  0.000000\n",
      "2           1  16.795653  0.504143   False        False  0.000000\n",
      "3           1  17.168290  0.504143    True         True  1.930856\n",
      "4           0  17.372071  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143    True         True  0.000000\n",
      "6996        0  19.665493  0.504143    True         True  0.000000\n",
      "6997        1  13.684731  0.504143   False        False  0.000000\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143    True         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002709131722763658}, 'validation': {'ate': -0.006819822152761669, 'ate_std': 0.14556569342588407, 'erupt': 17.18495758982961, 'norm_erupt': 17.150404379317425, 'qini': -57.026623079905185, 'auc': -0.0296730377932738, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True        False  0.000000\n",
      "1           1  16.947004  0.504143    True        False  1.968895\n",
      "2           1  19.124658  0.504143    True        False  1.968895\n",
      "3           0  15.266764  0.504143   False        False  2.001796\n",
      "4           0  15.059235  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  2.001796\n",
      "2996        1  16.902579  0.504143    True        False  1.968895\n",
      "2997        1  18.835211  0.504143   False        False  0.000000\n",
      "2998        0  14.982820  0.504143    True        False  0.000000\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007811658483262818}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}, 'experiment_tag': 'exp', 'time_total_s': 30.705240726470947}\n",
      "[flaml.tune.tune: 05-16 13:44:36] {636} INFO - trial 5 config: {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}}\n",
      "[flaml.automl: 05-16 13:44:36] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:36] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:36] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:36] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:36] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3296} INFO - Estimated sufficient time budget=44s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9865,\tbest estimator lgbm's best error=0.9865\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9865,\tbest estimator lgbm's best error=0.9865\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9659,\tbest estimator lgbm's best error=0.9659\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:36] {3343} INFO -  at 0.1s,\testimator xgboost's best error=61.4695,\tbest estimator lgbm's best error=0.9659\n",
      "[flaml.automl: 05-16 13:44:36] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9288,\tbest estimator extra_tree's best error=0.9288\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9213,\tbest estimator rf's best error=0.9213\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9328,\tbest estimator rf's best error=0.9213\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9328,\tbest estimator rf's best error=0.9213\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9203,\tbest estimator lgbm's best error=0.9203\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9203,\tbest estimator lgbm's best error=0.9203\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9171,\tbest estimator lgbm's best error=0.9171\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 11, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8896,\tbest estimator rf's best error=0.8896\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8896,\tbest estimator rf's best error=0.8896\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.3s,\testimator xgboost's best error=61.4695,\tbest estimator rf's best error=0.8896\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8770,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8826,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8770,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8826,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8770,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8797,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=41.9194,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8797,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8797,\tbest estimator rf's best error=0.8770\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 30, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8695,\tbest estimator rf's best error=0.8695\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8520,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9431,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9274,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 39, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9802,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9802,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 41, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9686,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 42, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9686,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 1.0s,\testimator lgbm's best error=0.9171,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8520,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8669,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 47, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:37] {3343} INFO -  at 1.1s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:37] {3166} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8520\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8478,\tbest estimator rf's best error=0.8478\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.2s,\testimator xgboost's best error=0.9274,\tbest estimator rf's best error=0.8478\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8478\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8478,\tbest estimator rf's best error=0.8478\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8478,\tbest estimator rf's best error=0.8478\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator lgbm's best error=0.9171,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=37.5521,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=37.5521,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=4.5345,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9256,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9256,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 63, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.9s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9256,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 2.0s,\testimator xgboost's best error=0.9274,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 68, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 69, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:38] {3343} INFO -  at 2.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:38] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.4s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 83, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.6s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.6s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.9s,\testimator extra_tree's best error=0.8587,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 2.9s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 3.0s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 98, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 3.0s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 3.0s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 100, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:39] {3343} INFO -  at 3.0s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:39] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.1s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.2s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9171,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.2s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 109, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.3s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.4s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.5s,\testimator lgbm's best error=0.9129,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9129,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9129,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9102,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.8s,\testimator extra_tree's best error=0.8528,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9102,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9102,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9102,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9102,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 3.9s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:44:40] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:40] {3166} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.1s,\testimator lgbm's best error=0.9051,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 143, current learner rf\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.3s,\testimator extra_tree's best error=0.8518,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 146, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.4s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9051,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9051,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.5s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 154, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.5s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8518,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.7s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.8s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 167, current learner rf\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.0s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.0s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.1s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:41] {3343} INFO -  at 5.1s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:41] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.1s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.1s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8444,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.4s,\testimator extra_tree's best error=0.8518,\tbest estimator rf's best error=0.8444\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.7s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 194, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.7s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 196, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.8s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.9s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 204, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.9s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 207, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 6.0s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:42] {3343} INFO -  at 6.0s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:42] {3166} INFO - iteration 210, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.1s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 211, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.2s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 213, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.3s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 216, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 221, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.5s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 226, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 227, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 230, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.7s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 232, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.7s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.7s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 236, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 237, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.9s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 239, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 240, current learner rf\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 241, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 7.0s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 7.0s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 243, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:43] {3343} INFO -  at 7.1s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:43] {3166} INFO - iteration 244, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 245, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 246, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 248, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.2s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 249, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 250, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 251, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.3s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.3s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 253, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 254, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.4s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.4s,\testimator lgbm's best error=0.8962,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 258, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 260, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.6s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 262, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.6s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 263, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.7s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 264, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 265, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.7s,\testimator catboost's best error=0.9615,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.8s,\testimator extra_tree's best error=0.8518,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.8s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.8s,\testimator extra_tree's best error=0.8518,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 269, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 271, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 272, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 7.9s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 273, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 274, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 275, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 276, current learner rf\n",
      "[flaml.automl: 05-16 13:44:44] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:44] {3166} INFO - iteration 277, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 278, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.2s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 279, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 281, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.2s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 282, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 283, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 284, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 285, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 288, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.5s,\testimator xgboost's best error=0.9179,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 289, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 290, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 291, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 292, current learner rf\n",
      "[flaml.automl: 05-16 13:44:45] {3343} INFO -  at 8.6s,\testimator rf's best error=0.8433,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:45] {3166} INFO - iteration 293, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:46] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8433\n",
      "[flaml.automl: 05-16 13:44:47] {3602} INFO - retrain rf for 0.1s\n",
      "[flaml.automl: 05-16 13:44:47] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.5908170731427957, max_leaf_nodes=84,\n",
      "                      n_estimators=24, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:44:47] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:47] {2902} INFO - Time taken to find the best model: 5.445199251174927\n",
      "[flaml.automl: 05-16 13:44:47] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:47] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:47] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:47] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:47] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3296} INFO - Estimated sufficient time budget=50s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9892,\tbest estimator lgbm's best error=0.9892\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9892,\tbest estimator lgbm's best error=0.9892\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9729,\tbest estimator lgbm's best error=0.9729\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.1s,\testimator xgboost's best error=61.2384,\tbest estimator lgbm's best error=0.9729\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9408,\tbest estimator extra_tree's best error=0.9408\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9384,\tbest estimator rf's best error=0.9384\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9453,\tbest estimator rf's best error=0.9384\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9453,\tbest estimator rf's best error=0.9384\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9440,\tbest estimator rf's best error=0.9384\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8797,\tbest estimator rf's best error=0.8797\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8797,\tbest estimator rf's best error=0.8797\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 11, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.3s,\testimator xgboost's best error=61.2384,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8940,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8940,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8700,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8700,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8700,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8633,\tbest estimator rf's best error=0.8633\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8565,\tbest estimator extra_tree's best error=0.8565\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8633,\tbest estimator extra_tree's best error=0.8565\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8503,\tbest estimator rf's best error=0.8503\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8473,\tbest estimator extra_tree's best error=0.8473\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8473,\tbest estimator extra_tree's best error=0.8473\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.6s,\testimator xgboost's best error=41.8643,\tbest estimator extra_tree's best error=0.8473\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8471,\tbest estimator extra_tree's best error=0.8471\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8449,\tbest estimator extra_tree's best error=0.8449\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8449,\tbest estimator extra_tree's best error=0.8449\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 30, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8503,\tbest estimator extra_tree's best error=0.8449\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8503,\tbest estimator extra_tree's best error=0.8449\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9522,\tbest estimator extra_tree's best error=0.8449\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8354,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9522,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9522,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8354,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:47] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:47] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8354,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 39, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.0s,\testimator catboost's best error=0.9824,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.0s,\testimator catboost's best error=0.9824,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 41, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.1s,\testimator catboost's best error=0.9723,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8354,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.1s,\testimator lgbm's best error=0.9440,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8354,\tbest estimator extra_tree's best error=0.8354\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 47, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.4s,\testimator catboost's best error=0.9723,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8503,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.5s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 53, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.6s,\testimator catboost's best error=0.9661,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8378,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 55, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8378,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.7s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8378,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8378,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.8s,\testimator catboost's best error=0.9661,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 60, current learner rf\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8378,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:48] {3343} INFO -  at 1.9s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:48] {3166} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=37.5411,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=37.5411,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=4.7502,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9423,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9423,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9423,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.6s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 80, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator xgboost's best error=0.9377,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9105,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:49] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:49] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.1s,\testimator catboost's best error=0.9661,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8350,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.9332,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.4s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.8339,\tbest estimator extra_tree's best error=0.8339\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 98, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.9332,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:50] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:50] {3166} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9332,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.9412,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.2s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9412,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.3s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.4s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.5s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.5s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.9407,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:51] {3343} INFO -  at 4.8s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:51] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 126, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.1s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 127, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8328,\tbest estimator rf's best error=0.8328\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.7s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 139, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.9s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:44:52] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:52] {3166} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 143, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.1s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.1s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 146, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.1s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 150, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.4s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.5s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.5s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.9298,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.8919,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 157, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.6s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.8919,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.6s,\testimator lgbm's best error=0.8919,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.7s,\testimator lgbm's best error=0.8919,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 161, current learner rf\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.8888,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.8s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:53] {3343} INFO -  at 6.9s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:53] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 167, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.0s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.0s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.1s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.1s,\testimator lgbm's best error=0.8888,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.2s,\testimator lgbm's best error=0.8888,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 173, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.2s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.2s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.2s,\testimator xgboost's best error=0.9132,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.3s,\testimator xgboost's best error=0.9121,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 180, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.6s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 182, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.6s,\testimator xgboost's best error=0.9121,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.8888,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 186, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.8s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 8.0s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:54] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.8848,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:54] {3166} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.8848,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.0s,\testimator extra_tree's best error=0.8339,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.8848,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 193, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 194, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 196, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.8846,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.4s,\testimator extra_tree's best error=0.8337,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.5s,\testimator lgbm's best error=0.8846,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.6s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 204, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.6s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 207, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.7s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 209, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.7s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 210, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 211, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 212, current learner rf\n",
      "[flaml.automl: 05-16 13:44:55] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:55] {3166} INFO - iteration 213, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 216, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.9038,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 218, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 219, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 220, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.4s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 221, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.5s,\testimator lgbm's best error=0.8846,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 224, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.5s,\testimator xgboost's best error=0.9121,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.8846,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 226, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.7s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 227, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 228, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 229, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.9121,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 230, current learner rf\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.9s,\testimator rf's best error=0.8319,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 232, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.9121,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:56] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9002,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:56] {3166} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8890,\tbest estimator rf's best error=0.8319\n",
      "[flaml.automl: 05-16 13:44:57] {3602} INFO - retrain rf for 0.1s\n",
      "[flaml.automl: 05-16 13:44:57] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.7556988971560713, max_leaf_nodes=91,\n",
      "                      n_estimators=46, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:44:57] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:44:57] {2902} INFO - Time taken to find the best model: 5.439824819564819\n",
      "[flaml.tune.tune: 05-16 13:44:57] {198} INFO - result: {'energy_distance': 0.008243371826370804, 'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'scores': {'train': {'ate': -0.024227710415625374, 'ate_std': 0.21478544936869173, 'erupt': 17.907722428149462, 'norm_erupt': 17.92263818379696, 'qini': 1687.4501078956298, 'auc': 10.850242444701168, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143   False        False  0.000000\n",
      "2           1  16.795653  0.504143   False        False  0.000000\n",
      "3           1  17.168290  0.504143   False        False  0.000000\n",
      "4           0  17.372071  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143   False        False  2.023275\n",
      "6996        0  19.665493  0.504143   False         True  2.023275\n",
      "6997        1  13.684731  0.504143    True         True  1.990022\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143    True         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002897752307350565}, 'validation': {'ate': -0.02133457544950064, 'ate_std': 0.1862610237041336, 'erupt': 17.183964301397847, 'norm_erupt': 17.145511251031294, 'qini': -36.59962254439172, 'auc': 0.1961853871599913, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True        False  0.000000\n",
      "1           1  16.947004  0.504143   False        False  0.000000\n",
      "2           1  19.124658  0.504143    True         True  1.968112\n",
      "3           0  15.266764  0.504143   False        False  2.000999\n",
      "4           0  15.059235  0.504143   False        False  2.000999\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  2.000999\n",
      "2996        1  16.902579  0.504143    True         True  1.968112\n",
      "2997        1  18.835211  0.504143    True         True  1.968112\n",
      "2998        0  14.982820  0.504143   False        False  2.000999\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.008243371826370804}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'subforest_size': 4}, 'experiment_tag': 'exp', 'time_total_s': 20.80683183670044}\n",
      "[flaml.tune.tune: 05-16 13:44:57] {636} INFO - trial 6 config: {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': 1, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'fit_intercept': 1, 'subforest_size': 4}}\n",
      "[flaml.automl: 05-16 13:44:57] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:44:57] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:44:57] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:44:57] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:44:57] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:57] {3296} INFO - Estimated sufficient time budget=54s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9859,\tbest estimator lgbm's best error=0.9859\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9859,\tbest estimator lgbm's best error=0.9859\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9661,\tbest estimator lgbm's best error=0.9661\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9398,\tbest estimator lgbm's best error=0.9398\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.1s,\testimator xgboost's best error=64.4929,\tbest estimator lgbm's best error=0.9398\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9338,\tbest estimator extra_tree's best error=0.9338\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 6, current learner rf\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9267,\tbest estimator rf's best error=0.9267\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8841,\tbest estimator rf's best error=0.8841\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 8, current learner rf\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8841,\tbest estimator rf's best error=0.8841\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8820,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8820,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.2s,\testimator xgboost's best error=64.4929,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9126,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:57] {3343} INFO -  at 0.3s,\testimator xgboost's best error=43.9697,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:57] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8820,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9126,\tbest estimator rf's best error=0.8820\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8814,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8954,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 18, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.4s,\testimator catboost's best error=0.9783,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.9398,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 20, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9783,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 21, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8814\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8632,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.7s,\testimator lgbm's best error=0.9389,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8632,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8632,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8632\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8619,\tbest estimator rf's best error=0.8619\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8619\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8619\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8568,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9469,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8568,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:58] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9439,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:58] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8568,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8568,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8850,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8568,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=39.3540,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=39.3540,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 55, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=4.7748,\tbest estimator rf's best error=0.8568\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8548,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9426,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9426,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9426,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8548,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8768,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8548,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8768,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8548,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 67, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.9s,\testimator catboost's best error=0.9661,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8548,\tbest estimator rf's best error=0.8548\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 71, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.0s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.1s,\testimator xgboost's best error=0.9439,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 73, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.1s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 75, current learner catboost\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.1s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:44:59] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:44:59] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 79, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8723,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.7s,\testimator extra_tree's best error=0.8723,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8723,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9439,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8723,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 3.0s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 3.0s,\testimator rf's best error=0.8544,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8544\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:00] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:00] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8666,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.8632,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.7s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 98, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.7s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.8s,\testimator extra_tree's best error=0.8632,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 103, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 4.2s,\testimator xgboost's best error=0.9439,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:01] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.9389,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:01] {3166} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8632,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.6s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 107, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.6s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8482,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9347,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator lgbm's best error=0.9387,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8482\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:45:02] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:02] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 6.1s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:03] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:03] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:45:04] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:04] {3166} INFO - iteration 126, current learner rf\n",
      "[flaml.automl: 05-16 13:45:04] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:04] {3166} INFO - iteration 127, current learner rf\n",
      "[flaml.automl: 05-16 13:45:04] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:04] {3166} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 8.1s,\testimator extra_tree's best error=0.8576,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.8576,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:05] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:05] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:45:06] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:06] {3166} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:06] {3343} INFO -  at 8.5s,\testimator catboost's best error=0.9587,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:06] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:06] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.8513,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:06] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:06] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9231,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:06] {3166} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:06] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.8513,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:06] {3166} INFO - iteration 139, current learner rf\n",
      "[flaml.automl: 05-16 13:45:07] {3343} INFO -  at 9.7s,\testimator rf's best error=0.8467,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:07] {3166} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:07] {3343} INFO -  at 9.8s,\testimator extra_tree's best error=0.8513,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:07] {3166} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:07] {3343} INFO -  at 10.1s,\testimator extra_tree's best error=0.8513,\tbest estimator rf's best error=0.8467\n",
      "[flaml.automl: 05-16 13:45:08] {3602} INFO - retrain rf for 0.2s\n",
      "[flaml.automl: 05-16 13:45:08] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.3777350466925546, max_leaf_nodes=70,\n",
      "                      n_estimators=299, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:45:08] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:45:08] {2902} INFO - Time taken to find the best model: 4.9945549964904785\n",
      "[flaml.automl: 05-16 13:45:08] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:45:08] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:45:08] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:45:08] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:45:08] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3296} INFO - Estimated sufficient time budget=43s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9895,\tbest estimator lgbm's best error=0.9895\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9895,\tbest estimator lgbm's best error=0.9895\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9711,\tbest estimator lgbm's best error=0.9711\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.0s,\testimator xgboost's best error=64.3058,\tbest estimator lgbm's best error=0.9711\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9347,\tbest estimator extra_tree's best error=0.9347\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9360,\tbest estimator extra_tree's best error=0.9347\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9429,\tbest estimator extra_tree's best error=0.9347\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9429,\tbest estimator extra_tree's best error=0.9347\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9294,\tbest estimator lgbm's best error=0.9294\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8857,\tbest estimator rf's best error=0.8857\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8857,\tbest estimator rf's best error=0.8857\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 11, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8763,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.3s,\testimator xgboost's best error=64.3058,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8991,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8991,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8812,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8763,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8812,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8763,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8812,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.5s,\testimator xgboost's best error=43.7401,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8812,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8763,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8763,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8812,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 25, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9824,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8768,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 27, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9824,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 28, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.7s,\testimator catboost's best error=0.9717,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8768,\tbest estimator rf's best error=0.8763\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8729,\tbest estimator extra_tree's best error=0.8729\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8689,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9294,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8689,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8729,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:45:08] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8689,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:08] {3166} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9717,\tbest estimator rf's best error=0.8689\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8670,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.0s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8670,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.1s,\testimator lgbm's best error=0.9264,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8670,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8670,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.3s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8689,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8670,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.6s,\testimator lgbm's best error=0.9264,\tbest estimator extra_tree's best error=0.8670\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 51, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.6s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.8s,\testimator lgbm's best error=0.9264,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.8s,\testimator lgbm's best error=0.9264,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:45:09] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:09] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=39.1509,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=39.1509,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=4.6706,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 61, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9418,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9418,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9418,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.0s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 68, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.1s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.2s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.2s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.2s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 75, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.4s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 78, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.4s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 81, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.5s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8633,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9388,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 87, current learner rf\n",
      "[flaml.automl: 05-16 13:45:10] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:10] {3166} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8633,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.1s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.1s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9362,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 92, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9358,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 94, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 95, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.4s,\testimator extra_tree's best error=0.8616,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 98, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 99, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 101, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8616,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 103, current learner rf\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.7s,\testimator rf's best error=0.8574,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.9163,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 105, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.8s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 106, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9141,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 107, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:11] {3343} INFO -  at 3.8s,\testimator catboost's best error=0.9650,\tbest estimator rf's best error=0.8574\n",
      "[flaml.automl: 05-16 13:45:11] {3166} INFO - iteration 108, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.1s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.3s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9358,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:45:12] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:12] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 118, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.2s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.2s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 123, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:13] {3343} INFO -  at 5.8s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:13] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 130, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.4s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.4s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 132, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.4s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 136, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.6s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 137, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.8s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 138, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.8s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:14] {3343} INFO -  at 6.8s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:14] {3166} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.1s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.2s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 143, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.5s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.6s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 146, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.6s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.8s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:15] {3343} INFO -  at 7.9s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:15] {3166} INFO - iteration 154, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 7.9s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.0s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 156, current learner rf\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.9358,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 158, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.1s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.4s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9358,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 167, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.7s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.7s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:16] {3343} INFO -  at 8.9s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:16] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8574,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.1s,\testimator xgboost's best error=0.9388,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 175, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.1s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8569,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9343,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 178, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.2s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 179, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.5s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 180, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.6s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9343,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.7s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 183, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.8s,\testimator catboost's best error=0.9650,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.8s,\testimator lgbm's best error=0.9141,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 185, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9229,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9229,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 187, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:17] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9229,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:17] {3166} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:18] {3343} INFO -  at 10.1s,\testimator extra_tree's best error=0.8535,\tbest estimator extra_tree's best error=0.8535\n",
      "[flaml.automl: 05-16 13:45:18] {3602} INFO - retrain extra_tree for 0.2s\n",
      "[flaml.automl: 05-16 13:45:18] {3609} INFO - retrained model: ExtraTreesRegressor(max_features=0.4149915620614688, max_leaf_nodes=72,\n",
      "                    n_estimators=256, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:45:18] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:45:18] {2902} INFO - Time taken to find the best model: 3.9588239192962646\n",
      "[flaml.tune.tune: 05-16 13:45:19] {198} INFO - result: {'energy_distance': 0.008053585143262154, 'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'scores': {'train': {'ate': -0.020070687483386484, 'ate_std': 0.2152335364926314, 'erupt': 17.840157332252325, 'norm_erupt': 17.864604771180336, 'qini': 1579.0646624709802, 'auc': 10.287888355606901, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143   False        False  0.000000\n",
      "2           1  16.795653  0.504143   False        False  0.000000\n",
      "3           1  17.168290  0.504143   False        False  0.000000\n",
      "4           0  17.372071  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143   False        False  1.993745\n",
      "6996        0  19.665493  0.504143   False        False  1.993745\n",
      "6997        1  13.684731  0.504143   False        False  0.000000\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143   False        False  1.993745\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0028599526843464673}, 'validation': {'ate': -0.014002515929301185, 'ate_std': 0.19367408571430883, 'erupt': 17.184388889735345, 'norm_erupt': 17.176205404620468, 'qini': -43.85204974446121, 'auc': 0.03670597938695732, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True         True  0.000000\n",
      "1           1  16.947004  0.504143   False        False  0.000000\n",
      "2           1  19.124658  0.504143   False        False  0.000000\n",
      "3           0  15.266764  0.504143   False        False  2.001043\n",
      "4           0  15.059235  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  2.001043\n",
      "2996        1  16.902579  0.504143    True         True  1.968155\n",
      "2997        1  18.835211  0.504143    True        False  1.968155\n",
      "2998        0  14.982820  0.504143   False        False  2.001043\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.008053585143262154}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': 1, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'fit_intercept': 1, 'subforest_size': 4}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': 1, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': 1, 'fit_intercept': 1, 'subforest_size': 4}, 'experiment_tag': 'exp', 'time_total_s': 21.454922914505005}\n",
      "[flaml.tune.tune: 05-16 13:45:19] {636} INFO - trial 7 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}\n",
      "[flaml.automl: 05-16 13:45:19] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:45:19] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:45:19] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:45:19] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:45:19] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3296} INFO - Estimated sufficient time budget=73s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator xgboost's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator xgboost's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9999,\tbest estimator lgbm's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.1s,\testimator xgboost's best error=0.9999,\tbest estimator xgboost's best error=0.9999\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9997,\tbest estimator extra_tree's best error=0.9997\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9997,\tbest estimator extra_tree's best error=0.9997\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9997,\tbest estimator extra_tree's best error=0.9997\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 15, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.3s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.3s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 17, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.3s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.3s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 19, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator catboost's best error=1.0004,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 20, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator catboost's best error=1.0003,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 21, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 24, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 25, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.5s,\testimator catboost's best error=1.0003,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 28, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9999,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 30, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.7s,\testimator catboost's best error=1.0002,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9999,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:45:19] {3343} INFO -  at 0.8s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:19] {3166} INFO - iteration 36, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 0.9s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 38, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 39, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=1.0027,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 40, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 41, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 42, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.0s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.1s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 45, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.1s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 46, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.2s,\testimator xgb_limitdepth's best error=0.9997,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 47, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.2s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 48, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.2s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 49, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.2s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.3s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 55, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.4s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.9999,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9986,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9984,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.6s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9984,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.7s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9984,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:20] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9984,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:20] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 1.9s,\testimator rf's best error=0.9981,\tbest estimator rf's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 77, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 78, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 81, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.1s,\testimator xgboost's best error=0.9996,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.2s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 89, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.9996,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 90, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 101, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.6s,\testimator catboost's best error=1.0002,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.6s,\testimator lgbm's best error=0.9999,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.7s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 107, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.7s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.8s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:21] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:21] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9999,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator lgbm's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9981\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.2s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 131, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9987,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.4s,\testimator lgbm's best error=0.9986,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 136, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9986,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.6s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 146, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9986,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:22] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9986,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:22] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 3.8s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 3.8s,\testimator lgbm's best error=0.9986,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 3.9s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 153, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 154, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 158, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 163, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.2s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 168, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.5s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.5s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 175, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.5s,\testimator catboost's best error=1.0002,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 179, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.7s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 180, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.7s,\testimator catboost's best error=1.0001,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 182, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 185, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:23] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:23] {3166} INFO - iteration 186, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.9s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.9s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.9s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.9s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 4.9s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.0s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 193, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.0s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 194, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.0s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.0s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.0s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.9980,\tbest estimator xgb_limitdepth's best error=0.9980\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.2s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.2s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.2s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 207, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 209, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 210, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.4s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 211, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9978,\tbest estimator xgb_limitdepth's best error=0.9978\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 212, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9977,\tbest estimator xgb_limitdepth's best error=0.9977\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 213, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9977,\tbest estimator xgb_limitdepth's best error=0.9977\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 216, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 218, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 219, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 220, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 221, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 226, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 227, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 228, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 230, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9976,\tbest estimator xgb_limitdepth's best error=0.9976\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 232, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 236, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 237, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:24] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:24] {3166} INFO - iteration 239, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 240, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 241, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 243, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 244, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 245, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 246, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 5.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 248, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 249, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 250, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 251, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 252, current learner rf\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.1s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 253, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 254, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 258, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 260, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 262, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 263, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 264, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 265, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 266, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 268, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 269, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 271, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 272, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 273, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 274, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 275, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 276, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 277, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 278, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 279, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 281, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 282, current learner rf\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 283, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 284, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 285, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 288, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 289, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.7s,\testimator catboost's best error=1.0001,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 290, current learner rf\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.8s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 291, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 292, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 293, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:25] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:25] {3166} INFO - iteration 294, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 295, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 296, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 297, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 298, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 299, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 300, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator extra_tree's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 302, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 6.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 303, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 305, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.1s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 306, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 307, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 308, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 309, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 310, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.2s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 311, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 312, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 313, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.3s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 314, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 315, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.3s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 316, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 317, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 318, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 319, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 320, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.5s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 321, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 322, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 323, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.7s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 324, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.7s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 325, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 326, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 327, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 328, current learner rf\n",
      "[flaml.automl: 05-16 13:45:26] {3343} INFO -  at 7.8s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:26] {3166} INFO - iteration 329, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 7.9s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 330, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 7.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 331, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 7.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 332, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 7.9s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 333, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 334, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 335, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 336, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 337, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 338, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.1s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 339, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 340, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 342, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 343, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 344, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 345, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 346, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 348, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 349, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 350, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.3s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 351, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 352, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 353, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 354, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.4s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 356, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 357, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 358, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.5s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 359, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.5s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 360, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 361, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.5s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 362, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 363, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 364, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 366, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.7s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 367, current learner rf\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.8s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 368, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 369, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 370, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 371, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:27] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:27] {3166} INFO - iteration 372, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 373, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 8.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 374, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 8.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 375, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 8.9s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 376, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 8.9s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 378, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 379, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.0s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 380, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.1s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 381, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.1s,\testimator extra_tree's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 382, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 383, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 384, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 385, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.2s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 386, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 387, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 388, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 389, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.3s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 390, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.3s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 391, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.4s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 392, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 393, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 394, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.4s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 395, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 396, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.5s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 397, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 398, current learner rf\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 399, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 400, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 401, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 402, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator extra_tree's best error=0.9997,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 403, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 404, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 405, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 406, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 407, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:28] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:28] {3166} INFO - iteration 408, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 9.8s,\testimator lgbm's best error=0.9982,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 409, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 410, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 411, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9965,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 412, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 9.9s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 413, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 10.0s,\testimator rf's best error=0.9981,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 414, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.9995,\tbest estimator xgb_limitdepth's best error=0.9965\n",
      "[flaml.automl: 05-16 13:45:29] {3602} INFO - retrain xgb_limitdepth for 0.0s\n",
      "[flaml.automl: 05-16 13:45:29] {3609} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.4937237192178395, colsample_bynode=None,\n",
      "             colsample_bytree=0.8148299762590895, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=1.0, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=15.31778710264314, missing=nan,\n",
      "             monotone_constraints=None, n_estimators=1, n_jobs=-1,\n",
      "             num_parallel_tree=None, predictor=None, random_state=None, ...)\n",
      "[flaml.automl: 05-16 13:45:29] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:45:29] {2902} INFO - Time taken to find the best model: 5.741542816162109\n",
      "[flaml.tune.tune: 05-16 13:45:29] {198} INFO - result: {'energy_distance': 0.07107670172812242, 'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome', 'scores': {'train': {'ate': 0.16417742, 'ate_std': 2.2719476, 'erupt': 17.20924732666143, 'norm_erupt': 17.23224183126819, 'qini': 135.73229287475615, 'auc': 0.2268873794779925, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143   False        False  0.000000\n",
      "2           1  16.795653  0.504143    True         True  1.827768\n",
      "3           1  17.168290  0.504143    True         True  1.827768\n",
      "4           0  17.372071  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143    True         True  0.000000\n",
      "6996        0  19.665493  0.504143    True         True  0.000000\n",
      "6997        1  13.684731  0.504143    True         True  1.827768\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143   False        False  1.858310\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0835879979143419}, 'validation': {'ate': 0.13935883, 'ate_std': 2.2779381, 'erupt': 17.25537150631067, 'norm_erupt': 17.225554626210357, 'qini': 37.528601490542364, 'auc': 0.9370367070236049, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143   False        False  1.981571\n",
      "1           1  16.947004  0.504143    True         True  1.949003\n",
      "2           1  19.124658  0.504143   False        False  0.000000\n",
      "3           0  15.266764  0.504143   False        False  1.981571\n",
      "4           0  15.059235  0.504143   False        False  1.981571\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  1.981571\n",
      "2996        1  16.902579  0.504143   False        False  0.000000\n",
      "2997        1  18.835211  0.504143   False        False  0.000000\n",
      "2998        0  14.982820  0.504143    True         True  0.000000\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.07107670172812242}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}, 'experiment_tag': 'exp', 'time_total_s': 10.329487323760986}\n",
      "[flaml.tune.tune: 05-16 13:45:29] {636} INFO - trial 8 config: {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 21, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'log2', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.3781055850921254, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}}\n",
      "[flaml.automl: 05-16 13:45:29] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:45:29] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:45:29] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:45:29] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:45:29] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3296} INFO - Estimated sufficient time budget=61s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9903,\tbest estimator lgbm's best error=0.9903\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9903,\tbest estimator lgbm's best error=0.9903\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9759,\tbest estimator lgbm's best error=0.9759\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator xgboost's best error=61.4318,\tbest estimator lgbm's best error=0.9759\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9389,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9541,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9541,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9455,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9455,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator xgboost's best error=61.4318,\tbest estimator extra_tree's best error=0.9389\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9020,\tbest estimator extra_tree's best error=0.9020\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9020,\tbest estimator extra_tree's best error=0.9020\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.8913,\tbest estimator extra_tree's best error=0.8913\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9157,\tbest estimator extra_tree's best error=0.8913\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9157,\tbest estimator extra_tree's best error=0.8913\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.3s,\testimator xgboost's best error=41.9217,\tbest estimator extra_tree's best error=0.8913\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8991,\tbest estimator extra_tree's best error=0.8913\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8727,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8925,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8727,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 20, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:29] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9801,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:29] {3166} INFO - iteration 21, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9801,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 22, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9686,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8912,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8727,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8727,\tbest estimator extra_tree's best error=0.8727\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8610,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8768,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8768,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8673,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8610,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9686,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9469,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8610,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.9s,\testimator lgbm's best error=0.9353,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 0.9s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8610\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 47, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8598,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 48, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.1s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8598,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8598,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8479,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8598,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8596,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.3s,\testimator lgbm's best error=0.9353,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.4s,\testimator lgbm's best error=0.9353,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:30] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8479,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:30] {3166} INFO - iteration 57, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8479,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 58, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8479,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 59, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8479,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.7s,\testimator lgbm's best error=0.9252,\tbest estimator extra_tree's best error=0.8479\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 61, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=37.6196,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 63, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=37.6196,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=4.7401,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9659,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 66, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9659,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9659,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 69, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 1.9s,\testimator lgbm's best error=0.9046,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.0s,\testimator lgbm's best error=0.9046,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.0s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.1s,\testimator lgbm's best error=0.9046,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.3s,\testimator lgbm's best error=0.9011,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8596,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:31] {3343} INFO -  at 2.5s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:31] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.8s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8438,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9011,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8438\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:32] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:32] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.8s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.9s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9011,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.9s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 3.9s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 109, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.0s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.1s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:33] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:33] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.6s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8421,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.8s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8559,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 4.9s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8421\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.4s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.4s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:34] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:34] {3166} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 147, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.1s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 149, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.2s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.3s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 152, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.3s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 153, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 154, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:35] {3343} INFO -  at 6.5s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:35] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 6.5s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 156, current learner rf\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 6.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 158, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 6.7s,\testimator extra_tree's best error=0.8391,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 159, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 6.7s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8391\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 160, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 7.2s,\testimator extra_tree's best error=0.8385,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 161, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 162, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:36] {3343} INFO -  at 7.2s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:36] {3166} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.8385,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 166, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.2s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.4s,\testimator extra_tree's best error=0.8385,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 168, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 170, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:37] {3343} INFO -  at 8.5s,\testimator catboost's best error=0.9615,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:37] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:38] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.8980,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:38] {3166} INFO - iteration 172, current learner rf\n",
      "[flaml.automl: 05-16 13:45:38] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:38] {3166} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:38] {3343} INFO -  at 9.5s,\testimator extra_tree's best error=0.8385,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:38] {3166} INFO - iteration 174, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:38] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:38] {3166} INFO - iteration 175, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:38] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:38] {3166} INFO - iteration 176, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator extra_tree's best error=0.8385,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 178, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 180, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9225,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 182, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 183, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 184, current learner rf\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 185, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 186, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 187, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 189, current learner rf\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.9s,\testimator rf's best error=0.8526,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 190, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 192, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 193, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 194, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 196, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 197, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8781,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3166} INFO - iteration 199, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:39] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.9419,\tbest estimator extra_tree's best error=0.8385\n",
      "[flaml.automl: 05-16 13:45:39] {3602} INFO - retrain extra_tree for 0.4s\n",
      "[flaml.automl: 05-16 13:45:39] {3609} INFO - retrained model: ExtraTreesRegressor(max_features=0.30169039088374844, max_leaf_nodes=365,\n",
      "                    n_estimators=765, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:45:39] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:45:39] {2902} INFO - Time taken to find the best model: 7.163802862167358\n",
      "[flaml.automl: 05-16 13:45:39] {2913} WARNING - Time taken to find the best model is 72% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl: 05-16 13:45:40] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:45:40] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:45:40] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:45:40] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:45:40] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3296} INFO - Estimated sufficient time budget=280s. Estimated necessary time budget=2s.\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9845,\tbest estimator lgbm's best error=0.9845\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9845,\tbest estimator lgbm's best error=0.9845\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9612,\tbest estimator lgbm's best error=0.9612\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9201,\tbest estimator lgbm's best error=0.9201\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9201,\tbest estimator lgbm's best error=0.9201\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9186,\tbest estimator lgbm's best error=0.9186\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9186,\tbest estimator lgbm's best error=0.9186\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9067,\tbest estimator lgbm's best error=0.9067\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9067,\tbest estimator lgbm's best error=0.9067\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9067,\tbest estimator lgbm's best error=0.9067\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9067,\tbest estimator lgbm's best error=0.9067\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9023,\tbest estimator lgbm's best error=0.9023\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9023,\tbest estimator lgbm's best error=0.9023\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9023,\tbest estimator lgbm's best error=0.9023\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9023,\tbest estimator lgbm's best error=0.9023\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9022,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator xgboost's best error=60.4719,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator xgboost's best error=60.4719,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator xgboost's best error=41.2912,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.2s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9022,\tbest estimator lgbm's best error=0.9022\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8885,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9218,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8957,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.8885,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.8885,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9098,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8957,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.8885,\tbest estimator lgbm's best error=0.8885\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8691,\tbest estimator extra_tree's best error=0.8691\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9098,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 41, current learner rf\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.7s,\testimator rf's best error=0.9053,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 42, current learner rf\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8754,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9098,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 45, current learner rf\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8754,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 05-16 13:45:40] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8579,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:40] {3166} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8564,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8579,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8579,\tbest estimator extra_tree's best error=0.8564\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8453,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8461,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8461,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8461,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.1s,\testimator lgbm's best error=0.8885,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9098,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8461,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8455,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 58, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.2s,\testimator xgboost's best error=0.8930,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 59, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.2s,\testimator lgbm's best error=0.8885,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 60, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.2s,\testimator xgboost's best error=0.8930,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8455,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8453,\tbest estimator extra_tree's best error=0.8453\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.4s,\testimator xgboost's best error=0.8930,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.5s,\testimator lgbm's best error=0.8885,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:41] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8364,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:41] {3166} INFO - iteration 75, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 1.8s,\testimator lgbm's best error=0.8885,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8402,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 1.9s,\testimator xgboost's best error=0.8930,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8402,\tbest estimator extra_tree's best error=0.8364\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8357,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8357,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8357\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 85, current learner rf\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8353,\tbest estimator rf's best error=0.8353\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:42] {3343} INFO -  at 2.5s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8353\n",
      "[flaml.automl: 05-16 13:45:42] {3166} INFO - iteration 87, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8353,\tbest estimator rf's best error=0.8353\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 88, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.0s,\testimator catboost's best error=0.9818,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 90, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.0s,\testimator catboost's best error=0.9818,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 91, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.0s,\testimator catboost's best error=0.9716,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 93, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.1s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.1s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 95, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 97, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 98, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.4s,\testimator catboost's best error=0.9716,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 99, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 102, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 104, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:43] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:43] {3166} INFO - iteration 105, current learner rf\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 106, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 3.9s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 3.9s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 108, current learner rf\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.0s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.1s,\testimator extra_tree's best error=0.8364,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.2s,\testimator extra_tree's best error=0.8358,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 115, current learner rf\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.3s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 117, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 118, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 120, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 121, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 122, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 123, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.5s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.5s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.8885,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.6s,\testimator lgbm's best error=0.8878,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.6s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 129, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 130, current learner rf\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.8s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:44] {3343} INFO -  at 4.8s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:44] {3166} INFO - iteration 133, current learner rf\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8331,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.0s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8358,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 137, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.1s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8331\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 138, current learner rf\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8325,\tbest estimator rf's best error=0.8325\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.3s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8325\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 140, current learner rf\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:45:45] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:45] {3166} INFO - iteration 142, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 5.9s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 144, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 145, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 146, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 05-16 13:45:46] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:46] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 150, current learner rf\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 152, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.2s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 153, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.2s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.2s,\testimator lgbm's best error=0.8878,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 155, current learner rf\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 156, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=36.9698,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=36.9698,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 158, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=4.5484,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 159, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.4s,\testimator xgb_limitdepth's best error=0.9063,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 160, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.5s,\testimator xgb_limitdepth's best error=0.9063,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 161, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9063,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 162, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.6s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.6s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:47] {3343} INFO -  at 7.8s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:47] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 171, current learner rf\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 172, current learner rf\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.4s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.5s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 179, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.6s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.6s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.8358,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 182, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:48] {3343} INFO -  at 8.7s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:48] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 184, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 185, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.2s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.2s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.3s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 189, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.7s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9014,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8313,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 194, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:49] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:49] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 196, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 197, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 198, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 202, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 10.0s,\testimator catboost's best error=0.9654,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 203, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 10.0s,\testimator extra_tree's best error=0.8358,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.8860,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 206, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.8930,\tbest estimator rf's best error=0.8313\n",
      "[flaml.automl: 05-16 13:45:50] {3602} INFO - retrain rf for 0.2s\n",
      "[flaml.automl: 05-16 13:45:50] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.5912610686057682, max_leaf_nodes=101,\n",
      "                      n_estimators=155, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:45:50] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:45:50] {2902} INFO - Time taken to find the best model: 5.436358213424683\n",
      "[flaml.tune.tune: 05-16 13:45:50] {198} INFO - result: {'energy_distance': 0.00828691514553448, 'estimator': <dowhy.causal_estimator.CausalEstimate object at 0x7fe778a2f9d0>, 'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'scores': {'train': {'ate': -0.028364707924426698, 'ate_std': 6.938893903907228e-18, 'erupt': 17.227812483605984, 'norm_erupt': 17.22781248360433, 'qini': -26.615754768973705, 'auc': -0.6437693483989101, 'values':       treated          Y         p  policy  norm_policy  weights\n",
      "0           0  16.443682  0.504143   False         True  2.01671\n",
      "1           1  19.220052  0.504143   False         True  0.00000\n",
      "2           1  16.795653  0.504143   False         True  0.00000\n",
      "3           1  17.168290  0.504143   False         True  0.00000\n",
      "4           0  17.372071  0.504143   False         True  2.01671\n",
      "...       ...        ...       ...     ...          ...      ...\n",
      "6995        0  15.901622  0.504143   False         True  2.01671\n",
      "6996        0  19.665493  0.504143   False         True  2.01671\n",
      "6997        1  13.684731  0.504143   False         True  0.00000\n",
      "6998        0  14.509022  0.504143   False         True  2.01671\n",
      "6999        0  14.743065  0.504143   False         True  2.01671\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0025453127350134608}, 'validation': {'ate': -0.028364707924426698, 'ate_std': 6.938893903907228e-18, 'erupt': 17.183057069660435, 'norm_erupt': 17.183057069660435, 'qini': -28.088757118086274, 'auc': 0.16675423668479444, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143   False        False  1.907184\n",
      "1           1  16.947004  0.504143   False        False  0.000000\n",
      "2           1  19.124658  0.504143   False        False  0.000000\n",
      "3           0  15.266764  0.504143   False        False  1.907184\n",
      "4           0  15.059235  0.504143   False        False  1.907184\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  1.907184\n",
      "2996        1  16.902579  0.504143   False        False  0.000000\n",
      "2997        1  18.835211  0.504143   False        False  0.000000\n",
      "2998        0  14.982820  0.504143   False        False  1.907184\n",
      "2999        0  14.206808  0.504143   False        False  1.907184\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.00828691514553448}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 21, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'log2', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.3781055850921254, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 21, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'log2', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.3781055850921254, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}, 'experiment_tag': 'exp', 'time_total_s': 21.3419451713562}\n",
      "[flaml.tune.tune: 05-16 13:45:50] {636} INFO - trial 9 config: {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.00151444794946084, 'n_estimators': 2, 'min_samples_split': 4, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.15437800297405868, 'max_features': 'auto', 'min_impurity_decrease': 3.784618715866711, 'max_samples': 0.31080024010381524, 'min_balancedness_tol': 0.04501275691617817, 'honest': 1, 'subforest_size': 8}}\n",
      "[flaml.automl: 05-16 13:45:50] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:45:50] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:45:50] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:45:50] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:45:50] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:50] {3296} INFO - Estimated sufficient time budget=50s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9887,\tbest estimator lgbm's best error=0.9887\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9887,\tbest estimator lgbm's best error=0.9887\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.1s,\testimator xgboost's best error=63.5585,\tbest estimator lgbm's best error=0.9887\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 3, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9402,\tbest estimator extra_tree's best error=0.9402\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 4, current learner rf\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9272,\tbest estimator rf's best error=0.9272\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.1s,\testimator xgboost's best error=63.5585,\tbest estimator rf's best error=0.9272\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:50] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9710,\tbest estimator rf's best error=0.9272\n",
      "[flaml.automl: 05-16 13:45:50] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.1s,\testimator rf's best error=0.8997,\tbest estimator rf's best error=0.8997\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 8, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8997,\tbest estimator rf's best error=0.8997\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 9, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8843,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.2s,\testimator rf's best error=0.8843,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.2s,\testimator xgboost's best error=43.4826,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.2s,\testimator extra_tree's best error=0.9136,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9136,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 14, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.3s,\testimator rf's best error=0.8843,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9567,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.3s,\testimator xgboost's best error=0.9567,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9567,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9447,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.4s,\testimator xgboost's best error=0.9562,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9447,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 21, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.4s,\testimator rf's best error=0.8843,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.9348,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 23, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9851,\tbest estimator rf's best error=0.8843\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 24, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.6s,\testimator rf's best error=0.8789,\tbest estimator rf's best error=0.8789\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8918,\tbest estimator rf's best error=0.8789\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 27, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.7s,\testimator catboost's best error=0.9851,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8789,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9348,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 33, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.8s,\testimator catboost's best error=0.9760,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9278,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.9s,\testimator catboost's best error=0.9760,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8789,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.0s,\testimator lgbm's best error=0.9278,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:51] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:51] {3166} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.2s,\testimator lgbm's best error=0.9278,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8789,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 50, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8789,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=38.9301,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=38.9301,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=4.8607,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.3s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8751,\tbest estimator extra_tree's best error=0.8751\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8746,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.4s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 58, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.4s,\testimator extra_tree's best error=0.8751,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 59, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8751,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 60, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8746,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 62, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8746,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 64, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8746\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8638,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 67, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8751,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8638,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 71, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 72, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 73, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 75, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9257,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.8s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8638\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 83, current learner rf\n",
      "[flaml.automl: 05-16 13:45:52] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:52] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8751,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 87, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.2s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 89, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 92, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 95, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.3s,\testimator xgboost's best error=0.9424,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 98, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.4s,\testimator xgboost's best error=0.9350,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 100, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 101, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 103, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.5s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.6s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 105, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.6s,\testimator xgboost's best error=0.9350,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 107, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.6s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.6s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 111, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9350,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 112, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 114, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.8s,\testimator xgboost's best error=0.9209,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 116, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 119, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.0s,\testimator xgboost's best error=0.9209,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 120, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.0s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 124, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.1s,\testimator xgboost's best error=0.9209,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:45:53] {3343} INFO -  at 3.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:53] {3166} INFO - iteration 126, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 127, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 128, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 131, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.9209,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.3s,\testimator xgboost's best error=0.9209,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.3s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 136, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 139, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.6s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 143, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.7s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.7s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 146, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 150, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 153, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 155, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 156, current learner rf\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:54] {3343} INFO -  at 4.1s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:54] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.2s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.2s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.3s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.3s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.4s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 171, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 172, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.6s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.6s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.7s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 179, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.7s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.8s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 184, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.9s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8576,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8576\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 189, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:55] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:55] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.2s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 194, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.2s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.2s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 196, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 197, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.4s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 202, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 204, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 207, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.5s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 210, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 211, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 212, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 213, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 214, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 215, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.8s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 216, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.8s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 218, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 219, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 220, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 221, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 222, current learner rf\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 6.0s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 224, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:56] {3343} INFO -  at 6.1s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:56] {3166} INFO - iteration 225, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 226, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 227, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 228, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 229, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.3s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 230, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 232, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 233, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.4s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 234, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 235, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.4s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 236, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 237, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 238, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.5s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 239, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 240, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 241, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 242, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 243, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 244, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 245, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.7s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 246, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.8s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 248, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 249, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 250, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 6.9s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 251, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 252, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 7.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 253, current learner rf\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 254, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 7.1s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:57] {3343} INFO -  at 7.1s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:57] {3166} INFO - iteration 256, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9151,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 258, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.2s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 260, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.3s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 262, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 263, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.3s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 264, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 265, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 266, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 267, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.4s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 268, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 269, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.4s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 270, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.5s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 271, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 272, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.5s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 273, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 274, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 275, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 276, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 277, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 278, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.7s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 279, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.8s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 281, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 282, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 283, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 284, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 285, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 7.9s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.0s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 288, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.0s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 289, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 290, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.1s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 292, current learner rf\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.1s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:58] {3343} INFO -  at 8.1s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:58] {3166} INFO - iteration 294, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.1s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 295, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.2s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 296, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 297, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 298, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 299, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 300, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 301, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 302, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 303, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 305, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.6s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 306, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.6s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 307, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.6s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 308, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.6s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 309, current learner catboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.6s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 310, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 311, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 312, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.7s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 313, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 314, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.8s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 315, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 316, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 317, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.8s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 318, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 319, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 320, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 8.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 321, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 322, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 323, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 324, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 325, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.1s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 326, current learner rf\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 327, current learner xgboost\n",
      "[flaml.automl: 05-16 13:45:59] {3343} INFO -  at 9.1s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:45:59] {3166} INFO - iteration 328, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 329, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 330, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.2s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 331, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.2s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 332, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 333, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.3s,\testimator xgboost's best error=0.9160,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 334, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.3s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 335, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.3s,\testimator xgboost's best error=0.9126,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 336, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.3s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 337, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.4s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 338, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.4s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 339, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.4s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 340, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.5s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 341, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 342, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.5s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 343, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 344, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 345, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.7s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 346, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 348, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.7s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 349, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9093,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 350, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.8s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 351, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 352, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 353, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 354, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.8s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 355, current learner rf\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.9s,\testimator rf's best error=0.8527,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 356, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 357, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.9s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 358, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 9.9s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 359, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 10.0s,\testimator catboost's best error=0.9705,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 360, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 361, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 10.0s,\testimator xgboost's best error=0.9072,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 362, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 10.0s,\testimator extra_tree's best error=0.8701,\tbest estimator rf's best error=0.8527\n",
      "[flaml.automl: 05-16 13:46:00] {3602} INFO - retrain rf for 0.0s\n",
      "[flaml.automl: 05-16 13:46:00] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.6448227132376881, max_leaf_nodes=46,\n",
      "                      n_estimators=10, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:46:00] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:46:00] {2902} INFO - Time taken to find the best model: 5.590531826019287\n",
      "[flaml.automl: 05-16 13:46:00] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:46:00] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:46:00] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:46:00] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:46:00] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:00] {3296} INFO - Estimated sufficient time budget=198s. Estimated necessary time budget=2s.\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9901,\tbest estimator lgbm's best error=0.9901\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:00] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9901,\tbest estimator lgbm's best error=0.9901\n",
      "[flaml.automl: 05-16 13:46:00] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9750,\tbest estimator lgbm's best error=0.9750\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator xgboost's best error=66.9689,\tbest estimator lgbm's best error=0.9750\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9585,\tbest estimator lgbm's best error=0.9585\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9585,\tbest estimator lgbm's best error=0.9585\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9456,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9456,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9456,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9456,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9456,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.3s,\testimator xgboost's best error=66.9689,\tbest estimator lgbm's best error=0.9456\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9395,\tbest estimator extra_tree's best error=0.9395\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9185,\tbest estimator extra_tree's best error=0.9185\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9185,\tbest estimator extra_tree's best error=0.9185\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.3s,\testimator xgboost's best error=45.8389,\tbest estimator extra_tree's best error=0.9185\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9158,\tbest estimator extra_tree's best error=0.9158\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 17, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9279,\tbest estimator extra_tree's best error=0.9158\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 18, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9110,\tbest estimator rf's best error=0.9110\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 19, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9110,\tbest estimator rf's best error=0.9110\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 20, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9105,\tbest estimator rf's best error=0.9105\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 21, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9105,\tbest estimator rf's best error=0.9105\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 22, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator rf's best error=0.9061,\tbest estimator rf's best error=0.9061\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 23, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator rf's best error=0.8996,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9708,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9708,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9708,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 28, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.7s,\testimator rf's best error=0.8996,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.9137,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.7s,\testimator lgbm's best error=0.9456,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9456,\tbest estimator rf's best error=0.8996\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8826,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.8s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 34, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.8s,\testimator rf's best error=0.8826,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8826,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.9109,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 37, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8826,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 38, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8826,\tbest estimator rf's best error=0.8826\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 39, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 40, current learner rf\n",
      "[flaml.automl: 05-16 13:46:01] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:01] {3166} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.1s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.1s,\testimator lgbm's best error=0.9456,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 43, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.9077,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.9027,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8965,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 49, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 50, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.5s,\testimator catboost's best error=0.9790,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 51, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.6s,\testimator catboost's best error=0.9790,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 52, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.6s,\testimator catboost's best error=0.9669,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 54, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.7s,\testimator lgbm's best error=0.9456,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8965,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 1.9s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 2.0s,\testimator catboost's best error=0.9669,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 2.0s,\testimator lgbm's best error=0.9437,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 61, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:02] {3343} INFO -  at 2.0s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:02] {3166} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.1s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 63, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.1s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8965,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 65, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.2s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 66, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.2s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8961,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 68, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.3s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.3s,\testimator lgbm's best error=0.9437,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 70, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 71, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.4s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 72, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.5s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.5s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 74, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 75, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.6s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 76, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 78, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.7s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 79, current learner rf\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.8s,\testimator rf's best error=0.8634,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 80, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=41.0304,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 81, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=41.0304,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=5.1979,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 83, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.8s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 87, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:03] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:03] {3166} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8634\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 96, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9447,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9446,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.3s,\testimator lgbm's best error=0.9437,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 105, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 106, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 107, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 108, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.5s,\testimator xgboost's best error=0.9691,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 109, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.5s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 110, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.6s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 111, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.6s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.6s,\testimator lgbm's best error=0.9324,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 113, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.6s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 114, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.9324,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 115, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8961,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.9324,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.7s,\testimator lgbm's best error=0.9324,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 118, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.7s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 119, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.9s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.9s,\testimator lgbm's best error=0.9324,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 121, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 3.9s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 122, current learner rf\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 4.0s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 123, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:04] {3343} INFO -  at 4.0s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:04] {3166} INFO - iteration 124, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.1s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.3s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.4s,\testimator rf's best error=0.8614,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 130, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.4s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8614\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 131, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 132, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 133, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.6s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.6s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 136, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.7s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 137, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.7s,\testimator xgboost's best error=0.9659,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 138, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.8s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 140, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 4.9s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 142, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 5.0s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 143, current learner rf\n",
      "[flaml.automl: 05-16 13:46:05] {3343} INFO -  at 5.1s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:05] {3166} INFO - iteration 144, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.1s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 145, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 146, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 147, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.3s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.3s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.3s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 153, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 154, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.6s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.7s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.7s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 157, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9512,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.7s,\testimator xgboost's best error=0.9512,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.8s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.8s,\testimator xgboost's best error=0.9511,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 5.9s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 163, current learner rf\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 6.0s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 164, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:06] {3343} INFO -  at 6.0s,\testimator extra_tree's best error=0.8868,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:06] {3166} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.8868,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.1s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 167, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.2s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.8840,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.8840,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.4s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 173, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 174, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.6s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 175, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 6.7s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 177, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.8832,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 178, current learner rf\n",
      "[flaml.automl: 05-16 13:46:07] {3343} INFO -  at 7.1s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:07] {3166} INFO - iteration 179, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 180, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 181, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 182, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.3s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.4s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.4s,\testimator lgbm's best error=0.9278,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 186, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.5s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.6s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 188, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.6s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.6s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.6s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 191, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.6s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.7s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 193, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.7s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 194, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.8s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 195, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.8s,\testimator xgboost's best error=0.9511,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.8s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.8s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 198, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 7.9s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 199, current learner rf\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 8.0s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 200, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 8.0s,\testimator catboost's best error=0.9596,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 201, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:08] {3343} INFO -  at 8.1s,\testimator xgboost's best error=0.9511,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:08] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 203, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 8.1s,\testimator lgbm's best error=0.9176,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 204, current learner rf\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 8.2s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 205, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 8.7s,\testimator extra_tree's best error=0.8765,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 206, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 9.0s,\testimator extra_tree's best error=0.8765,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 207, current learner rf\n",
      "[flaml.automl: 05-16 13:46:09] {3343} INFO -  at 9.1s,\testimator rf's best error=0.8510,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:09] {3166} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 10.2s,\testimator extra_tree's best error=0.8765,\tbest estimator rf's best error=0.8510\n",
      "[flaml.automl: 05-16 13:46:11] {3602} INFO - retrain rf for 0.0s\n",
      "[flaml.automl: 05-16 13:46:11] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.41461528889313515, max_leaf_nodes=69,\n",
      "                      n_estimators=42, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:46:11] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:46:11] {2902} INFO - Time taken to find the best model: 4.475703001022339\n",
      "[flaml.tune.tune: 05-16 13:46:11] {198} INFO - result: {'energy_distance': 0.007206380252478439, 'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'scores': {'train': {'ate': 0.09513135973943833, 'ate_std': 1.3877787807814457e-17, 'erupt': 17.18572003270283, 'norm_erupt': 17.22781248360433, 'qini': -4.933664684746068, 'auc': -0.6437693483989101, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.443682  0.504143    True         True  0.000000\n",
      "1           1  19.220052  0.504143    True         True  1.983565\n",
      "2           1  16.795653  0.504143    True         True  1.983565\n",
      "3           1  17.168290  0.504143    True         True  1.983565\n",
      "4           0  17.372071  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  15.901622  0.504143    True         True  0.000000\n",
      "6996        0  19.665493  0.504143    True         True  0.000000\n",
      "6997        1  13.684731  0.504143    True         True  1.983565\n",
      "6998        0  14.509022  0.504143    True         True  0.000000\n",
      "6999        0  14.743065  0.504143    True         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.005506147388831373}, 'validation': {'ate': 0.09513135973943834, 'ate_std': 0.0, 'erupt': 17.237800423577063, 'norm_erupt': 17.18305706965972, 'qini': -4.220997892411109, 'auc': 0.16675423668479444, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143    True         True  0.000000\n",
      "1           1  16.947004  0.504143    True         True  2.102313\n",
      "2           1  19.124658  0.504143    True         True  2.102313\n",
      "3           0  15.266764  0.504143    True         True  0.000000\n",
      "4           0  15.059235  0.504143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143    True         True  0.000000\n",
      "2996        1  16.902579  0.504143    True         True  2.102313\n",
      "2997        1  18.835211  0.504143    True         True  2.102313\n",
      "2998        0  14.982820  0.504143    True         True  0.000000\n",
      "2999        0  14.206808  0.504143    True         True  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007206380252478439}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.00151444794946084, 'n_estimators': 2, 'min_samples_split': 4, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.15437800297405868, 'max_features': 'auto', 'min_impurity_decrease': 3.784618715866711, 'max_samples': 0.31080024010381524, 'min_balancedness_tol': 0.04501275691617817, 'honest': 1, 'subforest_size': 8}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.00151444794946084, 'n_estimators': 2, 'min_samples_split': 4, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.15437800297405868, 'max_features': 'auto', 'min_impurity_decrease': 3.784618715866711, 'max_samples': 0.31080024010381524, 'min_balancedness_tol': 0.04501275691617817, 'honest': 1, 'subforest_size': 8}, 'experiment_tag': 'exp', 'time_total_s': 20.660711765289307}\n",
      "[flaml.tune.tune: 05-16 13:46:11] {636} INFO - trial 10 config: {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 37, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'auto', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.37810558509212533, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}}\n",
      "[flaml.automl: 05-16 13:46:11] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:46:11] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:46:11] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:46:11] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:46:11] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3296} INFO - Estimated sufficient time budget=47s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9869,\tbest estimator lgbm's best error=0.9869\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9869,\tbest estimator lgbm's best error=0.9869\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9680,\tbest estimator lgbm's best error=0.9680\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.1s,\testimator xgboost's best error=62.4144,\tbest estimator lgbm's best error=0.9680\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9276,\tbest estimator extra_tree's best error=0.9276\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9126,\tbest estimator rf's best error=0.9126\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9381,\tbest estimator rf's best error=0.9126\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 7, current learner rf\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9126,\tbest estimator rf's best error=0.9126\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9381,\tbest estimator rf's best error=0.9126\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9293,\tbest estimator rf's best error=0.9126\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9106,\tbest estimator rf's best error=0.9106\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.3s,\testimator xgboost's best error=62.4144,\tbest estimator rf's best error=0.9106\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.3s,\testimator xgboost's best error=42.5405,\tbest estimator rf's best error=0.9106\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9044,\tbest estimator extra_tree's best error=0.9044\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.9044,\tbest estimator extra_tree's best error=0.9044\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8728,\tbest estimator extra_tree's best error=0.8728\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9293,\tbest estimator extra_tree's best error=0.8728\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8728,\tbest estimator extra_tree's best error=0.8728\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9259,\tbest estimator extra_tree's best error=0.8728\n",
      "[flaml.automl: 05-16 13:46:11] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:11] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8728,\tbest estimator extra_tree's best error=0.8728\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8532,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 21, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9806,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 22, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9806,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 23, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9699,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9515,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9515,\tbest estimator extra_tree's best error=0.8532\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8439,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9515,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9510,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8439,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8439,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9259,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.8s,\testimator lgbm's best error=0.9259,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8439,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8439,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.0s,\testimator lgbm's best error=0.9210,\tbest estimator extra_tree's best error=0.8439\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8423,\tbest estimator extra_tree's best error=0.8423\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8423,\tbest estimator extra_tree's best error=0.8423\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8423,\tbest estimator extra_tree's best error=0.8423\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8423,\tbest estimator extra_tree's best error=0.8423\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 40, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.3s,\testimator catboost's best error=0.9699,\tbest estimator extra_tree's best error=0.8423\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:12] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:12] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.5s,\testimator lgbm's best error=0.9117,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.6s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.7s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.8s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.8s,\testimator lgbm's best error=0.9117,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator lgbm's best error=0.9117,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 50, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=38.1068,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 51, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=38.1068,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=4.6169,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 53, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9314,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 54, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 1.9s,\testimator xgb_limitdepth's best error=0.9314,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 55, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9314,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.0s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.0s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.0s,\testimator rf's best error=0.9106,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.1s,\testimator catboost's best error=0.9634,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.3s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.3s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8376,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 63, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:13] {3343} INFO -  at 2.4s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8376\n",
      "[flaml.automl: 05-16 13:46:13] {3166} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.5s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 65, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.5s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 66, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.6s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.7s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 68, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.7s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.8s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 2.9s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.0s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.0s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.2s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.2s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.2s,\testimator rf's best error=0.9106,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.2s,\testimator rf's best error=0.9106,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 80, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.4s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.4s,\testimator rf's best error=0.9106,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:14] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:14] {3166} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 3.7s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 3.8s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 3.8s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 3.9s,\testimator extra_tree's best error=0.8333,\tbest estimator extra_tree's best error=0.8333\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8328,\tbest estimator extra_tree's best error=0.8328\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 4.1s,\testimator catboost's best error=0.9634,\tbest estimator extra_tree's best error=0.8328\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 90, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 4.1s,\testimator catboost's best error=0.9634,\tbest estimator extra_tree's best error=0.8328\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:15] {3343} INFO -  at 4.1s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8328\n",
      "[flaml.automl: 05-16 13:46:15] {3166} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 4.5s,\testimator xgb_limitdepth's best error=0.9262,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 4.7s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 5.3s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:16] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:16] {3166} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 5.7s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 101, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.3s,\testimator xgboost's best error=0.9510,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.4s,\testimator lgbm's best error=0.9047,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:17] {3343} INFO -  at 6.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:17] {3166} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:18] {3343} INFO -  at 6.6s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:18] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:18] {3343} INFO -  at 7.3s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:18] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:18] {3343} INFO -  at 7.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:18] {3166} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.2s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.2s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.8978,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.8978,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.3s,\testimator lgbm's best error=0.8978,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:19] {3343} INFO -  at 8.4s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:19] {3166} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.5s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.5s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.6s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.6s,\testimator catboost's best error=0.9634,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.7s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.0s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.0s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.1s,\testimator catboost's best error=0.9634,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.2s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:20] {3343} INFO -  at 9.2s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:20] {3166} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 9.9s,\testimator extra_tree's best error=0.8254,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 9.9s,\testimator lgbm's best error=0.8926,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 141, current learner rf\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 10.0s,\testimator rf's best error=0.9106,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 143, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:21] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9099,\tbest estimator extra_tree's best error=0.8254\n",
      "[flaml.automl: 05-16 13:46:21] {3602} INFO - retrain extra_tree for 0.4s\n",
      "[flaml.automl: 05-16 13:46:21] {3609} INFO - retrained model: ExtraTreesRegressor(max_features=0.2950273274842667, max_leaf_nodes=205,\n",
      "                    n_estimators=583, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:46:21] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:46:21] {2902} INFO - Time taken to find the best model: 4.4907472133636475\n",
      "[flaml.automl: 05-16 13:46:22] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 13:46:22] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 13:46:22] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 13:46:22] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 13:46:22] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3296} INFO - Estimated sufficient time budget=41s. Estimated necessary time budget=0s.\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9863,\tbest estimator lgbm's best error=0.9863\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9863,\tbest estimator lgbm's best error=0.9863\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.0s,\testimator lgbm's best error=0.9670,\tbest estimator lgbm's best error=0.9670\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator xgboost's best error=68.6732,\tbest estimator lgbm's best error=0.9670\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator extra_tree's best error=0.9250,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 5, current learner rf\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator rf's best error=0.9385,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9378,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9378,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.1s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.9250\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 10, current learner rf\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.2s,\testimator rf's best error=0.9094,\tbest estimator rf's best error=0.9094\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.2s,\testimator xgboost's best error=68.6732,\tbest estimator rf's best error=0.9094\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.3s,\testimator xgboost's best error=46.8371,\tbest estimator rf's best error=0.9094\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 13, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9048,\tbest estimator extra_tree's best error=0.9048\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.9048,\tbest estimator extra_tree's best error=0.9048\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.3s,\testimator extra_tree's best error=0.8956,\tbest estimator extra_tree's best error=0.8956\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 16, current learner rf\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.4s,\testimator rf's best error=0.9079,\tbest estimator extra_tree's best error=0.8956\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8956,\tbest estimator extra_tree's best error=0.8956\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8956\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.4s,\testimator extra_tree's best error=0.8956,\tbest estimator extra_tree's best error=0.8956\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 20, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.5s,\testimator extra_tree's best error=0.8835,\tbest estimator extra_tree's best error=0.8835\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 21, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9779,\tbest estimator extra_tree's best error=0.8835\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 22, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.5s,\testimator catboost's best error=0.9779,\tbest estimator extra_tree's best error=0.8835\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 23, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9658,\tbest estimator extra_tree's best error=0.8835\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 24, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.6s,\testimator catboost's best error=0.9658,\tbest estimator extra_tree's best error=0.8835\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.6s,\testimator extra_tree's best error=0.8792,\tbest estimator extra_tree's best error=0.8792\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8792,\tbest estimator extra_tree's best error=0.8792\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8792,\tbest estimator extra_tree's best error=0.8792\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8680,\tbest estimator extra_tree's best error=0.8680\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8680,\tbest estimator extra_tree's best error=0.8680\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8599,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 31, current learner rf\n",
      "[flaml.automl: 05-16 13:46:22] {3343} INFO -  at 0.9s,\testimator rf's best error=0.8901,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:22] {3166} INFO - iteration 32, current learner rf\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8901,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 33, current learner rf\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8901,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8599,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 35, current learner rf\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.1s,\testimator rf's best error=0.8885,\tbest estimator extra_tree's best error=0.8599\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 39, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=41.9506,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 40, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.5s,\testimator xgb_limitdepth's best error=41.9506,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 41, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=5.0803,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 42, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 44, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 45, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 46, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 47, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.6s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 48, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 49, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 52, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 53, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.7s,\testimator xgboost's best error=0.9398,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:23] {3343} INFO -  at 1.8s,\testimator xgboost's best error=0.9387,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:23] {3166} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 56, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.1s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 57, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 58, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9437,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 59, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.1s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 60, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.2s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 61, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.2s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 63, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.4s,\testimator rf's best error=0.8862,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 64, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.5s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.5s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 66, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8729,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 67, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8729,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 68, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.6s,\testimator rf's best error=0.8729,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 69, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8729,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 70, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.7s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 71, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.7s,\testimator rf's best error=0.8729,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.8s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 73, current learner rf\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.9s,\testimator rf's best error=0.8685,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 74, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:24] {3343} INFO -  at 2.9s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:24] {3166} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.1s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 76, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.1s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 77, current learner rf\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.2s,\testimator rf's best error=0.8685,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 78, current learner rf\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.3s,\testimator rf's best error=0.8668,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 79, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.3s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 80, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.3s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 81, current learner rf\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.4s,\testimator rf's best error=0.8668,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 82, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.4s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 83, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.5s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 84, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 85, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 86, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.5s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.6s,\testimator extra_tree's best error=0.8592,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 88, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.6s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 89, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.7s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 90, current learner rf\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.8s,\testimator rf's best error=0.8654,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.8s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.9s,\testimator xgboost's best error=0.9387,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:25] {3343} INFO -  at 3.9s,\testimator xgb_limitdepth's best error=0.9283,\tbest estimator extra_tree's best error=0.8592\n",
      "[flaml.automl: 05-16 13:46:25] {3166} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.0s,\testimator extra_tree's best error=0.8519,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 95, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.2s,\testimator extra_tree's best error=0.8519,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.2s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.2s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.3s,\testimator extra_tree's best error=0.8519,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 99, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.4s,\testimator extra_tree's best error=0.8519,\tbest estimator extra_tree's best error=0.8519\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.5s,\testimator extra_tree's best error=0.8509,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.6s,\testimator extra_tree's best error=0.8509,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.6s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.8s,\testimator extra_tree's best error=0.8509,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:26] {3343} INFO -  at 4.8s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:26] {3166} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.0s,\testimator extra_tree's best error=0.8509,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.1s,\testimator extra_tree's best error=0.8509,\tbest estimator extra_tree's best error=0.8509\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.8488,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.3s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.5s,\testimator extra_tree's best error=0.8488,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.5s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8488,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.6s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:27] {3343} INFO -  at 5.6s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8488\n",
      "[flaml.automl: 05-16 13:46:27] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:28] {3343} INFO -  at 6.1s,\testimator extra_tree's best error=0.8468,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:28] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:28] {3343} INFO -  at 6.2s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:28] {3166} INFO - iteration 116, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:28] {3343} INFO -  at 6.2s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:28] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 13:46:28] {3343} INFO -  at 6.5s,\testimator rf's best error=0.8572,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:28] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:28] {3343} INFO -  at 6.5s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:28] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:29] {3343} INFO -  at 7.5s,\testimator extra_tree's best error=0.8468,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:29] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:29] {3343} INFO -  at 7.5s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:29] {3166} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:29] {3343} INFO -  at 7.7s,\testimator extra_tree's best error=0.8468,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:29] {3166} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:30] {3343} INFO -  at 8.5s,\testimator extra_tree's best error=0.8468,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:30] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:30] {3343} INFO -  at 8.5s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:30] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 13:46:30] {3343} INFO -  at 8.8s,\testimator extra_tree's best error=0.8468,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:30] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.0s,\testimator rf's best error=0.8572,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.0s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.6s,\testimator rf's best error=0.8572,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.6s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.7s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 132, current learner xgboost\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.7s,\testimator xgboost's best error=0.9387,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.7s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.8s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.8s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 136, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 138, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.8s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.9s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 141, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.9s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.9s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 143, current learner catboost\n",
      "[flaml.automl: 05-16 13:46:31] {3343} INFO -  at 9.9s,\testimator catboost's best error=0.9583,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:31] {3166} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:32] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:32] {3166} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:32] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:32] {3166} INFO - iteration 146, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 13:46:32] {3343} INFO -  at 10.0s,\testimator xgb_limitdepth's best error=0.9195,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:32] {3166} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:32] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:32] {3166} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl: 05-16 13:46:32] {3343} INFO -  at 10.0s,\testimator lgbm's best error=0.9339,\tbest estimator extra_tree's best error=0.8468\n",
      "[flaml.automl: 05-16 13:46:32] {3602} INFO - retrain extra_tree for 0.5s\n",
      "[flaml.automl: 05-16 13:46:32] {3609} INFO - retrained model: ExtraTreesRegressor(max_features=0.3134024665189564, max_leaf_nodes=224,\n",
      "                    n_estimators=850, n_jobs=-1)\n",
      "[flaml.automl: 05-16 13:46:32] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 13:46:32] {2902} INFO - Time taken to find the best model: 6.143966913223267\n",
      "[flaml.tune.tune: 05-16 13:46:33] {198} INFO - result: {'energy_distance': 0.007949838686730715, 'estimator': <dowhy.causal_estimator.CausalEstimate object at 0x7fe78c2c7fd0>, 'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'scores': {'train': {'ate': -0.015817980941493448, 'ate_std': 6.938893903907228e-18, 'erupt': 17.227812483605984, 'norm_erupt': 17.22781248360433, 'qini': -30.350930691917128, 'auc': -0.6437693483989101, 'values':       treated          Y         p  policy  norm_policy  weights\n",
      "0           0  16.443682  0.504143   False         True  2.01671\n",
      "1           1  19.220052  0.504143   False         True  0.00000\n",
      "2           1  16.795653  0.504143   False         True  0.00000\n",
      "3           1  17.168290  0.504143   False         True  0.00000\n",
      "4           0  17.372071  0.504143   False         True  2.01671\n",
      "...       ...        ...       ...     ...          ...      ...\n",
      "6995        0  15.901622  0.504143   False         True  2.01671\n",
      "6996        0  19.665493  0.504143   False         True  2.01671\n",
      "6997        1  13.684731  0.504143   False         True  0.00000\n",
      "6998        0  14.509022  0.504143   False         True  2.01671\n",
      "6999        0  14.743065  0.504143   False         True  2.01671\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002616322426453266}, 'validation': {'ate': -0.01581798094149345, 'ate_std': 3.469446951953614e-18, 'erupt': 17.183057069660435, 'norm_erupt': 17.183057069660435, 'qini': -11.25809034601401, 'auc': 0.16675423668479444, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  14.031430  0.504143   False        False  1.907184\n",
      "1           1  16.947004  0.504143   False        False  0.000000\n",
      "2           1  19.124658  0.504143   False        False  0.000000\n",
      "3           0  15.266764  0.504143   False        False  1.907184\n",
      "4           0  15.059235  0.504143   False        False  1.907184\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  14.192831  0.504143   False        False  1.907184\n",
      "2996        1  16.902579  0.504143   False        False  0.000000\n",
      "2997        1  18.835211  0.504143   False        False  0.000000\n",
      "2998        0  14.982820  0.504143   False        False  1.907184\n",
      "2999        0  14.206808  0.504143   False        False  1.907184\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007949838686730715}}, 'config': {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 37, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'auto', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.37810558509212533, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 0.0017231790528715186, 'n_estimators': 37, 'min_samples_split': 2, 'min_samples_leaf': 9, 'min_weight_fraction_leaf': 0.18432972513405987, 'max_features': 'auto', 'min_impurity_decrease': 2.6639242043080236, 'max_samples': 0.37810558509212533, 'min_balancedness_tol': 0.006805783323944936, 'honest': 1, 'subforest_size': 8}, 'experiment_tag': 'exp', 'time_total_s': 21.592467069625854}\n"
     ]
    }
   ],
   "source": [
    "ct = AutoCausality(\n",
    "    num_samples=num_samples,\n",
    "    components_time_budget=components_time_budget,\n",
    "    metric=\"energy_distance\",\n",
    "    verbose=3,\n",
    "    components_verbose=3,\n",
    "    train_size=train_size,\n",
    ")   \n",
    "ct.fit(data=cd, outcome=target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference in means estimate (naive ATE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.0131395155287919$"
      ],
      "text/plain": [
       "-0.01313951552879189"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.scorer.naive_ate(cd.data[cd.treatment], cd.data[target])[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CausaTune ATE estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -0.0430289215553754$"
      ],
      "text/plain": [
       "-0.043028921555375396"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct.effect(ct.test_df).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainable variation\n",
    "\n",
    "As a first performance check of this approach we test how much of the variation in the outcome metric remains unexplained with our outcome model prediction approach. \n",
    "\n",
    "For this, we use AutoML to predict outcomes as is done under the hood of CausalTune.\n",
    "The lower the unexplained variation, the more promising it is to use CausalTune for AB Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 05-16 09:53:42] {2599} INFO - task = regression\n",
      "[flaml.automl: 05-16 09:53:42] {2601} INFO - Data split method: uniform\n",
      "[flaml.automl: 05-16 09:53:42] {2604} INFO - Evaluation method: holdout\n",
      "[flaml.automl: 05-16 09:53:42] {2726} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 05-16 09:53:42] {2870} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3296} INFO - Estimated sufficient time budget=341s. Estimated necessary time budget=3s.\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9850,\tbest estimator lgbm's best error=0.9850\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9850,\tbest estimator lgbm's best error=0.9850\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9635,\tbest estimator lgbm's best error=0.9635\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9272,\tbest estimator lgbm's best error=0.9272\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9272,\tbest estimator lgbm's best error=0.9272\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.2s,\testimator lgbm's best error=0.9074,\tbest estimator lgbm's best error=0.9074\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9074,\tbest estimator lgbm's best error=0.9074\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9002,\tbest estimator lgbm's best error=0.9002\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9002,\tbest estimator lgbm's best error=0.9002\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9002,\tbest estimator lgbm's best error=0.9002\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.9002,\tbest estimator lgbm's best error=0.9002\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 11, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8964,\tbest estimator lgbm's best error=0.8964\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 12, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8964,\tbest estimator lgbm's best error=0.8964\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8964,\tbest estimator lgbm's best error=0.8964\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.3s,\testimator lgbm's best error=0.8964,\tbest estimator lgbm's best error=0.8964\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8822,\tbest estimator lgbm's best error=0.8822\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8822,\tbest estimator lgbm's best error=0.8822\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8714,\tbest estimator lgbm's best error=0.8714\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:42] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8714,\tbest estimator lgbm's best error=0.8714\n",
      "[flaml.automl: 05-16 09:53:42] {3166} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.4s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.5s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.5s,\testimator xgboost's best error=67.0438,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.5s,\testimator xgboost's best error=67.0438,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.5s,\testimator xgboost's best error=45.7488,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.5s,\testimator xgboost's best error=0.9632,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.6s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 29, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.6s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9632,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.6s,\testimator xgboost's best error=0.9632,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.7s,\testimator lgbm's best error=0.8651,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.7s,\testimator xgboost's best error=0.9629,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.9415,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8976,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.7s,\testimator extra_tree's best error=0.8976,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8764,\tbest estimator lgbm's best error=0.8651\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8612,\tbest estimator extra_tree's best error=0.8612\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.8s,\testimator extra_tree's best error=0.8612,\tbest estimator extra_tree's best error=0.8612\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8559,\tbest estimator extra_tree's best error=0.8559\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.9s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8559\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 0.9s,\testimator extra_tree's best error=0.8559,\tbest estimator extra_tree's best error=0.8559\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.0s,\testimator extra_tree's best error=0.8407,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 44, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.0s,\testimator rf's best error=0.9145,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 45, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8815,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 46, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.0s,\testimator rf's best error=0.8815,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.1s,\testimator extra_tree's best error=0.8407,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 48, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.2s,\testimator rf's best error=0.8605,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.2s,\testimator extra_tree's best error=0.8407,\tbest estimator extra_tree's best error=0.8407\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.3s,\testimator extra_tree's best error=0.8305,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 51, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.3s,\testimator rf's best error=0.8426,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 52, current learner rf\n",
      "[flaml.automl: 05-16 09:53:43] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8426,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:43] {3166} INFO - iteration 53, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.4s,\testimator rf's best error=0.8426,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.4s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 55, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.5s,\testimator extra_tree's best error=0.8305,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 56, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.5s,\testimator rf's best error=0.8426,\tbest estimator extra_tree's best error=0.8305\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 57, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8246,\tbest estimator rf's best error=0.8246\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 58, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.6s,\testimator rf's best error=0.8246,\tbest estimator rf's best error=0.8246\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 59, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8246,\tbest estimator rf's best error=0.8246\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 60, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.7s,\testimator rf's best error=0.8246,\tbest estimator rf's best error=0.8246\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 61, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8246,\tbest estimator rf's best error=0.8246\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 62, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 1.8s,\testimator rf's best error=0.8242,\tbest estimator rf's best error=0.8242\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 2.0s,\testimator extra_tree's best error=0.8234,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 64, current learner rf\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 2.0s,\testimator rf's best error=0.8242,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 2.1s,\testimator extra_tree's best error=0.8234,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 66, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:44] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8234,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:44] {3166} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.4s,\testimator extra_tree's best error=0.8234,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 68, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.4s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8234\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 69, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.7s,\testimator extra_tree's best error=0.8225,\tbest estimator extra_tree's best error=0.8225\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 70, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.8s,\testimator catboost's best error=0.9812,\tbest estimator extra_tree's best error=0.8225\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 71, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.9s,\testimator catboost's best error=0.9812,\tbest estimator extra_tree's best error=0.8225\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:45] {3343} INFO -  at 2.9s,\testimator catboost's best error=0.9711,\tbest estimator extra_tree's best error=0.8225\n",
      "[flaml.automl: 05-16 09:53:45] {3166} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:46] {3343} INFO -  at 3.5s,\testimator extra_tree's best error=0.8212,\tbest estimator extra_tree's best error=0.8212\n",
      "[flaml.automl: 05-16 09:53:46] {3166} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:46] {3343} INFO -  at 3.8s,\testimator extra_tree's best error=0.8212,\tbest estimator extra_tree's best error=0.8212\n",
      "[flaml.automl: 05-16 09:53:46] {3166} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:47] {3343} INFO -  at 4.9s,\testimator extra_tree's best error=0.8212,\tbest estimator extra_tree's best error=0.8212\n",
      "[flaml.automl: 05-16 09:53:47] {3166} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:47] {3343} INFO -  at 4.9s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8212\n",
      "[flaml.automl: 05-16 09:53:47] {3166} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:47] {3343} INFO -  at 5.0s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8212\n",
      "[flaml.automl: 05-16 09:53:47] {3166} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:47] {3343} INFO -  at 5.3s,\testimator extra_tree's best error=0.8135,\tbest estimator extra_tree's best error=0.8135\n",
      "[flaml.automl: 05-16 09:53:47] {3166} INFO - iteration 79, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:47] {3343} INFO -  at 5.3s,\testimator catboost's best error=0.9711,\tbest estimator extra_tree's best error=0.8135\n",
      "[flaml.automl: 05-16 09:53:47] {3166} INFO - iteration 80, current learner rf\n",
      "[flaml.automl: 05-16 09:53:48] {3343} INFO -  at 5.4s,\testimator rf's best error=0.8242,\tbest estimator extra_tree's best error=0.8135\n",
      "[flaml.automl: 05-16 09:53:48] {3166} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:48] {3343} INFO -  at 5.6s,\testimator extra_tree's best error=0.8135,\tbest estimator extra_tree's best error=0.8135\n",
      "[flaml.automl: 05-16 09:53:48] {3166} INFO - iteration 82, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:48] {3343} INFO -  at 5.7s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8135\n",
      "[flaml.automl: 05-16 09:53:48] {3166} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:48] {3343} INFO -  at 6.3s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:48] {3166} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:49] {3343} INFO -  at 7.0s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:49] {3166} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:50] {3343} INFO -  at 7.5s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:50] {3166} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.0s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.3s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 88, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.3s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 89, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.3s,\testimator xgb_limitdepth's best error=40.9341,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 90, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=40.9341,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 91, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=4.9834,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 92, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:51] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9313,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:51] {3166} INFO - iteration 93, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9313,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 94, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9313,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9271,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 96, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.4s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.4s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 100, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.9034,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 9.5s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 105, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 10.2s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 106, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:52] {3343} INFO -  at 10.2s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:52] {3166} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 10.8s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 10.8s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 109, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 10.8s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 10.9s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 111, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 11.3s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 11.3s,\testimator lgbm's best error=0.8651,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:53] {3343} INFO -  at 11.3s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:53] {3166} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:55] {3343} INFO -  at 12.7s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:55] {3166} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:55] {3343} INFO -  at 12.7s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:55] {3166} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:55] {3343} INFO -  at 12.8s,\testimator lgbm's best error=0.8631,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:55] {3166} INFO - iteration 117, current learner rf\n",
      "[flaml.automl: 05-16 09:53:55] {3343} INFO -  at 12.8s,\testimator rf's best error=0.8242,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:55] {3166} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:55] {3343} INFO -  at 12.8s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:55] {3166} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 13.5s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 13.5s,\testimator lgbm's best error=0.8631,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 13.5s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 13.5s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 13.6s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 14.1s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 125, current learner rf\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 14.3s,\testimator rf's best error=0.8194,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 14.3s,\testimator lgbm's best error=0.8631,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 14.3s,\testimator lgbm's best error=0.8631,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl: 05-16 09:53:56] {3343} INFO -  at 14.3s,\testimator lgbm's best error=0.8631,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:56] {3166} INFO - iteration 129, current learner rf\n",
      "[flaml.automl: 05-16 09:53:57] {3343} INFO -  at 14.7s,\testimator rf's best error=0.8181,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:57] {3166} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:57] {3343} INFO -  at 14.7s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:57] {3166} INFO - iteration 131, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:57] {3343} INFO -  at 14.7s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:57] {3166} INFO - iteration 132, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:57] {3343} INFO -  at 14.7s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:57] {3166} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:58] {3343} INFO -  at 16.0s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:58] {3166} INFO - iteration 134, current learner rf\n",
      "[flaml.automl: 05-16 09:53:58] {3343} INFO -  at 16.2s,\testimator rf's best error=0.8181,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:58] {3166} INFO - iteration 135, current learner rf\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 16.8s,\testimator rf's best error=0.8181,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator extra_tree's best error=0.8134,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 138, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 139, current learner catboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator catboost's best error=0.9649,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 140, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.1s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.2s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 144, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.2s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.2s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 146, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.2s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 147, current learner xgboost\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.2s,\testimator xgboost's best error=0.9219,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 148, current learner rf\n",
      "[flaml.automl: 05-16 09:53:59] {3343} INFO -  at 17.4s,\testimator rf's best error=0.8163,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:53:59] {3166} INFO - iteration 149, current learner rf\n",
      "[flaml.automl: 05-16 09:54:00] {3343} INFO -  at 17.5s,\testimator rf's best error=0.8163,\tbest estimator extra_tree's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:00] {3166} INFO - iteration 150, current learner rf\n",
      "[flaml.automl: 05-16 09:54:00] {3343} INFO -  at 17.8s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:00] {3166} INFO - iteration 151, current learner rf\n",
      "[flaml.automl: 05-16 09:54:00] {3343} INFO -  at 18.2s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:00] {3166} INFO - iteration 152, current learner rf\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 18.5s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 18.6s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 154, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 18.6s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 18.6s,\testimator lgbm's best error=0.8631,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 156, current learner rf\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 19.3s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:01] {3343} INFO -  at 19.4s,\testimator xgb_limitdepth's best error=0.8994,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:01] {3166} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 19.4s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 159, current learner rf\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 19.6s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 160, current learner rf\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 19.9s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 19.9s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 162, current learner rf\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 20.3s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 20.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 20.3s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 165, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:02] {3343} INFO -  at 20.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:02] {3166} INFO - iteration 166, current learner rf\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 20.5s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 20.5s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 20.5s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 169, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 20.6s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 170, current learner rf\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.2s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.3s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.3s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:03] {3343} INFO -  at 21.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:03] {3166} INFO - iteration 176, current learner rf\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.7s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.7s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.7s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 179, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.7s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 181, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.8s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 182, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 21.8s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 183, current learner rf\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 22.2s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:04] {3343} INFO -  at 22.2s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:04] {3166} INFO - iteration 185, current learner rf\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 22.9s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 22.9s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 187, current learner rf\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 23.1s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 188, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 23.1s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 23.1s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 190, current learner rf\n",
      "[flaml.automl: 05-16 09:54:05] {3343} INFO -  at 23.3s,\testimator rf's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:05] {3166} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl: 05-16 09:54:06] {3343} INFO -  at 23.7s,\testimator extra_tree's best error=0.8134,\tbest estimator rf's best error=0.8134\n",
      "[flaml.automl: 05-16 09:54:06] {3166} INFO - iteration 192, current learner rf\n",
      "[flaml.automl: 05-16 09:54:06] {3343} INFO -  at 24.3s,\testimator rf's best error=0.8132,\tbest estimator rf's best error=0.8132\n",
      "[flaml.automl: 05-16 09:54:06] {3166} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:06] {3343} INFO -  at 24.3s,\testimator xgboost's best error=0.9035,\tbest estimator rf's best error=0.8132\n",
      "[flaml.automl: 05-16 09:54:06] {3166} INFO - iteration 194, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:06] {3343} INFO -  at 24.3s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8132\n",
      "[flaml.automl: 05-16 09:54:06] {3166} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:06] {3343} INFO -  at 24.3s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8132\n",
      "[flaml.automl: 05-16 09:54:06] {3166} INFO - iteration 196, current learner rf\n",
      "[flaml.automl: 05-16 09:54:08] {3343} INFO -  at 25.5s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:08] {3166} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:08] {3343} INFO -  at 25.5s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:08] {3166} INFO - iteration 198, current learner rf\n",
      "[flaml.automl: 05-16 09:54:08] {3343} INFO -  at 26.2s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:08] {3166} INFO - iteration 199, current learner rf\n",
      "[flaml.automl: 05-16 09:54:10] {3343} INFO -  at 28.0s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:10] {3166} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:10] {3343} INFO -  at 28.0s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:10] {3166} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:10] {3343} INFO -  at 28.0s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:10] {3166} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:10] {3343} INFO -  at 28.0s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:10] {3166} INFO - iteration 203, current learner rf\n",
      "[flaml.automl: 05-16 09:54:11] {3343} INFO -  at 28.9s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:11] {3166} INFO - iteration 204, current learner rf\n",
      "[flaml.automl: 05-16 09:54:11] {3343} INFO -  at 29.2s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:11] {3166} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:11] {3343} INFO -  at 29.2s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:11] {3166} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:11] {3343} INFO -  at 29.2s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:11] {3166} INFO - iteration 207, current learner rf\n",
      "[flaml.automl: 05-16 09:54:13] {3343} INFO -  at 30.7s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:13] {3166} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:13] {3343} INFO -  at 30.7s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:13] {3166} INFO - iteration 209, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:13] {3343} INFO -  at 30.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:13] {3166} INFO - iteration 210, current learner rf\n",
      "[flaml.automl: 05-16 09:54:14] {3343} INFO -  at 31.7s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:14] {3166} INFO - iteration 211, current learner rf\n",
      "[flaml.automl: 05-16 09:54:15] {3343} INFO -  at 33.1s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:15] {3166} INFO - iteration 212, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:15] {3343} INFO -  at 33.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:15] {3166} INFO - iteration 213, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:15] {3343} INFO -  at 33.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:15] {3166} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:15] {3343} INFO -  at 33.2s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:15] {3166} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:15] {3343} INFO -  at 33.2s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:15] {3166} INFO - iteration 216, current learner rf\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.7s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.7s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator lgbm's best error=0.8621,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 221, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.8s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.9s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.9s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:18] {3343} INFO -  at 35.9s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:18] {3166} INFO - iteration 227, current learner rf\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 36.4s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 36.4s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 36.5s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 230, current learner rf\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 232, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:19] {3343} INFO -  at 37.1s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:19] {3166} INFO - iteration 236, current learner rf\n",
      "[flaml.automl: 05-16 09:54:21] {3343} INFO -  at 39.4s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:21] {3166} INFO - iteration 237, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:21] {3343} INFO -  at 39.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:21] {3166} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:21] {3343} INFO -  at 39.4s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:21] {3166} INFO - iteration 239, current learner rf\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 41.7s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 240, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 41.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 241, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 41.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 41.7s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 243, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 41.8s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 244, current learner rf\n",
      "[flaml.automl: 05-16 09:54:24] {3343} INFO -  at 42.4s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:24] {3166} INFO - iteration 245, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:25] {3343} INFO -  at 42.4s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:25] {3166} INFO - iteration 246, current learner rf\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.2s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.2s,\testimator xgb_limitdepth's best error=0.8960,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 248, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 250, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 251, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 253, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 254, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.3s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.4s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:26] {3343} INFO -  at 44.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:26] {3166} INFO - iteration 258, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 260, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.4s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 262, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 263, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 44.5s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 264, current learner rf\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.3s,\testimator rf's best error=0.8111,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 265, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 266, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.3s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 268, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.4s,\testimator xgb_limitdepth's best error=0.8925,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 269, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:27] {3343} INFO -  at 45.4s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:27] {3166} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 45.4s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8111\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 271, current learner rf\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 272, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 273, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 274, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 275, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 276, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:28] {3343} INFO -  at 46.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:28] {3166} INFO - iteration 277, current learner rf\n",
      "[flaml.automl: 05-16 09:54:30] {3343} INFO -  at 47.4s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:30] {3166} INFO - iteration 278, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:30] {3343} INFO -  at 47.4s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:30] {3166} INFO - iteration 279, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:30] {3343} INFO -  at 47.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:30] {3166} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:30] {3343} INFO -  at 47.4s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:30] {3166} INFO - iteration 281, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:30] {3343} INFO -  at 47.5s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:30] {3166} INFO - iteration 282, current learner rf\n",
      "[flaml.automl: 05-16 09:54:31] {3343} INFO -  at 49.0s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:31] {3166} INFO - iteration 283, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:31] {3343} INFO -  at 49.0s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:31] {3166} INFO - iteration 284, current learner rf\n",
      "[flaml.automl: 05-16 09:54:32] {3343} INFO -  at 49.4s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:32] {3166} INFO - iteration 285, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:32] {3343} INFO -  at 49.5s,\testimator xgb_limitdepth's best error=0.8907,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:32] {3166} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:32] {3343} INFO -  at 49.5s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:32] {3166} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:32] {3343} INFO -  at 49.5s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:32] {3166} INFO - iteration 288, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:32] {3343} INFO -  at 49.5s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:32] {3166} INFO - iteration 289, current learner rf\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 50.7s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 290, current learner rf\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.2s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 291, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.2s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 292, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 293, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 294, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 295, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 296, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 297, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 298, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:33] {3343} INFO -  at 51.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:33] {3166} INFO - iteration 299, current learner rf\n",
      "[flaml.automl: 05-16 09:54:34] {3343} INFO -  at 52.0s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:34] {3166} INFO - iteration 300, current learner rf\n",
      "[flaml.automl: 05-16 09:54:35] {3343} INFO -  at 52.9s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:35] {3166} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:35] {3343} INFO -  at 52.9s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:35] {3166} INFO - iteration 302, current learner rf\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.6s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.6s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 305, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 306, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 307, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 308, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 309, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.7s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 310, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 54.8s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 311, current learner rf\n",
      "[flaml.automl: 05-16 09:54:37] {3343} INFO -  at 55.1s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:37] {3166} INFO - iteration 312, current learner rf\n",
      "[flaml.automl: 05-16 09:54:38] {3343} INFO -  at 55.8s,\testimator rf's best error=0.8103,\tbest estimator rf's best error=0.8103\n",
      "[flaml.automl: 05-16 09:54:38] {3166} INFO - iteration 313, current learner rf\n",
      "[flaml.automl: 05-16 09:54:39] {3343} INFO -  at 56.9s,\testimator rf's best error=0.8092,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:39] {3166} INFO - iteration 314, current learner rf\n",
      "[flaml.automl: 05-16 09:54:40] {3343} INFO -  at 57.5s,\testimator rf's best error=0.8092,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:40] {3166} INFO - iteration 315, current learner rf\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.0s,\testimator rf's best error=0.8092,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 316, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.0s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 317, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 318, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 319, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 320, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 321, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 322, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 323, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.1s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 324, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 325, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.2s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 326, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.2s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 327, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.2s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 328, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.3s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 329, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.3s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 330, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 331, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.3s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 332, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.3s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 333, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:41] {3343} INFO -  at 59.4s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:41] {3166} INFO - iteration 334, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 335, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.4s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 336, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.4s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 337, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.4s,\testimator xgb_limitdepth's best error=0.8898,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 338, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.4s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 339, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.5s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 340, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.5s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.5s,\testimator lgbm's best error=0.8613,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 342, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.5s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 343, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.5s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 344, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 345, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 346, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8805,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8804,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 348, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8804,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 349, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.6s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 350, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.7s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 351, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.7s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 352, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 353, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 354, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 355, current learner catboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator catboost's best error=0.9649,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 356, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 357, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 358, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 359, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.8s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 360, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 361, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 362, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 363, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 364, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 366, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 367, current learner xgboost\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgboost's best error=0.9027,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 368, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 59.9s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 369, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 370, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 371, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 372, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:42] {3166} INFO - iteration 373, current learner xgb_limitdepth\n",
      "[flaml.automl: 05-16 09:54:42] {3343} INFO -  at 60.0s,\testimator xgb_limitdepth's best error=0.8703,\tbest estimator rf's best error=0.8092\n",
      "[flaml.automl: 05-16 09:54:43] {3602} INFO - retrain rf for 1.0s\n",
      "[flaml.automl: 05-16 09:54:43] {3609} INFO - retrained model: RandomForestRegressor(max_features=0.20288371366601884, max_leaf_nodes=2074,\n",
      "                      n_estimators=719, n_jobs=-1)\n",
      "[flaml.automl: 05-16 09:54:43] {2901} INFO - fit succeeded\n",
      "[flaml.automl: 05-16 09:54:43] {2902} INFO - Time taken to find the best model: 56.91362190246582\n",
      "[flaml.automl: 05-16 09:54:43] {2913} WARNING - Time taken to find the best model is 95% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "automl = AutoML()\n",
    "automl.fit(cd.data[cd.data.columns.drop([target])], cd.data[target], task='regression', time_budget=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variation unexplained: 32.04%\n"
     ]
    }
   ],
   "source": [
    "# Fraction of variation unexplained\n",
    "mse = mean_squared_error(automl.predict(ct.test_df[ct.test_df.columns.drop([target])]), ct.test_df[target])\n",
    "var_y = cd.data[target].var()\n",
    "fvu = mse / var_y\n",
    "print(f'Variation unexplained: {100*fvu:.2f}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping with simple component models for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap configuration\n",
    "\n",
    "n_samples = 10\n",
    "n_sample_size = cd.data.shape[0]\n",
    "\n",
    "components_time_budget = 1\n",
    "train_size = .7\n",
    "num_samples= 1\n",
    "\n",
    "ct_ate = []\n",
    "scores = []\n",
    "naive_ate = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:56] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:56] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:56] {198} INFO - result: {'energy_distance': 0.006792934398862194, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.011579309137595114, 'ate_std': 0.000116246964705089, 'erupt': 18.55996201162422, 'norm_erupt': 18.553505788081747, 'qini': -23.852848985673297, 'auc': -1.399911751519962, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           1  16.637389  0.493286   False         True  0.000000\n",
      "1           0  15.619788  0.493286   False        False  1.973499\n",
      "2           1  17.450365  0.493286   False         True  0.000000\n",
      "3           0  18.552339  0.493286   False         True  1.973499\n",
      "4           0  15.800541  0.493286   False        False  1.973499\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  19.256347  0.493286   False        False  1.973499\n",
      "6996        1  19.757813  0.493286   False         True  0.000000\n",
      "6997        0  20.691722  0.493286   False         True  1.973499\n",
      "6998        0  18.806551  0.493286   False         True  1.973499\n",
      "6999        1  17.517908  0.493286   False        False  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002057209368648394}, 'validation': {'ate': -0.06261450675022497, 'ate_std': 0.0006375814238824671, 'erupt': 18.619502909824362, 'norm_erupt': 18.665585595867007, 'qini': 57.474846932949156, 'auc': 0.05021953537220153, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           1  20.490105  0.493286   False         True  0.000000\n",
      "1           1  18.865828  0.493286   False        False  0.000000\n",
      "2           1  20.965618  0.493286   False        False  0.000000\n",
      "3           0  20.520835  0.493286   False        False  2.086231\n",
      "4           0  21.778236  0.493286   False         True  2.086231\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        1  20.137614  0.493286   False        False  0.000000\n",
      "2996        0  18.514284  0.493286   False         True  2.086231\n",
      "2997        0  19.505551  0.493286   False        False  2.086231\n",
      "2998        1  15.504331  0.493286   False         True  0.000000\n",
      "2999        0  15.076587  0.493286   False         True  2.086231\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.006792934398862194}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.34567975997924805}\n",
      "[flaml.tune.tune: 05-16 10:15:56] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:56] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:56] {198} INFO - result: {'energy_distance': 0.005983301187777457, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.0391809242264879, 'ate_std': 0.0003876940874276623, 'erupt': 18.606178353553545, 'norm_erupt': 18.6014193548534, 'qini': 21.25206294864325, 'auc': -0.3767425906132473, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           1  20.112318  0.497571   False        False  0.000000\n",
      "1           0  20.647893  0.497571   False        False  1.990333\n",
      "2           1  21.043673  0.497571   False        False  0.000000\n",
      "3           0  19.812145  0.497571   False         True  1.990333\n",
      "4           1  19.577449  0.497571   False        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        1  18.395654  0.497571   False        False  0.000000\n",
      "6996        1  20.879923  0.497571   False        False  0.000000\n",
      "6997        0  20.293234  0.497571   False        False  1.990333\n",
      "6998        0  16.042143  0.497571   False         True  1.990333\n",
      "6999        1  19.439427  0.497571   False         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0027404451184196432}, 'validation': {'ate': 0.007163792750025626, 'ate_std': 7.078611548314342e-05, 'erupt': 18.51472744275859, 'norm_erupt': 18.497969958308897, 'qini': -25.035118524170226, 'auc': 0.01494272641295895, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           1  19.826668  0.497571    True         True  1.958225\n",
      "1           0  19.297738  0.497571    True        False  0.000000\n",
      "2           1  20.440927  0.497571    True         True  1.958225\n",
      "3           1  14.256567  0.497571    True        False  1.958225\n",
      "4           0  18.530959  0.497571    True        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  16.933968  0.497571    True         True  0.000000\n",
      "2996        1  19.942713  0.497571    True         True  1.958225\n",
      "2997        0  18.775998  0.497571    True        False  0.000000\n",
      "2998        0  16.179343  0.497571    True         True  0.000000\n",
      "2999        1  21.731790  0.497571    True         True  1.958225\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.005983301187777457}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.3190898895263672}\n",
      "[flaml.tune.tune: 05-16 10:15:57] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:57] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:57] {198} INFO - result: {'energy_distance': 0.008223708603578572, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.053330272370589064, 'ate_std': 0.0005328490124000781, 'erupt': 18.58544796784066, 'norm_erupt': 18.58999439386208, 'qini': 52.47089325100652, 'auc': -0.22797989638940153, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  16.048306  0.504429   False        False  2.017873\n",
      "1           1  15.791355  0.504429   False        False  0.000000\n",
      "2           0  22.121083  0.504429   False         True  2.017873\n",
      "3           1  17.616941  0.504429   False         True  0.000000\n",
      "4           1  21.248339  0.504429   False        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  20.719193  0.504429   False        False  2.017873\n",
      "6996        1  21.751761  0.504429   False        False  0.000000\n",
      "6997        0  21.770173  0.504429   False         True  2.017873\n",
      "6998        0  21.358867  0.504429   False         True  2.017873\n",
      "6999        1  13.342782  0.504429   False         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002487908977600206}, 'validation': {'ate': 0.0379034427400729, 'ate_std': 0.00038513141910727225, 'erupt': 18.59602126883093, 'norm_erupt': 18.5422043491241, 'qini': 10.035487846520548, 'auc': 0.9217311801919266, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  17.790098  0.504429    True        False  0.000000\n",
      "1           0  15.812063  0.504429    True         True  0.000000\n",
      "2           1  14.051419  0.504429    True        False  2.021563\n",
      "3           0  15.839469  0.504429    True         True  0.000000\n",
      "4           0  20.373237  0.504429    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        1  16.325828  0.504429    True        False  2.021563\n",
      "2996        0  18.519996  0.504429    True         True  0.000000\n",
      "2997        1  20.245841  0.504429    True        False  2.021563\n",
      "2998        1  19.076671  0.504429    True         True  2.021563\n",
      "2999        0  19.956365  0.504429    True        False  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.008223708603578572}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.32768702507019043}\n",
      "[flaml.tune.tune: 05-16 10:15:57] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:57] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:57] {198} INFO - result: {'energy_distance': 0.0058109873680871615, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.05969376352754612, 'ate_std': 0.0005969679158480774, 'erupt': 18.599203079643647, 'norm_erupt': 18.546238341526777, 'qini': -108.2984456472235, 'auc': -1.0286201663954293, 'values':       treated          Y      p  policy  norm_policy   weights\n",
      "0           0  17.528751  0.503   False         True  2.012072\n",
      "1           0  20.194275  0.503   False        False  2.012072\n",
      "2           1  17.681854  0.503   False         True  0.000000\n",
      "3           1  20.532287  0.503   False        False  0.000000\n",
      "4           1  22.146098  0.503   False        False  0.000000\n",
      "...       ...        ...    ...     ...          ...       ...\n",
      "6995        1  19.226113  0.503   False         True  0.000000\n",
      "6996        0  16.062745  0.503   False         True  2.012072\n",
      "6997        1  17.474206  0.503   False        False  0.000000\n",
      "6998        0  17.014679  0.503   False         True  2.012072\n",
      "6999        1  16.874348  0.503   False         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002998917224006803}, 'validation': {'ate': 0.05202089059546003, 'ate_std': 0.0005268769252296038, 'erupt': 18.57816482248784, 'norm_erupt': 18.486822028100537, 'qini': -22.229602102162477, 'auc': 0.3671933760208461, 'values':       treated          Y      p  policy  norm_policy   weights\n",
      "0           1  21.637487  0.503    True        False  2.008032\n",
      "1           1  17.686181  0.503    True         True  2.008032\n",
      "2           1  23.209958  0.503    True        False  2.008032\n",
      "3           0  17.352264  0.503    True        False  0.000000\n",
      "4           0  16.556600  0.503    True        False  0.000000\n",
      "...       ...        ...    ...     ...          ...       ...\n",
      "2995        1  16.177807  0.503    True         True  2.008032\n",
      "2996        0  19.466907  0.503    True         True  0.000000\n",
      "2997        1  16.395977  0.503    True         True  2.008032\n",
      "2998        1  15.442883  0.503    True         True  2.008032\n",
      "2999        0  21.010240  0.503    True        False  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.0058109873680871615}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.31870508193969727}\n",
      "[flaml.tune.tune: 05-16 10:15:58] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:58] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:58] {198} INFO - result: {'energy_distance': 0.005788010381093223, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.05035427163124883, 'ate_std': 0.0005012833328496887, 'erupt': 18.572021588395803, 'norm_erupt': 18.604408988210302, 'qini': 77.59782902824692, 'auc': -0.15252976465491122, 'values':       treated          Y      p  policy  norm_policy   weights\n",
      "0           0  16.015486  0.501   False         True  2.004008\n",
      "1           0  20.925857  0.501   False        False  2.004008\n",
      "2           1  20.566342  0.501   False         True  0.000000\n",
      "3           1  16.008869  0.501   False        False  0.000000\n",
      "4           0  16.292683  0.501   False        False  2.004008\n",
      "...       ...        ...    ...     ...          ...       ...\n",
      "6995        1  16.503242  0.501   False        False  0.000000\n",
      "6996        0  21.124333  0.501   False        False  2.004008\n",
      "6997        1  19.519575  0.501   False         True  0.000000\n",
      "6998        0  16.394999  0.501   False        False  2.004008\n",
      "6999        1  17.601474  0.501   False         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002691830861719424}, 'validation': {'ate': 0.030199550597361853, 'ate_std': 0.0002984701103300946, 'erupt': 18.619313139435985, 'norm_erupt': 18.63856108722518, 'qini': 55.98398376739112, 'auc': 1.44700065770201, 'values':       treated          Y      p  policy  norm_policy  weights\n",
      "0           1  18.379469  0.501    True         True  1.98939\n",
      "1           0  17.842581  0.501    True         True  0.00000\n",
      "2           1  18.432596  0.501    True         True  1.98939\n",
      "3           0  19.559262  0.501    True        False  0.00000\n",
      "4           0  15.175315  0.501    True        False  0.00000\n",
      "...       ...        ...    ...     ...          ...      ...\n",
      "2995        0  19.761234  0.501    True         True  0.00000\n",
      "2996        0  18.482398  0.501    True        False  0.00000\n",
      "2997        0  17.675863  0.501    True        False  0.00000\n",
      "2998        1  15.914809  0.501    True         True  1.98939\n",
      "2999        1  21.801527  0.501    True         True  1.98939\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.005788010381093223}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.31581687927246094}\n",
      "[flaml.tune.tune: 05-16 10:15:58] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:58] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:58] {198} INFO - result: {'energy_distance': 0.005135261588912421, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': 0.001947649643368465, 'ate_std': 1.9312691509662422e-05, 'erupt': 18.573675278887926, 'norm_erupt': 18.61171622669532, 'qini': 68.03274416428596, 'auc': 12.535443754348988, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  18.297895  0.505286    True         True  0.000000\n",
      "1           1  20.455774  0.505286    True         True  1.979078\n",
      "2           0  16.926579  0.505286    True        False  0.000000\n",
      "3           1  18.110362  0.505286    True        False  1.979078\n",
      "4           0  21.282630  0.505286    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        1  19.883264  0.505286    True         True  1.979078\n",
      "6996        1  21.166955  0.505286    True        False  1.979078\n",
      "6997        1  21.949851  0.505286    True        False  1.979078\n",
      "6998        0  20.994268  0.505286    True         True  0.000000\n",
      "6999        1  19.009731  0.505286    True        False  1.979078\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.003595402807980541}, 'validation': {'ate': -0.09262088874386314, 'ate_std': 0.0009398856952772158, 'erupt': 18.589445971884068, 'norm_erupt': 18.632496831942746, 'qini': 47.5831118201505, 'auc': -0.22646470894790646, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           1  22.268793  0.505286   False        False  0.000000\n",
      "1           0  21.895748  0.505286   False        False  1.971091\n",
      "2           1  17.593517  0.505286   False        False  0.000000\n",
      "3           1  17.432140  0.505286   False         True  0.000000\n",
      "4           1  20.773562  0.505286   False         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        1  17.696733  0.505286   False        False  0.000000\n",
      "2996        1  16.708051  0.505286   False        False  0.000000\n",
      "2997        0  21.647110  0.505286   False         True  1.971091\n",
      "2998        0  17.140984  0.505286   False         True  1.971091\n",
      "2999        0  18.223902  0.505286   False         True  1.971091\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.005135261588912421}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.31238818168640137}\n",
      "[flaml.tune.tune: 05-16 10:15:58] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:58] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:59] {198} INFO - result: {'energy_distance': 0.007758453705789314, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': 0.004967161314645033, 'ate_std': 4.955200090092801e-05, 'erupt': 18.531350579393045, 'norm_erupt': 18.51556313105187, 'qini': -24.609333787208605, 'auc': -1.2673392952490135, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  18.829940  0.504429    True         True  0.000000\n",
      "1           0  15.457717  0.504429    True        False  0.000000\n",
      "2           0  18.079474  0.504429    True         True  0.000000\n",
      "3           0  21.252543  0.504429    True         True  0.000000\n",
      "4           0  19.867758  0.504429    True        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  18.956735  0.504429    True        False  0.000000\n",
      "6996        1  15.425403  0.504429    True         True  1.982441\n",
      "6997        0  16.427027  0.504429    True         True  0.000000\n",
      "6998        0  19.088509  0.504429    True        False  0.000000\n",
      "6999        0  19.044537  0.504429    True         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002483344840977786}, 'validation': {'ate': -0.095429854904333, 'ate_std': 0.0009573242826169369, 'erupt': 18.693276609741087, 'norm_erupt': 18.695223293154445, 'qini': -10.554926775442315, 'auc': -0.6118374431780976, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  17.811206  0.504429   False        False  1.978892\n",
      "1           1  19.323065  0.504429   False         True  0.000000\n",
      "2           0  18.285468  0.504429   False         True  1.978892\n",
      "3           1  20.646958  0.504429   False        False  0.000000\n",
      "4           1  18.259702  0.504429   False         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        0  19.338318  0.504429   False        False  1.978892\n",
      "2996        0  20.223674  0.504429   False         True  1.978892\n",
      "2997        1  19.045810  0.504429   False         True  0.000000\n",
      "2998        1  17.754077  0.504429   False         True  0.000000\n",
      "2999        0  20.698791  0.504429   False        False  1.978892\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.007758453705789314}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.3151559829711914}\n",
      "[flaml.tune.tune: 05-16 10:15:59] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:59] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:15:59] {198} INFO - result: {'energy_distance': 0.0052745134072340605, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.050069357732443864, 'ate_std': 0.0005002133916783034, 'erupt': 18.591171986206607, 'norm_erupt': 18.62312517475528, 'qini': 41.280741448026525, 'auc': -0.2818577034783602, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  19.281053  0.503143   False        False  2.012651\n",
      "1           1  20.242997  0.503143   False        False  0.000000\n",
      "2           0  21.141306  0.503143   False        False  2.012651\n",
      "3           1  20.316544  0.503143   False         True  0.000000\n",
      "4           0  22.001497  0.503143   False        False  2.012651\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  17.719065  0.503143   False        False  2.012651\n",
      "6996        1  16.700631  0.503143   False        False  0.000000\n",
      "6997        0  21.009746  0.503143   False        False  2.012651\n",
      "6998        0  23.361902  0.503143   False        False  2.012651\n",
      "6999        1  21.999325  0.503143   False         True  0.000000\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0034060841083940474}, 'validation': {'ate': 0.029720290417507754, 'ate_std': 0.00028663287322823163, 'erupt': 18.574466434986736, 'norm_erupt': 18.53016571972723, 'qini': -63.12950982054056, 'auc': -0.9355078704032814, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  21.002487  0.503143    True         True  0.000000\n",
      "1           0  19.806870  0.503143    True        False  0.000000\n",
      "2           1  17.574668  0.503143    True        False  2.009377\n",
      "3           1  17.557636  0.503143    True        False  2.009377\n",
      "4           0  17.155990  0.503143    True         True  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        1  19.056484  0.503143    True        False  2.009377\n",
      "2996        0  16.539274  0.503143    True         True  0.000000\n",
      "2997        0  20.451575  0.503143    True         True  0.000000\n",
      "2998        1  16.562265  0.503143    True         True  2.009377\n",
      "2999        1  21.055897  0.503143    True         True  2.009377\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.0052745134072340605}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.31480908393859863}\n",
      "[flaml.tune.tune: 05-16 10:15:59] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:15:59] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:16:00] {198} INFO - result: {'energy_distance': 0.006610284194676019, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.0695606086181253, 'ate_std': 0.0006930908799010237, 'erupt': 18.60165880080607, 'norm_erupt': 18.59702044598442, 'qini': -34.9238439868696, 'auc': -0.537915893962846, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  20.110090  0.501143   False         True  2.004582\n",
      "1           1  15.638357  0.501143   False         True  0.000000\n",
      "2           0  17.043327  0.501143   False        False  2.004582\n",
      "3           1  20.833821  0.501143   False        False  0.000000\n",
      "4           1  15.928459  0.501143   False        False  0.000000\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        0  18.135049  0.501143   False         True  2.004582\n",
      "6996        0  19.740795  0.501143   False         True  2.004582\n",
      "6997        0  17.065648  0.501143   False         True  2.004582\n",
      "6998        1  16.418315  0.501143   False         True  0.000000\n",
      "6999        0  17.124370  0.501143   False         True  2.004582\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.002294497375074478}, 'validation': {'ate': 0.0753060410127725, 'ate_std': 0.000744223012488317, 'erupt': 18.595094339188524, 'norm_erupt': 18.456829964273563, 'qini': -36.921265402735315, 'auc': 0.12556665076373813, 'values':       treated          Y         p  policy  norm_policy  weights\n",
      "0           1  18.481479  0.501143    True        False  1.99071\n",
      "1           1  17.845761  0.501143    True         True  1.99071\n",
      "2           1  19.035502  0.501143    True         True  1.99071\n",
      "3           1  15.337736  0.501143    True        False  1.99071\n",
      "4           1  21.603649  0.501143    True        False  1.99071\n",
      "...       ...        ...       ...     ...          ...      ...\n",
      "2995        1  16.585693  0.501143    True        False  1.99071\n",
      "2996        1  19.655858  0.501143    True         True  1.99071\n",
      "2997        1  17.531571  0.501143    True        False  1.99071\n",
      "2998        1  15.571515  0.501143    True        False  1.99071\n",
      "2999        0  20.383914  0.501143    True        False  0.00000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.006610284194676019}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.31295299530029297}\n",
      "[flaml.tune.tune: 05-16 10:16:00] {493} WARNING - Using CFO for search. To use BlendSearch, run: pip install flaml[blendsearch]\n",
      "[flaml.tune.tune: 05-16 10:16:00] {636} INFO - trial 1 config: {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Propensity-Weighted scoring estimator to be used in scoring tasks\n",
      "Initial configs: [{'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.Dummy'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.SLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.metalearners.DomainAdaptationLearner'}}, {'estimator': {'estimator_name': 'backdoor.econml.dr.ForestDRLearner', 'min_propensity': 1e-06, 'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.econml.dml.CausalForestDML', 'drate': True, 'n_estimators': 100, 'criterion': 'mse', 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'auto', 'min_impurity_decrease': 0.0, 'max_samples': 0.45, 'min_balancedness_tol': 0.45, 'honest': True, 'fit_intercept': True, 'subforest_size': 4}}, {'estimator': {'estimator_name': 'backdoor.auto_causality.models.TransformedOutcome'}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-16 10:16:00] {198} INFO - result: {'energy_distance': 0.006714130112385419, 'estimator_name': 'backdoor.auto_causality.models.NaiveDummy', 'scores': {'train': {'ate': -0.07526288357717965, 'ate_std': 0.0007495062427130468, 'erupt': 18.618508971518978, 'norm_erupt': 18.609667111898535, 'qini': 12.368160265707115, 'auc': -0.5063336932090177, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  21.522560  0.500143   False         True  2.000572\n",
      "1           1  17.148742  0.500143   False        False  0.000000\n",
      "2           0  20.946794  0.500143   False        False  2.000572\n",
      "3           1  17.023447  0.500143   False        False  0.000000\n",
      "4           0  18.395886  0.500143   False         True  2.000572\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "6995        1  20.000841  0.500143   False        False  0.000000\n",
      "6996        0  16.446436  0.500143   False         True  2.000572\n",
      "6997        1  16.157334  0.500143   False        False  0.000000\n",
      "6998        0  19.771409  0.500143   False         True  2.000572\n",
      "6999        0  21.409569  0.500143   False         True  2.000572\n",
      "\n",
      "[7000 rows x 6 columns], 'energy_distance': 0.0031727287175487007}, 'validation': {'ate': 0.08930861416966598, 'ate_std': 0.000904716769385588, 'erupt': 18.569041103208637, 'norm_erupt': 18.479414159688368, 'qini': -18.641416559002806, 'auc': 0.4925396885303557, 'values':       treated          Y         p  policy  norm_policy   weights\n",
      "0           0  19.940281  0.500143    True        False  0.000000\n",
      "1           1  19.603253  0.500143    True        False  1.981506\n",
      "2           0  17.182463  0.500143    True         True  0.000000\n",
      "3           0  21.746971  0.500143    True        False  0.000000\n",
      "4           1  15.325571  0.500143    True        False  1.981506\n",
      "...       ...        ...       ...     ...          ...       ...\n",
      "2995        1  21.574707  0.500143    True         True  1.981506\n",
      "2996        0  17.323676  0.500143    True        False  0.000000\n",
      "2997        0  15.398387  0.500143    True         True  0.000000\n",
      "2998        0  14.451003  0.500143    True        False  0.000000\n",
      "2999        0  15.947691  0.500143    True        False  0.000000\n",
      "\n",
      "[3000 rows x 6 columns], 'energy_distance': 0.006714130112385419}}, 'config': {'estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}}, 'training_iteration': 0, 'config/estimator': {'estimator_name': 'backdoor.auto_causality.models.NaiveDummy'}, 'experiment_tag': 'exp', 'time_total_s': 0.3134043216705322}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(n_samples):\n",
    "    cd_bt = generate_synth_data_with_categories()\n",
    "    cd_bt.preprocess_dataset()\n",
    "    outcome_regressor = RandomForestRegressor()\n",
    "    \n",
    "    ct = AutoCausality(\n",
    "        num_samples=num_samples,\n",
    "        components_time_budget=components_time_budget,\n",
    "        metric=\"energy_distance\",\n",
    "        train_size=train_size,\n",
    "        propensity_model='dummy',\n",
    "        outcome_model=outcome_regressor\n",
    "        )        \n",
    "\n",
    "    ct.fit(data=cd, outcome=target)\n",
    "\n",
    "    ct_ate.append(ct.effect(ct.test_df).mean())\n",
    "    scores.append(ct.best_score)\n",
    "    naive_ate.append(ct.scorer.naive_ate(cd_bt.data[cd_bt.treatment], cd_bt.data[target])[0])\n",
    "    del ct, cd_bt, outcome_regressor\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot([ct_ate, naive_ate])\n",
    "ax.set_xticklabels(['$\\hat{\\mu}_{CausalTune}$', '$\\hat{\\mu}_{DiffInMeans}$'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Segmentation with Wise Pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = list(set(cd.data.columns) - set([cd.treatment]) - set(cd.outcomes) - set(['random']))\n",
    "\n",
    "ps_counts = (\n",
    "    cd.data#.loc[cd.data[cd.treatment].isin([0, cd.treatment]), :]\n",
    "    .groupby(by=segments)[cd.treatment]\n",
    "    .agg(\"count\")\n",
    ")\n",
    "\n",
    "df_effects = pd.concat([cd.data[segments], pd.Series(ct.effect(cd.data), name='CATE')], axis=1)\n",
    "df_eff_by_seg = df_effects.groupby(by=segments)['CATE'].agg('mean')\n",
    "\n",
    "df_wp = pd.concat([df_eff_by_seg, ps_counts], axis=1).reset_index()\n",
    "df_wp['totals'] = df_wp['variant'] * df_wp['CATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "image/png": {
       "height": 590,
       "width": 2090
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 2\n",
    "min_segments = 3\n",
    "\n",
    "sf = wp.explain_levels(\n",
    "    df=df_wp,\n",
    "    dims=segments,\n",
    "    total_name='totals',\n",
    "    size_name=cd.treatment,\n",
    "    max_depth=max_depth,\n",
    "    min_segments=min_segments,\n",
    ")\n",
    "sf.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
